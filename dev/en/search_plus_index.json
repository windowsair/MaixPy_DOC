{"./":{"url":"./","title":"Introduction","keywords":"","body":"MaixPy Documentation What is MaixPy MaixPy ported Micropython to K210 (a 64-bit dual-core RISC-V CPU with hardware FPU and convolution accelerator). A project that supports MCU routine operations and integrates machine vision and microphone arrays to quickly develop intelligent applications in the AIOT field that are extremely cost effective and practical. MicroPython is a lean and efficient implementation of the Python 3 programming language that includes a small subset of the Python standard library and is optimised to run on microcontrollers and in constrained environments. K210 created for AIOT(AI+IOT) use, It's powerful performance and low cost are very competitive. Micropython makes programming on K210 hardware easier, the code is open source and can be found on GitHub) For example if we want to find an I2C device, we just need this code: from machine import I2C i2c = I2C(I2C.I2C0, freq=100000, scl=28, sda=29) devices = i2c.scan() print(devices) Again, if we want to make a breathing light using PWM, we just need this code: from machine import Timer,PWM import time tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM) ch = PWM(tim, freq=500000, duty=50, pin=board_info.LED_G) duty=0 dir = True while True: if dir: duty += 10 else: duty -= 10 if duty>100: duty = 100 dir = False elif duty To take a picture： import sensor import image import lcd lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) while True: img=sensor.snapshot() lcd.display(img) About this documentation Everything related to MaixPy, mainly about How to choose and get a suitable module/development board How to get started with MaixPy, even if you are not an expert in hardware programming. Learn MicroPython language basics Libraries (API) reference Let's get started First of all, we need to choose a development board that suits your needs. The following ones are currently available: Dan dock with Sipeed M1(Dan) module k.png) Sipeed Maix BiT Sipeed Maix Go Sipeed Maixduino To get any of those boards, visit Sipeed Official Website More hardware infomation here We can now start writing software, refer to get started Video tutorial This video will briefly introduce the basics to get started. To get more in-depth, please check the documentation. MaixPy source code If you want to participate in the development of MaixPy's built in features, you can download the source code and do a pull request. MaixPy source is hosted on GitHub Branch Status master This project was started by ©Sipeed Co.,Ltd. and accepts contributions from the open source community. You can see who contributed by checking the list of contributors Source code of MaixPy documentation Doumentation will be edited if the API code is changed. The source of the documentation can be found on GitHub You MUST read the documentation convention before editing it! Branch Status master dev Feedback Documentation feedback Code feedback "},"others/what_maix_do.html":{"url":"others/what_maix_do.html","title":"What can MaixPy do?","keywords":"","body":"Powerful Maix Board(k210) Can Do Most of them integrated to MaixPy, or some of them include in Maixduino or from other developers draw picture Turorial Openmv and Record video MobileNet Face detection NES gamer emulator MNIST Play video Feature map display GBA game emulator Game Quake I source code Game Doom source code MMD 3D rendering your browser does not support the video tag source code Gimbal face track Mic array LittlevGL FFT spectrum "},"get_started/get_hardware.html":{"url":"get_started/get_hardware.html","title":"Get the hardware","keywords":"","body":"Getting a development board Get your favorite hardware from Sipeed's official Taobao store or from Seeed Studio Required hardware 一A development board Choose a board here USB Type C cable Type-C is chosen because it's reversible and it's very friendly for development. If you're buying from the official Taobao store, you can ask them to include it with your order. Type-C cables are also very common with Android phones. Screen By default, the LCD (24-pin interface) of the st7789 driver chip is used with a resolution of 320x240. If you're buying from the official Taobao store, you can ask them to include it with your order. Camera MaixPy devices support the ov2640 camera by default, and are often bundled with Maix devices. The ov2640 cameras bundled with Maix device are typically offered with two different lens options; a larger focusable fisheye lens, or a smaller fixed-focus lens. If you're buying from the official Taobao store, you can order a specific camera with your order. Micro SD Card (TF Card) (optional) Some Flash memory within the the device is reserved for a file system, but this internal memory is very slow! For quicker operation and additional storage, you can insert a Micro SD card or a TF card into the card slot available on most Maix devices. When purchasing a memory card, try to choose a new fast Micro SD card, such as a SD 2 generation protocol, Class10 memory card. Of course, the quality of SD cards on the market is uneven, and the SPI mode may not be compatible. Try to buy a regular card. Or maybe you should customize the driver code ~~ As shown below, the two cards on the left are not supported by the MaixPy driver. Both the middle and the right cards are supported, but the class10 card in the middle is the fastest. ST-Link (used to update the firmware of the STM32 on the development board Maix Go) (optional) If you purchase a Maix Go, it has an embedded STM32 chip to simulate the USB-to-Serial converter, as well as JTAG. If you want to upgrade its firmware later on, it is recommended to buy an ST-Link programmer. JTAG Debugger (optional) The K210 chip supports JTAG debugging. If you need to debug, you will need to use the JTAG debugger. Please check the Sipeed Taobao store or SeeedStudio.com to buy one. If you are using a Maix Go development board, you won't need to purchase the JTAG debugger separately as it has an integrated STM32 chip that can emulate JTAG (STM32 uses CMSIS-DAP or open-ec firmware). open-ec firmware is currently not supported, although support will be added later. Please refer to the open-ec GitHub project page for more information. "},"get_started/upgrade_firmware.html":{"url":"get_started/upgrade_firmware.html","title":"Upgrade the firmware","keywords":"","body":"Upgrade MaixPy firmware Connecting the board Connect the Type C cable, one end to the development board, one end to the computer. Install the driver We need to install the serial port driver as the board is connected to the computer through the USB to serial converter. Install the driver according to the board's USB to serial port chip model. In you are using Linux or Mac and you don't want to use sudo every time, add yourself to the dialout users group with the following command: sudo usermod -a -G dialout $(whoami) For Dan Dock or Maix Bit The CH340 chip is being used, Linux does not need to install the driver as the system already comes with it. Execute ls /dev/ttyUSB* to check if the device is found. If using Windows, search and download the drivers on the Internet, then open Device manager and look if the serial port is listed. For Maix Go An STM32 is being used to implement the serial port and the JTAG functionality. By default, this STM32 chip is running a build of the open-ec firmware. If everything is right, one or two serial ports will appear. In linux the following two serial ports will appear: /dev/ttyUSB0 and /dev/ttyUSB1. Please use /dev/ttyUSB1 when downloading and accessing the serial port. Windows is similar. If you need to re-burn this firmware, you can download it from GitHub or open-ec firmware, then use the STM32's SW pins (GND, SWDIO, SWCLK) from the ST-LINK connection board for programming. (The STM32 on the current version of the Go board does not support serial port burning. It can only be burned using ST-LINK. Please purchase it if you need it, or use a board with IO simulation such as the Raspberry Pi)) Currently, open-ec cannot simulate JTAG to debug the board. Use CMSIS-DAP to do so. You can download it from the official website and then burn it using an ST-LINK. Afterwards, /dev/ttyACM0 will appear under linux. ST-LINK has a very complete description of the burning method of STM32, please search for yourself. Please note that updating the firmware of STM32 is not the same as updating the MaixPy firmware. Generally, you do not need to update the firmware of STM32. The default is enough. STM32 is just a USB to serial port tool! Do not be confused. For the new Maixduino and Maix Bit versions that come with a microphone (using a CH552 chip) For the boards with a CH552 chip, to get the USB serial port, FT2232 drivers need to be installed. Search yourself for FT2232 drivers. In those boards, the JTAG function is not available. Get the upgrade tool Download kflash_gui and you will get a zip file. kflash_gui is cross-platform, it can work on multiple systems (including Windows, Linux, MacOS or even Raspberry Pi) Extract the downloaded file to a folder, then double-click kflash_gui.exe to run the app. Get firmware The release version of the firmware is downloaded from the GitHub page The automated builds can be downloaded from here Firmware files have the .bin or .kfpkg extension To package kfpkg files, check this link Firmware naming instructions: maixpy_v*_no_lvgl.bin： MaixPy firmware, without LVGL version. (LVGL is an embedded GUI framework, you need to use when writing the interface) maixpy_v*_full.bin： Full version of MaixPy firmware (MicroPython + OpenMV API + lvgl) maixpy_v0.3.1_minimum.bin： MaixPy firmware minimum set, not supported ´by MaixPy IDE, does not contain OpenMVrelated algorithms face_model_at_0x300000.kfpkg： Face model, placed in address 0x300000, can be downloaded multiple times without conflict elf.7z： elf file, ordinary users do not care, used for crash debugging Download firmwre to the development board Open kflash_gui Select the firmware, set the options and then click to download. For more features, or instructions on how to use the tool, check the kflash_gui project page For the early Maix Go， if the download fails, try holding the three-phase dial to the down location during the download procedure. "},"get_started/power_on.html":{"url":"get_started/power_on.html","title":"Power on","keywords":"","body":"Power up the device, first time setup with MaixPy Connecting hardware Connect the Type C cable, one end of the computer development board Check to see if the device has been properly identified: Under Linux can ls /dev/ttyUSB* or ls /dev/ttyACM* to see, if not you can ls /dev come look for the specific device name with the relevant serial chip and drive Under Windows, you can open Device Manager to view If the device is not found, you need to confirm if the driver is installed and if the contact is good. Using the serial port tool Linux Use minicom or screen tool. minicom sudo apt update sudo apt install minicom sudo minicom -s # Then set the serial port number according to the prompt and the baud rate is 115200. Do not know how to search using the search tool. # Set Backspace to DEL function # Set linewrap to Yes sudo minicom Note that minicom's default configuration file save requires sudo permission, so use sudo minicom -s Press here A to set the device Press E to set the baud rate, the baud rate needs to be set 115200 Here press A and R the setting is switched to the setting in the drawing as the first to use the latter pye editor shortcuts do not conflict, is provided to wrap the second one is to be able to display full output After setting save and exit, next time do not need to set up is required only if sudo minicom you can, if you do not want to use every time sudo a command is executed sudo usermod -a -G dialout $(whoami) to add themselves to the dialout user groups can be, may need to log off or reboot to take effect, note that sudo minicom -s if you use The default profile is still needed sudo After entering minicom, click the Enter button to see the interactive interface of MaixPy. Input help(), you can view help To exit minicom, press Ctrl+A X, press Enter confirm to exit Screen sudo apt update sudo apt install screen sudo screen /dev/ttyUSB0 115200 Then click the Enter button to see the interactive interface of MaixPy. >>> Input help(), you can view help To exit screen, press Ctrl+A K and press Y confirm to exit Windows Use tools like putty or xshell Then select the serial port mode, then set the serial port and baud rate to open the serial port. Then click the Enter button to see the interactive interface of MaixPy. >>> Input help(), you can view help "},"get_started/led_blink.html":{"url":"get_started/led_blink.html","title":"LED blink","keywords":"","body":"Lighting the LED The lighting program is the first program to learn all the development boards. Just like learning all programming languages, learning the hello world is a sacred meaning. It is well known that lighting an LED requires a power supply, a resistor, and an LED bulb. On the Dan Dock development board, there are three LEDs, the lines are as follows: For example, we want to red light, i.e., LED_R connected to the LED, the LED can be seen in FIG positive 3.3V power supply has been connected, so long as we can LED_R LED lighting is low. Before writing the program, we need to know that the corresponding pins of the on-chip peripherals (such as GPIO, I2C, etc.) of the hardware K210 used by MaixPy can be arbitrarily set. The STM32 on-chip peripherals and pin correspondences have been fixed. Some of the pins can be multiplexed, compared to the K210 with greater degrees of freedom. For example, I2C can use Pin11 and Pin12, or can be changed to any other pin. We control the LEDs and need to use GPIO The procedure is as follows: from Maix import GPIO fm.register(board_info.LED_R, fm.fpioa.GPIO0) led_r=GPIO(GPIO.GPIO0,GPIO.OUT) led_r.value(0) We only need to click the lines of the code one by one to the keyboard inside the terminal and press OK to execute. Among them, we start with the package Maix introduced GPIO this class; Front pin can be set K210, so we use .fm(fpioa manager) correspondence between peripherals and pin registration chip built-in object to this, here　fm.fpioa.GPIO0 is a GPIO Peripheral K210's ( Note the difference between GPIO (peripheral) and pin (real hardware pin)), so the fm.fpioa.GPIO0 registration to pin board_info.LED_R; Here board_info is a board type information can be entered in serial terminal board_info. then press TAB the button to see all the members, each pin largely value Then define a GPIO subject, specific parameters to see GPIO the module's documentation, look in the left sidebar. Use led_r.value(0) or led_r.value(1) to set high to low It is already possible to light up here. If you know the Python syntax, you can try to write a for loop to achieve LED flashing~ "},"get_started/edit_file.html":{"url":"get_started/edit_file.html","title":"Edit and execute files","keywords":"","body":"Editing, saving and executing files This section teaches you how to edit, save and execute files. REPL interface To keep things simple in the previous example, we entered code directly in the terminal at the Maix prompt which was executed immediately upon pressing the Enter key. Such interactive command line interfaces are often referred to as REPL（Read Eval Print Loop). MaixPy's REPL interface operates similar to most other command line interfaces except that the supported syntax is MicroPython While MaixPy's REPL interface is simple and convenient for small tasks, it soon becomes annoying to re-enter your code each time you want to run it. The solution is to save your code to a file, and then execute the file. The remainder of this page describes that process. MaixPy file system MaixPy devices have an internal file system which can access both internal and external memories. During boot, the device will mount any external memory cards formatted with either SPIFFS or FAT file systems, and add them to the internal file system as the /flash or /sd directories respectively. NOTES: SPIFFS cards are by default assigned to 3MB SPIFFS (starting at flash address 0xD00000). When detected at boot, SPIFFS devices automatically appear as the /flash directory within the device's internal file system. Currently the SPIFFS implementation in MaixPy does not support the creation of directories. FAT formatted SD (TF) cards are supported, but FAT32 or exFAT formatted cards are not currently supported. When detected at boot, FAT formatted cards will be automatically mounted and appear as the /sd directory in the device's internal file system. It should be noted that the root directory is only used to mount the SD card or SPIFFS flash card. All other file operations happen in the /flash or /sd directories, as determined by the format of the memory card discovered at boot time. Navigating the file system In MaixPy's REPL interface and in code the following os commands can be used to navigate directories and manage files. Command Description Example os.chdir() changes the current directory os.chdir(\"/flash\") os.listdir() list the files in the current directory os.listdir() os.listdir(path) list the files in another directory os.listdir(\"/sd\") os.getcwd() return the current working directory os.getcwd() os.rename(old_path, new_path) rename a file os.rename(\"./blue.py\", \"./aaah.py\") os.remove(path) remove a file os.remove(\"./herring.py\") For a complete list of os commands refer to the MicroPython documentation Editing and saving files There are a number of ways you can edit and save files described below as Methods A through C Method A: Edit and save files using the pye editor built into MaixPy MaixPy includes a built-in open source editor Micropython Editor(pye) At the REPL interface enter pye(\"hello.py\") to create a file and enter the edit mode. Keyboard shortcuts and other instructions can be found here Enter the following code: print(\"hello maixpy\") When you have finished editing, press Ctrl+S and then press Enter to save, and then press Ctrl+Q to exit the editor. Note : The pye editor has certain requirements of the connected terminal. For intuitive operation the BackSpace key should be configured to send Ctrl+?, otherwise the BackSpace key will function as Ctrl+H (ie: character replacement). Linux users are recommended to use minicom. Use sudo minicom -s to set the reference to the previous tutorial Windows users can use PuTTY which supports Backspace key configuration. Note Typing Shift-Backspace will cause PuTTY to send whichever code isn't configured as the default. Alternatively, Xshell users can use: File → Properties → Terminal → Keyboard, Change the delete and backspace sequences to ASCII 127. Method B: Read files to PC by uPyLoader, then download to board after editing This method uses the uPyLoader utility Download the executable: release Select the serial port and click the Connect button to connect the board The first time you run the software, you need to initialize it. Click File->Init transfer files to complete the initialization. This will create two files in the board, __upload.py and __download.py. Then double click file name to read and edit, then click the save button to download the file to board Method C: Read files to PC by rshell, edit, and then save back to board Install rshell first according to the doc of rshell sudo apt-get install python3-pip sudo pip3 install rshell rshell -p /dev/ttyUSB1 # select board serial Edit file ls /flash edit /flash/boot.py # the editor uses vim commands Execution of documents Once MicroPython files exist on the file system they may be executed using the following methods Method A: Execute using import At MaixPy's REPL interface simply enter: import hello then press Enter The hello.py file will run and should output hello maixpy But be careful, the import command can only be used once. If you want to execute the code more than once, please use Method B below. Method B: Execute using exec() Use exec() in a simple program to execute your file with open(\"hello.py\") as f: exec(f.read()) Method C: Execute using uPyLoader Just select the file, then click the execute button Method D: Execute files locally on PC using ampy ampy run script by command ampy run file_in_PC.py to execute files on PC (file won't transmit to board) "},"get_started/upload_script.html":{"url":"get_started/upload_script.html","title":"Upload the script to the development board","keywords":"","body":"Upload script to development board Earlier we came across the pye(\"filename.py\") command to open an editor that directly edits files in the file system. But slowly we will find that this method is only suitable for changing a small amount of code. When the amount of code is huge or we need to highlight support, it does not apply. We need to write the code on the computer and upload it to the board. There are currently several methods: Uploading scripts using the MaixPy IDE Open the MaixPy IDE and connect to the development board. Edit the file, then in the top Tools menu click Save opened file as boot.py to save the code to the development board's boot.py file. The next time the board is powered on, it will be automatically executed. You can also use the Send file option in the Tools menu to send the file. It will be saved to the development board with the same name. This script can also upload other small files. Uploading and running scripts using the graphical tool uPyLoader uPyLoader is an open source software that allows you to easily connect to MaixPy and upload, download, and execute files, monitor output, and more. Download the executable: release Select the serial port and click the Connect button to connect the board The first time you run the software you will need to initialize it. Click File -> Init transfer files to complete the initialization. This will create two files in the board, __upload.py and __download.py. On the left side select the file you want to upload and click Transfer to upload it to the board's file system. On the right side are the files inside the board, click List files to refresh the file list. To execute the script, simply select the file name and click on Execute. Click on View -> Terminal above to open the terminal to view the runtime output or send a command Using rshell tool Just as widh the linux, use the cp on rshell to copy the file to the development board. First, install rshell: sudo apt-get install python3-pip sudo pip3 install rshell rshell -p /dev/ttyUSB1 # choose the device according to your serial port Then copy file~ ls /flash cp ./test.py /flash/ # copies the file \"text.py\" from the computer to the root directory of the development board You can learn about other features of rshell in its project page. Using the command line tool ampy ampy is an open source, easy-to-use command line tool for uploading, downloading, and executing files. Note that this tool is running on the computer, not on the board. Use ampy --help to view help and information. The ampy run file_in_PC.py command also allows you to run the script directly on the board without uploading it previously. TF card copy After copying it to the TF card, execute import filename in the terminal to run the script. "},"get_started/boot.html":{"url":"get_started/boot.html","title":"Boot","keywords":"","body":"Boot script If a memory card formatted with either a SPIFFS or FAT file system is detected at boot, MaixPy will look for a boot.py file in the root directory of that memory card. If /boot.py is found, the system will immediately execute it. If the /boot.py file is not found, the device will automatically create one on the memory card that offers a basic REPL command line interface. Edit the contents of the /boot.py file on the memory card to determine what the device does when it is reset or rebooted. Notes: Memory cards must be formatted with a SPIFFS or FAT filesystem, not FAT32. FAT memory cards will have a mount point of /sd, while SPIFFS cards will appear as /flash. "},"get_started/how_to_read.html":{"url":"get_started/how_to_read.html","title":"How to read the documentation","keywords":"","body":"How to use (/read) this article correctly Just contact, you can look carefully from the top to the next page according to the directory on the left sidebar. Then learn how to update the firmware, how to write code Every module's doc contains examples at the end of page, you can try it out ~ Finally, the interface and parameters of the module are consulted according to their own needs during use. There is a search box in the upper left corner, which can be used well. You can also use the browser's page search function, ie press Ctrl+F, then enter the content to search and press the enter key If you can't find anything, please don't worry, you can go to github's issue (document issue, code issue) Is there any mention of the page (/search)? If you don't have one, you can create a new issue or contact technical support. If pages load slowly, refresh or just wait, or change your network Doc pages generated by gitbook, there may be some error occur when click too fast but network speed not enough, just take care of the url( path ), for example: Wrong url: http://localhost:4000/zh/zh/get_started/how_to_read.html Correct url: http://localhost:4000/zh/get_started/how_to_read.html so just change the wrong url, or just back to (maixpy.sipeed.com) refresh page "},"libs/standard/":{"url":"libs/standard/","title":"Standard library","keywords":"","body":"standard libs cmath gc math sys ubinascii ucollections uctypes uerrno uheapq ujson uos ure uselect ustruct utime uzlib "},"libs/standard/cmath.html":{"url":"libs/standard/cmath.html","title":"cmath","keywords":"","body":"cmath – mathematical functions for complex numbers This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: cmath. The cmath module provides some basic mathematical functions for working with complex numbers. Availability: not available on WiPy and ESP8266. Floating point support required for this module. Functions cos cmath.cos(z) Return the cosine of z. exp cmath.exp(z) Return the exponential of z. log cmath.log(z) Return the natural logarithm of z. The branch cut is along the negative real axis. log10 cmath.log10(z) Return the base-10 logarithm of z. The branch cut is along the negative real axis. phase cmath.phase(z) Returns the phase of the number z, in the range (-pi, +pi]. polar cmath.polar(z) Returns, as a tuple, the polar form of z. rect cmath.rect(r, phi) Returns the complex number with modulus r and phase phi. sin cmath.sin(z) Return the sine of z. sqrt cmath.sqrt(z) Return the square-root of z. Constants cmath.e base of the natural logarithm cmath.pi the ratio of a circle’s circumference to its diameter "},"libs/standard/gc.html":{"url":"libs/standard/gc.html","title":"gc","keywords":"","body":"gc – control the garbage collector This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: gc. Functions gc.enable() Enable automatic garbage collection. gc.disable() Disable automatic garbage collection. Heap memory can still be allocated, and garbage collection can still be initiated manually using gc.collect(). gc.collect() Run a garbage collection. gc.mem_alloc() Return the number of bytes of heap RAM that are allocated. Difference to CPython This function is MicroPython extension. gc.mem_free() Return the number of bytes of available heap RAM, or -1 if this amount is not known. Difference to CPython This function is MicroPython extension. gc.threshold([amount]) Set or query the additional GC allocation threshold. Normally, a collection is triggered only when a new allocation cannot be satisfied, i.e. on an out-of-memory (OOM) condition. If this function is called, in addition to OOM, a collection will be triggered each time after amount bytes have been allocated (in total, since the previous time such an amount of bytes have been allocated). amount is usually specified as less than the full heap size, with the intention to trigger a collection earlier than when the heap becomes exhausted, and in the hope that an early collection will prevent excessive memory fragmentation. This is a heuristic measure, the effect of which will vary from application to application, as well as the optimal value of the amount parameter. Calling the function without argument will return the current value of the threshold. A value of -1 means a disabled allocation threshold. Difference to CPython This function is a MicroPython extension. CPython has a similar function - set_threshold(), but due to different GC implementations, its signature and semantics are different. "},"libs/standard/math.html":{"url":"libs/standard/math.html","title":"math","keywords":"","body":"math – mathematical functions This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: math. The math module provides some basic mathematical functions for working with floating-point numbers. Note: On the pyboard, floating-point numbers have 32-bit precision. Availability: not available on WiPy. Floating point support required for this module. Functions math.acos(x) Return the inverse cosine of x. math.acosh(x) Return the inverse hyperbolic cosine of x. math.asin(x) Return the inverse sine of x. math.asinh(x) Return the inverse hyperbolic sine of x. math.atan(x) Return the inverse tangent of x. math.atan2(y, x) Return the principal value of the inverse tangent of y/x. math.atanh(x) Return the inverse hyperbolic tangent of x. math.ceil(x) Return an integer, being x rounded towards positive infinity. math.copysign(x, y) Return x with the sign of y. math.cos(x) Return the cosine of x. math.cosh(x) Return the hyperbolic cosine of x. math.degrees(x) Return radians x converted to degrees. math.erf(x) Return the error function of x. math.erfc(x) Return the complementary error function of x. math.exp(x) Return the exponential of x. math.expm1(x) Return exp(x) - 1. math.fabs(x) Return the absolute value of x. math.floor(x) Return an integer, being x rounded towards negative infinity. math.fmod(x, y) Return the remainder of x/y. math.frexp(x) Decomposes a floating-point number into its mantissa and exponent. The returned value is the tuple (m, e) such that x == m * 2**e exactly. If x == 0 then the function returns (0.0, 0), otherwise the relation 0.5 holds. math.gamma(x) Return the gamma function of x. math.isfinite(x) Return True if x is finite. math.isinf(x) Return True if x is infinite. math.isnan(x) Return True if x is not-a-number math.ldexp(x, exp) Return x * (2**exp). math.lgamma(x) Return the natural logarithm of the gamma function of x. math.log(x) Return the natural logarithm of x. math.log10(x) Return the base-10 logarithm of x. math.log2(x) Return the base-2 logarithm of x. math.modf(x) Return a tuple of two floats, being the fractional and integral parts of x. Both return values have the same sign as x. math.pow(x, y) Returns x to the power of y. math.radians(x) Return degrees x converted to radians. math.sin(x) Return the sine of x. math.sinh(x) Return the hyperbolic sine of x. math.sqrt(x) Return the square root of x. math.tan(x) Return the tangent of x. math.tanh(x) Return the hyperbolic tangent of x. math.trunc(x) Return an integer, being x rounded towards 0. Constants math.e base of the natural logarithm math.pi the ratio of a circle’s circumference to its diameter "},"libs/standard/sys.html":{"url":"libs/standard/sys.html","title":"sys","keywords":"","body":"sys – system specific functions This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: sys. Functions sys.exit(retval=0) Terminate current program with a given exit code. Underlyingly, this function raise as SystemExit exception. If an argument is given, its value given as an argument to SystemExit. sys.print_exception(exc, file=sys.stdout) Print exception with a traceback to a file-like object file (or sys.stdout by default). Difference to CPython This is simplified version of a function which appears in the traceback module in CPython. Unlike traceback.print_exception(), this function takes just exception value instead of exception type, exception value, and traceback object; file argument should be positional; further arguments are not supported. CPython-compatible traceback module can be found in micropython-lib. Constants sys.argv A mutable list of arguments the current program was started with. sys.byteorder The byte order of the system (\"little\" or \"big\"). sys.implementation Object with information about the current Python implementation. For MicroPython, it has following attributes: name - string “micropython” version - tuple (major, minor, micro), e.g. (1, 7, 0) This object is the recommended way to distinguish MicroPython from other Python implementations (note that it still may not exist in the very minimal ports). Difference to CPython CPython mandates more attributes for this object, but the actual useful bare minimum is implemented in MicroPython. sys.maxsize Maximum value which a native integer type can hold on the current platform, or maximum value representable by MicroPython integer type, if it’s smaller than platform max value (that is the case for MicroPython ports without long int support). This attribute is useful for detecting “bitness” of a platform (32-bit vs 64-bit, etc.). It’s recommended to not compare this attribute to some value directly, but instead count number of bits in it: bits = 0 v = sys.maxsize while v: bits += 1 v >>= 1 if bits > 32: # 64-bit (or more) platform ... else: # 32-bit (or less) platform # Note that on 32-bit platform, value of bits may be less than 32 # (e.g. 31) due to peculiarities described above, so use \"> 16\", # \"> 32\", \"> 64\" style of comparisons. sys.modules Dictionary of loaded modules. On some ports, it may not include builtin modules. sys.path A mutable list of directories to search for imported modules. sys.platform The platform that MicroPython is running on. For OS/RTOS ports, this is usually an identifier of the OS, e.g. \"linux\". For baremetal ports it is an identifier of a board, e.g. \"pyboard\" for the original MicroPython reference board. It thus can be used to distinguish one board from another. If you need to check whether your program runs on MicroPython (vs other Python implementation), use sys.implementation instead. sys.stderr Standard error stream. sys.stdin Standard input stream. sys.stdout Standard output stream. sys.version Python language version that this implementation conforms to, as a string. sys.version_info Python language version that this implementation conforms to, as a tuple of ints. "},"libs/standard/ubinascii.html":{"url":"libs/standard/ubinascii.html","title":"ubinascii","keywords":"","body":"ubinascii – binary/ASCII conversions This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: binascii. This module implements conversions between binary data and various encodings of it in ASCII form (in both directions). Functions ubinascii.hexlify(data[, sep]) Convert binary data to hexadecimal representation. Returns bytes string. Difference to CPython If additional argument, sep is supplied, it is used as a separator between hexadecimal values. ubinascii.unhexlify(data) Convert hexadecimal data to binary representation. Returns bytes string. (i.e. inverse of hexlify) ubinascii.a2b_base64(data) Decode base64-encoded data, ignoring invalid characters in the input. Conforms to RFC 2045 s.6.8. Returns a bytes object. ubinascii.b2a_base64(data) Encode binary data in base64 format, as in RFC 3548. Returns the encoded data followed by a newline character, as a bytes object. "},"libs/standard/ucollections.html":{"url":"libs/standard/ucollections.html","title":"ucollections","keywords":"","body":"ucollections – collection and container types This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: collections. This module implements advanced collection and container types to hold/accumulate various objects. Classes ucollections.deque(iterable, maxlen[, flags]) Deques (double-ended queues) are a list-like container that support O(1) appends and pops from either side of the deque. New deques are created using the following arguments: iterable must be the empty tuple, and the new deque is created empty. maxlen must be specified and the deque will be bounded to this maximum length. Once the deque is full, any new items added will discard items from the opposite end. The optional flags can be 1 to check for overflow when adding items. As well as supporting bool and len, deque objects have the following methods: deque.append(x) Add x to the right side of the deque. Raises IndexError if overflow checking is enabled and there is no more room left. deque.popleft() Remove and return an item from the left side of the deque. Raises IndexError if no items are present. ucollections.namedtuple(name, fields) This is factory function to create a new namedtuple type with a specific name and set of fields. A namedtuple is a subclass of tuple which allows to access its fields not just by numeric index, but also with an attribute access syntax using symbolic field names. Fields is a sequence of strings specifying field names. For compatibility with CPython it can also be a a string with space-separated field named (but this is less efficient). Example of use: from ucollections import namedtuple MyTuple = namedtuple(\"MyTuple\", (\"id\", \"name\")) t1 = MyTuple(1, \"foo\") t2 = MyTuple(2, \"bar\") print(t1.name) assert t2.name == t2[1] ucollections.OrderedDict(...) dict type subclass which remembers and preserves the order of keys added. When ordered dict is iterated over, keys/items are returned in the order they were added: from ucollections import OrderedDict # To make benefit of ordered keys, OrderedDict should be initialized # from sequence of (key, value) pairs. d = OrderedDict([(\"z\", 1), (\"a\", 2)]) # More items can be added as usual d[\"w\"] = 5 d[\"b\"] = 3 for k, v in d.items(): print(k, v) Output: z 1 a 2 w 5 b 3 "},"libs/standard/uctypes.html":{"url":"libs/standard/uctypes.html","title":"uctypes","keywords":"","body":"uctypes – access binary data in a structured way This module implements “foreign data interface” for MicroPython. The idea behind it is similar to CPython’s ctypes modules, but the actual API is different, streamlined and optimized for small size. The basic idea of the module is to define data structure layout with about the same power as the C language allows, and then access it using familiar dot-syntax to reference sub-fields. Warning uctypes module allows access to arbitrary memory addresses of the machine (including I/O and control registers). Uncareful usage of it may lead to crashes, data loss, and even hardware malfunction. See also Module ustruct Standard Python way to access binary data structures (doesn’t scale well to large and complex structures). Usage examples: import uctypes # Example 1: Subset of ELF file header # https://wikipedia.org/wiki/Executable_and_Linkable_Format#File_header ELF_HEADER = { \"EI_MAG\": (0x0 | uctypes.ARRAY, 4 | uctypes.UINT8), \"EI_DATA\": 0x5 | uctypes.UINT8, \"e_machine\": 0x12 | uctypes.UINT16, } # \"f\" is an ELF file opened in binary mode buf = f.read(uctypes.sizeof(ELF_HEADER, uctypes.LITTLE_ENDIAN)) header = uctypes.struct(uctypes.addressof(buf), ELF_HEADER, uctypes.LITTLE_ENDIAN) assert header.EI_MAG == b\"\\x7fELF\" assert header.EI_DATA == 1, \"Oops, wrong endianness. Could retry with uctypes.BIG_ENDIAN.\" print(\"machine:\", hex(header.e_machine)) # Example 2: In-memory data structure, with pointers COORD = { \"x\": 0 | uctypes.FLOAT32, \"y\": 4 | uctypes.FLOAT32, } STRUCT1 = { \"data1\": 0 | uctypes.UINT8, \"data2\": 4 | uctypes.UINT32, \"ptr\": (8 | uctypes.PTR, COORD), } # Suppose you have address of a structure of type STRUCT1 in \"addr\" # uctypes.NATIVE is optional (used by default) struct1 = uctypes.struct(addr, STRUCT1, uctypes.NATIVE) print(\"x:\", struct1.ptr[0].x) # Example 3: Access to CPU registers. Subset of STM32F4xx WWDG block WWDG_LAYOUT = { \"WWDG_CR\": (0, { # BFUINT32 here means size of the WWDG_CR register \"WDGA\": 7 Defining structure layout Structure layout is defined by a “descriptor” - a Python dictionary which encodes field names as keys and other properties required to access them as associated values: { \"field1\": , \"field2\": , ... } Currently, uctypes requires explicit specification of offsets for each field. Offset are given in bytes from the structure start. Following are encoding examples for various field types: Scalar types: \"field_name\": offset | uctypes.UINT32 in other words, the value is a scalar type identifier ORed with a field offset (in bytes) from the start of the structure. Recursive structures: \"sub\": (offset, { \"b0\": 0 | uctypes.UINT8, \"b1\": 1 | uctypes.UINT8, }) i.e. value is a 2-tuple, first element of which is an offset, and second is a structure descriptor dictionary (note: offsets in recursive descriptors are relative to the structure it defines). Of course, recursive structures can be specified not just by a literal dictionary, but by referring to a structure descriptor dictionary (defined earlier) by name. Arrays of primitive types: \"arr\": (offset | uctypes.ARRAY, size | uctypes.UINT8), i.e. value is a 2-tuple, first element of which is ARRAY flag ORed with offset, and second is scalar element type ORed number of elements in the array. Arrays of aggregate types: \"arr2\": (offset | uctypes.ARRAY, size, {\"b\": 0 | uctypes.UINT8}), i.e. value is a 3-tuple, first element of which is ARRAY flag ORed with offset, second is a number of elements in the array, and third is a descriptor of element type. Pointer to a primitive type: \"ptr\": (offset | uctypes.PTR, uctypes.UINT8), i.e. value is a 2-tuple, first element of which is PTR flag ORed with offset, and second is a scalar element type. Pointer to an aggregate type: \"ptr2\": (offset | uctypes.PTR, {\"b\": 0 | uctypes.UINT8}), i.e. value is a 2-tuple, first element of which is PTR flag ORed with offset, second is a descriptor of type pointed to. Bitfields: \"bitf0\": offset | uctypes.BFUINT16 | lsbit i.e. value is a type of scalar value containing given bitfield (typenames are similar to scalar types, but prefixes with BF), ORed with offset for scalar value containing the bitfield, and further ORed with values for bit position and bit length of the bitfield within the scalar value, shifted by BF_POS and BF_LEN bits, respectively. A bitfield position is counted from the least significant bit of the scalar (having position of 0), and is the number of right-most bit of a field (in other words, it’s a number of bits a scalar needs to be shifted right to extract the bitfield). In the example above, first a UINT16 value will be extracted at offset 0 (this detail may be important when accessing hardware registers, where particular access size and alignment are required), and then bitfield whose rightmost bit is lsbit bit of this UINT16, and length is bitsize bits, will be extracted. For example, if lsbit is 0 and bitsize is 8, then effectively it will access least-significant byte of UINT16. Note that bitfield operations are independent of target byte endianness, in particular, example above will access least-significant byte of UINT16 in both little- and big-endian structures. But it depends on the least significant bit being numbered 0. Some targets may use different numbering in their native ABI, but uctypes always uses the normalized numbering described above. Module contents class uctypes.struct(addr, descriptor, layout_type=NATIVE) Instantiate a “foreign data structure” object based on structure address in memory, descriptor (encoded as a dictionary), and layout type (see below). uctypes.LITTLE_ENDIAN Layout type for a little-endian packed structure. (Packed means that every field occupies exactly as many bytes as defined in the descriptor, i.e. the alignment is 1). uctypes.BIG_ENDIAN Layout type for a big-endian packed structure. uctypes.NATIVE Layout type for a native structure - with data endianness and alignment conforming to the ABI of the system on which MicroPython runs. uctypes.sizeof(struct, layout_type=NATIVE) Return size of data structure in bytes. The struct argument can be either a structure class or a specific instantiated structure object (or its aggregate field). uctypes.addressof(obj) Return address of an object. Argument should be bytes, bytearray or other object supporting buffer protocol (and address of this buffer is what actually returned). uctypes.bytes_at(addr, size) Capture memory at the given address and size as bytes object. As bytes object is immutable, memory is actually duplicated and copied into bytes object, so if memory contents change later, created object retains original value. uctypes.bytearray_at(addr, size) Capture memory at the given address and size as bytearray object. Unlike bytes_at() function above, memory is captured by reference, so it can be both written too, and you will access current value at the given memory address. uctypes.UINT8 uctypes.INT8 uctypes.UINT16 uctypes.INT16 uctypes.UINT32 uctypes.INT32 uctypes.UINT64 uctypes.INT64 Integer types for structure descriptors. Constants for 8, 16, 32, and 64 bit types are provided, both signed and unsigned. uctypes.FLOAT32 uctypes.FLOAT64 Floating-point types for structure descriptors. uctypes.VOID VOID is an alias for UINT8, and is provided to conviniently define C’s void pointers: (uctypes.PTR, uctypes.VOID). uctypes.PTR uctypes.ARRAY Type constants for pointers and arrays. Note that there is no explicit constant for structures, it’s implicit: an aggregate type without PTR or ARRAY flags is a structure. Structure descriptors and instantiating structure objects Given a structure descriptor dictionary and its layout type, you can instantiate a specific structure instance at a given memory address using uctypes.struct() constructor. Memory address usually comes from following sources: Predefined address, when accessing hardware registers on a baremetal system. Lookup these addresses in datasheet for a particular MCU/SoC. As a return value from a call to some FFI (Foreign Function Interface) function. From uctypes.addressof(), when you want to pass arguments to an FFI function, or alternatively, to access some data for I/O (for example, data read from a file or network socket). Structure objects Structure objects allow accessing individual fields using standard dot notation: my_struct.substruct1.field1. If a field is of scalar type, getting it will produce a primitive value (Python integer or float) corresponding to the value contained in a field. A scalar field can also be assigned to. If a field is an array, its individual elements can be accessed with the standard subscript operator [] - both read and assigned to. If a field is a pointer, it can be dereferenced using [0] syntax (corresponding to C * operator, though [0] works in C too). Subscripting a pointer with other integer values but 0 are also supported, with the same semantics as in C. Summing up, accessing structure fields generally follows the C syntax, except for pointer dereference, when you need to use [0] operator instead of *. Limitations Accessing non-scalar fields leads to allocation of intermediate objects to represent them. This means that special care should be taken to layout a structure which needs to be accessed when memory allocation is disabled (e.g. from an interrupt). The recommendations are: Avoid accessing nested structures. For example, instead of mcu_registers.peripheral_a.register1, define separate layout descriptors for each peripheral, to be accessed as peripheral_a.register1. Or just cache a particular peripheral: peripheral_a = mcu_registers.peripheral_a. If a register consists of multiple bitfields, you would need to cache references to a particular register: reg_a = mcu_registers.peripheral_a.reg_a. Avoid other non-scalar data, like arrays. For example, instead of peripheral_a.register[0] use peripheral_a.register0. Again, an alternative is to cache intermediate values, e.g. register0 = peripheral_a.register[0]. Range of offsets supported by the uctypes module is limited. The exact range supported is considered an implementation detail, and the general suggestion is to split structure definitions to cover from a few kilobytes to a few dozen of kilobytes maximum. In most cases, this is a natural situation anyway, e.g. it doesn’t make sense to define all registers of an MCU (spread over 32-bit address space) in one structure, but rather a peripheral block by peripheral block. In some extreme cases, you may need to split a structure in several parts artificially (e.g. if accessing native data structure with multi-megabyte array in the middle, though that would be a very synthetic case).) "},"libs/standard/uerrno.html":{"url":"libs/standard/uerrno.html","title":"uerrno","keywords":"","body":"uerrno — system error codes This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: errno. This module provides access to symbolic error codes for OSError exception. A particular inventory of codes depends on MicroPython port， Will explain the specific function that will cause an error. Constants EEXIST, EAGAIN, etc. Error codes, based on ANSI C/POSIX standard. All error codes start with “E”. As mentioned above, inventory of the codes depends on MicroPython port. Errors are usually accessible as exc.args[0] where exc is an instance of OSError. Usage example: try: uos.mkdir(\"my_dir\") except OSError as exc: if exc.args[0] == uerrno.EEXIST: print(\"Directory already exists\") uerrno.errorcode Dictionary mapping numeric error codes to strings with symbolic error code (see above): >>> print(uerrno.errorcode[uerrno.EEXIST]) EEXIST "},"libs/standard/uheapq.html":{"url":"libs/standard/uheapq.html","title":"uheapq","keywords":"","body":"uheapq – heap queue algorithm This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: heapq. This module implements the heap queue algorithm. A heap queue is simply a list that has its elements stored in a certain way. Functions heappush uheapq.heappush(heap, item) Push the item onto the heap. heappop uheapq.heappop(heap) Pop the first item from the heap, and return it. Raises IndexError if heap is empty. heapify uheapq.heapify(x) Convert the list x into a heap. This is an in-place operation. "},"libs/standard/ujson.html":{"url":"libs/standard/ujson.html","title":"ujson","keywords":"","body":"ujson – JSON encoding and decoding This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: json. This modules allows to convert between Python objects and the JSON data format. Functions dump ujson.dump(obj, stream) Serialise obj to a JSON string, writing it to the given stream. dumps ujson.dumps(obj) Return obj represented as a JSON string. load ujson.load(stream) Parse the given stream, interpreting it as a JSON string and deserialising the data to a Python object. The resulting object is returned. Parsing continues until end-of-file is encountered. A ValueError is raised if the data in stream is not correctly formed. loads ujson.loads(str) Parse the JSON str and return an object. Raises ValueError if the string is not correctly formed. "},"libs/standard/uos.html":{"url":"libs/standard/uos.html","title":"uos","keywords":"","body":"uos – basic “operating system” services This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: os. The uos module contains functions for filesystem access and mounting, terminal redirection and duplication, and the uname and urandom functions. General functions uos.uname() Return a tuple (possibly a named tuple) containing information about the underlying machine and/or its operating system. The tuple has five fields in the following order, each of them being a string: sysname – the name of the underlying system nodename – the network name (can be the same as sysname) release – the version of the underlying system version – the MicroPython version and build date machine – an identifier for the underlying hardware (eg board, CPU) uos.urandom(n) Return a bytes object with n random bytes. Whenever possible, it is generated by the hardware random number generator. Filesystem access uos.chdir(path) Change current directory. uos.getcwd() Get the current directory. uos.ilistdir([dir]) This function returns an iterator which then yields tuples corresponding to the entries in the directory that it is listing. With no argument it lists the current directory, otherwise it lists the directory given by dir. The tuples have the form (name, type, inode[, size]): name is a string (or bytes if dir is a bytes object) and is the name of the entry; type is an integer that specifies the type of the entry, with 0x4000 for directories and 0x8000 for regular files; inode is an integer corresponding to the inode of the file, and may be 0 for filesystems that don’t have such a notion. Some platforms may return a 4-tuple that includes the entry’s size. For file entries, size is an integer representing the size of the file or -1 if unknown. Its meaning is currently undefined for directory entries. uos.listdir([dir]) With no argument, list the current directory. Otherwise list the given directory. uos.mkdir(path) Create a new directory. uos.remove(path) Remove a file. uos.rmdir(path) Remove a directory. uos.rename(old_path, new_path) Rename a file. uos.stat(path) Get the status of a file or directory. uos.statvfs(path) Get the status of a fileystem. Returns a tuple with the filesystem information in the following order: f_bsize – file system block size f_frsize – fragment size f_blocks – size of fs in f_frsize units f_bfree – number of free blocks f_bavail – number of free blocks for unpriviliged users f_files – number of inodes f_ffree – number of free inodes f_favail – number of free inodes for unpriviliged users f_flag – mount flags f_namemax – maximum filename length Parameters related to inodes: f_files, f_ffree, f_avail and the f_flags parameter may return 0 as they can be unavailable in a port-specific implementation. uos.sync() Sync all filesystems. Terminal redirection and duplication uos.dupterm(stream_object, index=0) Duplicate or switch the MicroPython terminal (the REPL) on the given stream-like object. The stream_object argument must implement the readinto() and write() methods. The stream should be in non-blocking mode and readinto() should return None if there is no data available for reading. After calling this function all terminal output is repeated on this stream, and any input that is available on the stream is passed on to the terminal input. The index parameter should be a non-negative integer and specifies which duplication slot is set. A given port may implement more than one slot (slot 0 will always be available) and in that case terminal input and output is duplicated on all the slots that are set. If None is passed as the stream_object then duplication is cancelled on the slot given by index. The function returns the previous stream-like object in the given slot. Filesystem mounting Some ports provide a Virtual Filesystem (VFS) and the ability to mount multiple “real” filesystems within this VFS. Filesystem objects can be mounted at either the root of the VFS, or at a subdirectory that lives in the root. This allows dynamic and flexible configuration of the filesystem that is seen by Python programs. Ports that have this functionality provide the mount() and umount() functions, and possibly various filesystem implementations represented by VFS classes. uos.mount(fsobj, mount_point, *, readonly) Mount the filesystem object fsobj at the location in the VFS given by the mount_point string. fsobj can be a a VFS object that has a mount() method, or a block device. If it’s a block device then the filesystem type is automatically detected (an exception is raised if no filesystem was recognised). mount_point may be '/' to mount fsobj at the root, or '/' to mount it at a subdirectory under the root. If readonly is True then the filesystem is mounted read-only. During the mount process the method mount() is called on the filesystem object. Will raise OSError(EPERM) if mount_point is already mounted. uos.umount(mount_point) Unmount a filesystem. mount_point can be a string naming the mount location, or a previously-mounted filesystem object. During the unmount process the method umount() is called on the filesystem object. Will raise OSError(EINVAL) if mount_point is not found. class uos.VfsFat(block_dev) Create a filesystem object that uses the FAT filesystem format. Storage of the FAT filesystem is provided by block_dev. Objects created by this constructor can be mounted using mount(). static mkfs(block_dev) Build a FAT filesystem on block_dev. Block devices A block device is an object which implements the block protocol, which is a set of methods described below by the AbstractBlockDev class. A concrete implementation of this class will usually allow access to the memory-like functionality a piece of hardware (like flash memory). A block device can be used by a particular filesystem driver to store the data for its filesystem. class uos.AbstractBlockDev(...) Construct a block device object. The parameters to the constructor are dependent on the specific block device. readblocks(block_num, buf) Starting at the block given by the index block_num, read blocks from the device into buf (an array of bytes). The number of blocks to read is given by the length of buf, which will be a multiple of the block size. writeblocks(block_num, buf) Starting at the block given by the index block_num, write blocks from buf (an array of bytes) to the device. The number of blocks to write is given by the length of buf, which will be a multiple of the block size. ioctl(op, arg) Control the block device and query its parameters. The operation to perform is given by op which is one of the following integers: 1 – initialise the device (arg is unused) 2 – shutdown the device (arg is unused) 3 – sync the device (arg is unused) 4 – get a count of the number of blocks, should return an integer (arg is unused) 5 – get the number of bytes in a block, should return an integer, or None in which case the default value of 512 is used (arg is unused) By way of example, the following class will implement a block device that stores its data in RAM using a bytearray: class RAMBlockDev: def __init__(self, block_size, num_blocks): self.block_size = block_size self.data = bytearray(block_size * num_blocks) def readblocks(self, block_num, buf): for i in range(len(buf)): buf[i] = self.data[block_num * self.block_size + i] def writeblocks(self, block_num, buf): for i in range(len(buf)): self.data[block_num * self.block_size + i] = buf[i] def ioctl(self, op, arg): if op == 4: # get number of blocks return len(self.data) // self.block_size if op == 5: # get block size return self.block_size It can be used as follows: import uos bdev = RAMBlockDev(512, 50) uos.VfsFat.mkfs(bdev) vfs = uos.VfsFat(bdev) uos.mount(vfs, '/ramdisk') "},"libs/standard/ure.html":{"url":"libs/standard/ure.html","title":"ure","keywords":"","body":"ure – simple regular expressions This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: re. This module implements regular expression operations. Regular expression syntax supported is a subset of CPython re module (and actually is a subset of POSIX extended regular expressions). Supported operators and special sequences . : Match any character. [...] : Match set of characters. Individual characters and ranges are supported, including negated sets (e.g. [^a-c]). ^ : Match the start of the string. $ : Match the end of the string. ? : Match zero or one of the previous sub-pattern. * : Match zero or more of the previous sub-pattern. + : Match one or more of the previous sub-pattern. ?? : Non-greedy version of ?, match zero or one, with the preference for zero. *? : Non-greedy version of *, match zero or more, with the preference for the shortest match. +? : Non-greedy version of +, match one or more, with the preference for the shortest match. | : Match either the left-hand side or the right-hand side sub-patterns of this operator. (...) : Grouping. Each group is capturing (a substring it captures can be accessed with match.group() method). \\d : Matches digit. Equivalent to [0-9]. \\D : Matches non-digit. Equivalent to [^0-9]. \\s : Matches whitespace. Equivalent to [ \\t-\\r]. \\S : Matches non-whitespace. Equivalent to [^ \\t-\\r]. \\w : Matches “word characters” (ASCII only). Equivalent to [A-Za-z0-9_]. \\W : Matches non “word characters” (ASCII only). Equivalent to [^A-Za-z0-9_]. \\ : Escape character. Any other character following the backslash, except for those listed above, is taken literally. For example, \\* is equivalent to literal * (not treated as the * operator). Note that \\r, \\n, etc. are not handled specially, and will be equivalent to literal letters r, n, etc. Due to this, it’s not recommended to use raw Python strings (r\"\") for regular expressions. For example, r\"\\r\\n\" when used as the regular expression is equivalent to \"rn\". To match CR character followed by LF, use \"\\r\\n\". NOT SUPPORTED: counted repetitions ({m,n}) named groups ((?P...)) non-capturing groups ((?:...)) more advanced assertions (\\b, \\B) special character escapes like \\r, \\n - use Python’s own escaping instead etc. Example: import ure # As ure doesn't support escapes itself, use of r\"\" strings is not # recommended. regex = ure.compile(\"[\\r\\n]\") regex.split(\"line1\\rline2\\nline3\\r\\n\") # Result: # ['line1', 'line2', 'line3', '', ''] Functions ure.compile(regex_str[, flags]) Compile regular expression, return regex object. ure.match(regex_str, string) Compile regex_str and match against string. Match always happens from starting position in a string. ure.search(regex_str, string) Compile regex_str and search it in a string. Unlike match, this will search string for first position which matches regex (which still may be 0 if regex is anchored). ure.sub(regex_str, replace, string, count=0, flags=0) Compile regex_str and search for it in string, replacing all matches with replace, and returning the new string. replace can be a string or a function. If it is a string then escape sequences of the form \\ and \\g can be used to expand to the corresponding group (or an empty string for unmatched groups). If replace is a function then it must take a single argument (the match) and should return a replacement string. If count is specified and non-zero then substitution will stop after this many substitutions are made. The flags argument is ignored. Note: availability of this function depends on MicroPython port. ure.DEBUG Flag value, display debug information about compiled expression. (Availability depends on MicroPython port.) Regex objects Compiled regular expression. Instances of this class are created using ure.compile(). regex.match(string) regex.search(string) regex.sub(replace, string, count=0, flags=0) Similar to the module-level functions match(), search() and sub(). Using methods is (much) more efficient if the same regex is applied to multiple strings. regex.split(string, max_split=-1) Split a string using regex. If max_split is given, it specifies maximum number of splits to perform. Returns list of strings (there may be up to max_split+1 elements if it’s specified). Match objects Match objects as returned by match() and search() methods, and passed to the replacement function in sub(). match.group(index) Return matching (sub)string. index is 0 for entire match, 1 and above for each capturing group. Only numeric groups are supported. match.groups() Return a tuple containing all the substrings of the groups of the match. Note: availability of this method depends on MicroPython port. match.start([index]) match.end([index]) Return the index in the original string of the start or end of the substring group that was matched. index defaults to the entire group, otherwise it will select a group. Note: availability of these methods depends on MicroPython port. match.span([index]) Returns the 2-tuple (match.start(index), match.end(index)). Note: availability of this method depends on MicroPython port. "},"libs/standard/uselect.html":{"url":"libs/standard/uselect.html","title":"uselect","keywords":"","body":""},"libs/standard/usocket.html":{"url":"libs/standard/usocket.html","title":"usocket","keywords":"","body":"usocket – socket module This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: socket. This module provides access to the BSD socket interface. Difference to CPython For efficiency and consistency, socket objects in MicroPython implement a stream (file-like) interface directly. In CPython, you need to convert a socket to a file-like object using makefile() method. This method is still supported by MicroPython (but is a no-op), so where compatibility with CPython matters, be sure to use it. Socket address format(s) The native socket address format of the usocket module is an opaque data type returned by getaddrinfo function, which must be used to resolve textual address (including numeric addresses): sockaddr = usocket.getaddrinfo('www.micropython.org', 80)[0][-1] # You must use getaddrinfo() even for numeric addresses sockaddr = usocket.getaddrinfo('127.0.0.1', 80)[0][-1] # Now you can use that address sock.connect(addr) Using getaddrinfo is the most efficient (both in terms of memory and processing power) and portable way to work with addresses. However, socket module (note the difference with native MicroPython usocket module described here) provides CPython-compatible way to specify addresses using tuples, as described below. Note that depending on a MicroPython port, socket module can be builtin or need to be installed from micropython-lib (as in the case of MicroPython Unix port), and some ports still accept only numeric addresses in the tuple format, and require to use getaddrinfo function to resolve domain names. Summing up: Always use getaddrinfo when writing portable applications. Tuple addresses described below can be used as a shortcut for quick hacks and interactive use, if your port supports them. Tuple address format for socket module: IPv4: (ipv4_address, port), where ipv4_address is a string with dot-notation numeric IPv4 address, e.g. \"8.8.8.8\", and port is and integer port number in the range 1-65535. Note the domain names are not accepted as ipv4_address, they should be resolved first using usocket.getaddrinfo(). IPv6: (ipv6_address, port, flowinfo, scopeid), where ipv6_address is a string with colon-notation numeric IPv6 address, e.g. \"2001:db8::1\", and port is an integer port number in the range 1-65535. flowinfo must be 0. scopeid is the interface scope identifier for link-local addresses. Note the domain names are not accepted as ipv6_address, they should be resolved first using usocket.getaddrinfo(). Availability of IPv6 support depends on a MicroPython port. Functions usocket.socket(af=AF_INET, type=SOCK_STREAM, proto=IPPROTO_TCP) Create a new socket using the given address family, socket type and protocol number. Note that specifying proto in most cases is not required (and not recommended, as some MicroPython ports may omit IPPROTO_* constants). Instead, type argument will select needed protocol automatically: # Create STREAM TCP socket socket(AF_INET, SOCK_STREAM) # Create DGRAM UDP socket socket(AF_INET, SOCK_DGRAM) usocket.getaddrinfo(host, port, af=0, type=0, proto=0, flags=0) Translate the host/port argument into a sequence of 5-tuples that contain all the necessary arguments for creating a socket connected to that service. Arguments af, type, and proto (which have the same meaning as for the socket() function) can be used to filter which kind of addresses are returned. If a parameter is not specified or zero, all combinations of addresses can be returned (requiring filtering on the user side). The resulting list of 5-tuples has the following structure: (family, type, proto, canonname, sockaddr) The following example shows how to connect to a given url: s = usocket.socket() # This assumes that if \"type\" is not specified, an address for # SOCK_STREAM will be returned, which may be not true s.connect(usocket.getaddrinfo('www.micropython.org', 80)[0][-1]) Recommended use of filtering params: s = usocket.socket() # Guaranteed to return an address which can be connect'ed to for # stream operation. s.connect(usocket.getaddrinfo('www.micropython.org', 80, 0, SOCK_STREAM)[0][-1]) Difference to CPython CPython raises a socket.gaierror exception (OSError subclass) in case of error in this function. MicroPython doesn’t have socket.gaierror and raises OSError directly. Note that error numbers of getaddrinfo() form a separate namespace and may not match error numbers from the uerrno module. To distinguish getaddrinfo() errors, they are represented by negative numbers, whereas standard system errors are positive numbers (error numbers are accessible using e.args[0] property from an exception object). The use of negative values is a provisional detail which may change in the future. usocket.inet_ntop(af, bin_addr) Convert a binary network address bin_addr of the given address family af to a textual representation: >>> usocket.inet_ntop(usocket.AF_INET, b\"\\x7f\\0\\0\\1\") '127.0.0.1' usocket.inet_pton(af, txt_addr) Convert a textual network address txt_addr of the given address family af to a binary representation: >>> usocket.inet_pton(usocket.AF_INET, \"1.2.3.4\") b'\\x01\\x02\\x03\\x04' Constants usocket.AF_INET usocket.AF_INET6 Address family types. Availability depends on a particular MicroPython port. usocket.SOCK_STREAM usocket.SOCK_DGRAM Socket types. usocket.IPPROTO_UDP usocket.IPPROTO_TCP IP protocol numbers. Availability depends on a particular MicroPython port. Note that you don’t need to specify these in a call to usocket.socket(), because SOCK_STREAM socket type automatically selects IPPROTO_TCP, and SOCK_DGRAM - IPPROTO_UDP. Thus, the only real use of these constants is as an argument to setsockopt(). usocket.SOL_* Socket option levels (an argument to setsockopt()). The exact inventory depends on a MicroPython port. usocket.SO_* Socket options (an argument to setsockopt()). The exact inventory depends on a MicroPython port. Constants specific to WiPy: usocket.IPPROTO_SEC Special protocol value to create SSL-compatible socket. class socket Methods socket.close() Mark the socket closed and release all resources. Once that happens, all future operations on the socket object will fail. The remote end will receive EOF indication if supported by protocol. Sockets are automatically closed when they are garbage-collected, but it is recommended to close() them explicitly as soon you finished working with them. socket.bind(address) Bind the socket to address. The socket must not already be bound. socket.listen([backlog]) Enable a server to accept connections. If backlog is specified, it must be at least 0 (if it’s lower, it will be set to 0); and specifies the number of unaccepted connections that the system will allow before refusing new connections. If not specified, a default reasonable value is chosen. socket.accept() Accept a connection. The socket must be bound to an address and listening for connections. The return value is a pair (conn, address) where conn is a new socket object usable to send and receive data on the connection, and address is the address bound to the socket on the other end of the connection. socket.connect(address) Connect to a remote socket at address. socket.send(bytes) Send data to the socket. The socket must be connected to a remote socket. Returns number of bytes sent, which may be smaller than the length of data (“short write”). socket.sendall(bytes) Send all data to the socket. The socket must be connected to a remote socket. Unlike send(), this method will try to send all of data, by sending data chunk by chunk consecutively. The behavior of this method on non-blocking sockets is undefined. Due to this, on MicroPython, it’s recommended to use write() method instead, which has the same “no short writes” policy for blocking sockets, and will return number of bytes sent on non-blocking sockets. socket.recv(bufsize) Receive data from the socket. The return value is a bytes object representing the data received. The maximum amount of data to be received at once is specified by bufsize. socket.sendto(bytes, address) Send data to the socket. The socket should not be connected to a remote socket, since the destination socket is specified by address. socket.recvfrom(bufsize) Receive data from the socket. The return value is a pair (bytes, address) where bytes is a bytes object representing the data received and address is the address of the socket sending the data. socket.setsockopt(level, optname, value) Set the value of the given socket option. The needed symbolic constants are defined in the socket module (SO_* etc.). The value can be an integer or a bytes-like object representing a buffer. socket.settimeout(value) Note: Not every port supports this method, see below. Set a timeout on blocking socket operations. The value argument can be a nonnegative floating point number expressing seconds, or None. If a non-zero value is given, subsequent socket operations will raise an OSError exception if the timeout period value has elapsed before the operation has completed. If zero is given, the socket is put in non-blocking mode. If None is given, the socket is put in blocking mode. Not every MicroPython port supports this method. A more portable and generic solution is to use uselect.poll object. This allows to wait on multiple objects at the same time (and not just on sockets, but on generic stream objects which support polling). Example: # Instead of: s.settimeout(1.0) # time in seconds s.read(10) # may timeout # Use: poller = uselect.poll() poller.register(s, uselect.POLLIN) res = poller.poll(1000) # time in milliseconds if not res: # s is still not ready for input, i.e. operation timed out Difference to CPython CPython raises a socket.timeout exception in case of timeout, which is an OSError subclass. MicroPython raises an OSError directly instead. If you use except OSError: to catch the exception, your code will work both in MicroPython and CPython. socket.setblocking(flag) Set blocking or non-blocking mode of the socket: if flag is false, the socket is set to non-blocking, else to blocking mode. This method is a shorthand for certain settimeout() calls: sock.setblocking(True) is equivalent to sock.settimeout(None) sock.setblocking(False) is equivalent to sock.settimeout(0) socket.makefile(mode='rb', buffering=0) Return a file object associated with the socket. The exact returned type depends on the arguments given to makefile(). The support is limited to binary modes only (‘rb’, ‘wb’, and ‘rwb’). CPython’s arguments: encoding, errors and newline are not supported. Difference to CPython As MicroPython doesn’t support buffered streams, values of buffering parameter is ignored and treated as if it was 0 (unbuffered). Difference to CPython Closing the file object returned by makefile() WILL close the original socket as well. socket.read([size]) Read up to size bytes from the socket. Return a bytes object. If size is not given, it reads all data available from the socket until EOF; as such the method will not return until the socket is closed. This function tries to read as much data as requested (no “short reads”). This may be not possible with non-blocking socket though, and then less data will be returned. socket.readinto(buf[, nbytes]) Read bytes into the buf. If nbytes is specified then read at most that many bytes. Otherwise, read at most len(buf) bytes. Just as read(), this method follows “no short reads” policy. Return value: number of bytes read and stored into buf. socket.readline() Read a line, ending in a newline character. Return value: the line read. socket.write(buf) Write the buffer of bytes to the socket. This function will try to write all data to a socket (no “short writes”). This may be not possible with a non-blocking socket though, and returned value will be less than the length of buf. Return value: number of bytes written. exception usocket.error MicroPython does NOT have this exception. Difference to CPython CPython used to have a socket.error exception which is now deprecated, and is an alias of OSError. In MicroPython, use OSError directly. Demo Demo 1: Download picture and display on LCD attention set WiFi SSID and password first in code import socket import network import gc import os import lcd, image fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) fm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX) uart = machine.UART(machine.UART.UART2,115200,timeout=1000, read_buf_len=4096) nic=network.ESP8285(uart) nic.connect(\"Sipeed_2.4G\",\"------\") sock = socket.socket() addr = socket.getaddrinfo(\"dl.sipeed.com\", 80)[0][-1] sock.connect(addr) sock.send('''GET /MAIX/MaixPy/assets/Alice.bmp HTTP/1.1 Host: dl.sipeed.com cache-control: no-cache ''') img = b\"\" sock.settimeout(5) while True: data = sock.recv(4096) if len(data) == 0: break print(\"rcv:\", len(data)) img = img + data print(len(img)) img = img[img.find(b\"\\r\\n\\r\\n\")+4:] print(len(img)) print(\"save to /sd/Alice.bmp\") f = open(\"/sd/Alice.bmp\",\"wb\") f.write(img) f.close() print(\"save ok\") print(\"display\") img = image.Image(\"/sd/Alice.bmp\") lcd.init() lcd.display(img) Demo 2: Send picture import os import socket import network import gc fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) fm.register(board_info.WIFI_TX,fm.fpioa.UART2_RX) uart = machine.UART(machine.UART.UART2,115200,timeout=1000, read_buf_len=4096) nic=network.ESP8285(uart) nic.connect(\"Sipeed_2.4G\",\"-------\") addr = (\"192.168.0.183\", 3456) sock = socket.socket() sock.connect(addr) sock.settimeout(5) f = open(\"/sd/Alice.bmp\",\"rb\") while True: img = f.read(2048) if not img or (len(img) == 0): break sock.send(img) f.close() sock.close() "},"libs/standard/ustruct.html":{"url":"libs/standard/ustruct.html","title":"ustruct","keywords":"","body":"ustruct – pack and unpack primitive data types This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: struct. Supported size/byte order prefixes: @, , >, !. Supported format codes: b, B, h, H, i, I, l, L, q, Q, s, P, f, d (the latter 2 depending on the floating-point support). Functions calcsize ustruct.calcsize(fmt) Return the number of bytes needed to store the given fmt. pack ustruct.pack(fmt, v1, v2, ...) Pack the values v1, v2, … according to the format string fmt. The return value is a bytes object encoding the values. pack_into ustruct.pack_into(fmt, buffer, offset, v1, v2, ...) Pack the values v1, v2, … according to the format string fmt into a buffer starting at offset. offset may be negative to count from the end of buffer. unpack ustruct.unpack(fmt, data) Unpack from the data according to the format string fmt. The return value is a tuple of the unpacked values. unpack_from ustruct.unpack_from(fmt, data, offset=0) Unpack from the data starting at offset according to the format string fmt. offset may be negative to count from the end of buffer. The return value is a tuple of the unpacked values. "},"libs/standard/utime.html":{"url":"libs/standard/utime.html","title":"utime","keywords":"","body":"utime – time related functions This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: time. The utime module provides functions for getting the current time and date, measuring time intervals, and for delays. Time Epoch: Unix port uses standard for POSIX systems epoch of 1970-01-01 00:00:00 UTC. However, embedded ports use epoch of 2000-01-01 00:00:00 UTC. Maintaining actual calendar date/time: This requires a Real Time Clock (RTC). On systems with underlying OS (including some RTOS), an RTC may be implicit. Setting and maintaining actual calendar time is responsibility of OS/RTOS and is done outside of MicroPython, it just uses OS API to query date/time. On baremetal ports however system time depends on machine.RTC() object. The current calendar time may be set using machine.RTC().datetime(tuple) function, and maintained by following means: By a backup battery (which may be an additional, optional component for a particular board). Using networked time protocol (requires setup by a port/user). Set manually by a user on each power-up (many boards then maintain RTC time across hard resets, though some may require setting it again in such case). If actual calendar time is not maintained with a system/MicroPython RTC, functions below which require reference to current absolute time may behave not as expected. Functions utime.localtime([secs]) Convert a time expressed in seconds since the Epoch (see above) into an 8-tuple which contains: (year, month, mday, hour, minute, second, weekday, yearday) If secs is not provided or None, then the current time from the RTC is used. year includes the century (for example 2014). month is 1-12 mday is 1-31 hour is 0-23 minute is 0-59 second is 0-59 weekday is 0-6 for Mon-Sun yearday is 1-366 utime.mktime() This is inverse function of localtime. It’s argument is a full 8-tuple which expresses a time as per localtime. It returns an integer which is the number of seconds since Jan 1, 2000. utime.sleep(seconds) Sleep for the given number of seconds. Some boards may accept seconds as a floating-point number to sleep for a fractional number of seconds. Note that other boards may not accept a floating-point argument, for compatibility with them use sleep_ms() and sleep_us() functions. utime.sleep_ms(ms) Delay for given number of milliseconds, should be positive or 0. utime.sleep_us(us) Delay for given number of microseconds, should be positive or 0. utime.ticks_ms() Returns an increasing millisecond counter with an arbitrary reference point, that wraps around after some value. The wrap-around value is not explicitly exposed, but we will refer to it as TICKS_MAX to simplify discussion. Period of the values is TICKS_PERIOD = TICKS_MAX + 1. TICKS_PERIOD is guaranteed to be a power of two, but otherwise may differ from port to port. The same period value is used for all of ticks_ms(), ticks_us(), ticks_cpu() functions (for simplicity). Thus, these functions will return a value in range [0 .. TICKS_MAX], inclusive, total TICKS_PERIOD values. Note that only non-negative values are used. For the most part, you should treat values returned by these functions as opaque. The only operations available for them are ticks_diff() and ticks_add() functions described below. Note: Performing standard mathematical operations (+, -) or relational operators (, >=) directly on these value will lead to invalid result. Performing mathematical operations and then passing their results as arguments to ticks_diff() or ticks_add() will also lead to invalid results from the latter functions. utime.ticks_us() Just like ticks_ms() above, but in microseconds. utime.ticks_cpu() Similar to ticks_ms() and ticks_us(), but with the highest possible resolution in the system. This is usually CPU clocks, and that’s why the function is named that way. But it doesn’t have to be a CPU clock, some other timing source available in a system (e.g. high-resolution timer) can be used instead. The exact timing unit (resolution) of this function is not specified on utime module level, but documentation for a specific port may provide more specific information. This function is intended for very fine benchmarking or very tight real-time loops. Avoid using it in portable code. Availability: Not every port implements this function. utime.ticks_add(ticks, delta) Offset ticks value by a given number, which can be either positive or negative. Given a ticks value, this function allows to calculate ticks value delta ticks before or after it, following modular-arithmetic definition of tick values (see ticks_ms() above). ticks parameter must be a direct result of call to ticks_ms(), ticks_us(), or ticks_cpu() functions (or from previous call to ticks_add()). However, delta can be an arbitrary integer number or numeric expression. ticks_add() is useful for calculating deadlines for events/tasks. (Note: you must use ticks_diff() function to work with deadlines.) Examples: # Find out what ticks value there was 100ms ago print(ticks_add(time.ticks_ms(), -100)) # Calculate deadline for operation and test for it deadline = ticks_add(time.ticks_ms(), 200) while ticks_diff(deadline, time.ticks_ms()) > 0: do_a_little_of_something() # Find out TICKS_MAX used by this port print(ticks_add(0, -1)) utime.ticks_diff(ticks1, ticks2) Measure ticks difference between values returned from ticks_ms(), ticks_us(), or ticks_cpu() functions, as a signed value which may wrap around. The argument order is the same as for subtraction operator, ticks_diff(ticks1, ticks2) has the same meaning as ticks1 - ticks2. However, values returned by ticks_ms(), etc. functions may wrap around, so directly using subtraction on them will produce incorrect result. That is why ticks_diff() is needed, it implements modular (or more specifically, ring) arithmetics to produce correct result even for wrap-around values (as long as they not too distant inbetween, see below). The function returns signed value in the range [-TICKS_PERIOD/2 .. TICKS_PERIOD/2-1] (that’s a typical range definition for two’s-complement signed binary integers). If the result is negative, it means that ticks1 occurred earlier in time than ticks2. Otherwise, it means that ticks1 occurred after ticks2. This holds only if ticks1 and ticks2 are apart from each other for no more than TICKS_PERIOD/2-1 ticks. If that does not hold, incorrect result will be returned. Specifically, if two tick values are apart for TICKS_PERIOD/2-1 ticks, that value will be returned by the function. However, if TICKS_PERIOD/2 of real-time ticks has passed between them, the function will return -TICKS_PERIOD/2 instead, i.e. result value will wrap around to the negative range of possible values. Informal rationale of the constraints above: Suppose you are locked in a room with no means to monitor passing of time except a standard 12-notch clock. Then if you look at dial-plate now, and don’t look again for another 13 hours (e.g., if you fall for a long sleep), then once you finally look again, it may seem to you that only 1 hour has passed. To avoid this mistake, just look at the clock regularly. Your application should do the same. “Too long sleep” metaphor also maps directly to application behavior: don’t let your application run any single task for too long. Run tasks in steps, and do time-keeping inbetween. ticks_diff() is designed to accommodate various usage patterns, among them: Polling with timeout. In this case, the order of events is known, and you will deal only with positive results of ticks_diff(): # Wait for GPIO pin to be asserted, but at most 500us start = time.ticks_us() while pin.value() == 0: if time.ticks_diff(time.ticks_us(), start) > 500: raise TimeoutError Scheduling events. In this case, ticks_diff() result may be negative if an event is overdue: # This code snippet is not optimized now = time.ticks_ms() scheduled_time = task.scheduled_time() if ticks_diff(scheduled_time, now) > 0: print(\"Too early, let's nap\") sleep_ms(ticks_diff(scheduled_time, now)) task.run() elif ticks_diff(scheduled_time, now) == 0: print(\"Right at time!\") task.run() elif ticks_diff(scheduled_time, now) Note: Do not pass time() values to ticks_diff(), you should use normal mathematical operations on them. But note that time() may (and will) also overflow. This is known as https://en.wikipedia.org/wiki/Year_2038_problem . utime.time() Returns the number of seconds, as an integer, since the Epoch, assuming that underlying RTC is set and maintained as described above. If an RTC is not set, this function returns number of seconds since a port-specific reference point in time (for embedded boards without a battery-backed RTC, usually since power up or reset). If you want to develop portable MicroPython application, you should not rely on this function to provide higher than second precision. If you need higher precision, use ticks_ms() and ticks_us()functions, if you need calendar time, localtime() without an argument is a better choice. Difference to CPython In CPython, this function returns number of seconds since Unix epoch, 1970-01-01 00:00 UTC, as a floating-point, usually having microsecond precision. With MicroPython, only Unix port uses the same Epoch, and if floating-point precision allows, returns sub-second precision. Embedded hardware usually doesn’t have floating-point precision to represent both long time ranges and subsecond precision, so they use integer value with second precision. Some embedded hardware also lacks battery-powered RTC, so returns number of seconds since last power-up or from other relative, hardware-specific point (e.g. reset). "},"libs/standard/uzlib.html":{"url":"libs/standard/uzlib.html","title":"uzlib","keywords":"","body":"zlib — zlib decompression This module implements a subset of the corresponding CPython module, as described below. For more information, refer to the original CPython documentation: zlib. This module allows to decompress binary data compressed with DEFLATE algorithm (commonly used in zlib library and gzip archiver). Compression is not yet implemented. Functions decompress uzlib.decompress(data, wbits=0, bufsize=0) Return decompressed data as bytes. wbits is DEFLATE dictionary window size used during compression (8-15, the dictionary size is power of 2 of that value). Additionally, if value is positive, data is assumed to be zlib stream (with zlib header). Otherwise, if it’s negative, it’s assumed to be raw DEFLATE stream. bufsize parameter is for compatibility with CPython and is ignored. DecompIO class uzlib.DecompIO(stream, wbits=0) Create a stream wrapper which allows transparent decompression of compressed data in another stream. This allows to process compressed streams with data larger than available heap size. In addition to values described in decompress(), wbits may take values 24..31 (16 + 8..15), meaning that input stream has gzip header. Difference to CPython This class is MicroPython extension. It’s included on provisional basis and may be changed considerably or removed in later versions. "},"libs/machine/":{"url":"libs/machine/","title":"Machine","keywords":"","body":""},"libs/machine/i2c.html":{"url":"libs/machine/i2c.html","title":"I2C","keywords":"","body":"machine.I2C "},"libs/machine/pwm.html":{"url":"libs/machine/pwm.html","title":"PWM","keywords":"","body":"machine.PWM "},"libs/machine/spi.html":{"url":"libs/machine/spi.html","title":"SPI","keywords":"","body":"machine.SPI "},"libs/machine/timer.html":{"url":"libs/machine/timer.html","title":"Timer","keywords":"","body":"machine.Timer Hardware timers deal with timing of periods and events. Timers are perhaps the most flexible and heterogeneous kind of hardware in MCUs and SoCs, differently greatly from a model to a model. MicroPython’s Timer class defines a baseline operation of executing a callback with a given period (or once after some delay), and allow specific boards to define more non-standard behavior (which thus won’t be portable to other boards). Constructors class machine.Timer(id, channel, mode=Timer.MODE_ONE_SHOT, period=1000, unit=Timer.UNIT_MS, callback=None, arg=None, start=True, priority=1, div=0) Construct a new timer object of the given id. Parameters id: Timer ID, [0~2] (Timer.TIMER0~TIMER2) channel: Timer channel, [Timer.CHANNEL0~Timer.CHANNEL3] mode: Timer mode, MODE_ONE_SHOT or MODE_PERIODICor MODE_PWM period: Timer period, after period the callback will be invoke, (0,~). unit: unit of timer, default ms, Timer.UNIT_S or Timer.UNIT_MS or Timer.UNIT_US orTimer.UNIT_NS callback: Timer callback, two parameters, first is Timer, second is user param, see param parameter below. callback execute in interrupt, so don't stay too long in callback arg: Argument dilivered to callback start: If start instantly timer after init, True:start, False:not start, need call start() function. priority: interrupt priority, [1,7]. div: Timer clock divider,[0,255],default to 0. clk_timer = clk_pll0/2^(div+1) clk_timer*period(unit:s) should =1 Methods init Same to constructor Timer.init(id, channel, mode=Timer.MODE_ONE_SHOT, period=1000, unit=Timer.UNIT_MS, callback=None, arg=None, start=True, priority=1, div=0) callback_arg callback arg of timer obj callback Get or set callback e.g. def on_timer(timer,param): print(\"time up:\",timer) print(\"param:\",timer.callback_arg()) tim.callback(on_timer) print(on_timer, tim.callback()) period Get or set period e.g. tim.period(2000) print( tim.period() ) start Start timer e.g. tim.start() stop Stop timer restart Restart timer deinit/del Deinitialises the timer. Stops the timer, and disables the timer peripheral. e.g. tim.deinit() or del tim Constants TIMER0: Timer0 id TIMER1: Timer1 id TIMER2: Timer2 id CHANNEL0: Timer channel 0 CHANNEL1: Timer channel 1 CHANNEL2: Timer channel 2 CHANNEL3: Timer channel 3 MODE_ONE_SHOT: Timer only run once MODE_PERIODIC: Timer always run MODE_PWM: Timer used by PWM UNIT_S: unit flag (s) UNIT_MS: unit flag (ms) UNIT_US: unit flag (us) UNIT_NS: unit flag (ns) Demo Demo 1 Print data after 3s just once from machine import Timer def on_timer(timer): print(\"time up:\",timer) print(\"param:\",timer.callback_arg()) tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_ONE_SHOT, period=3000, callback=on_timer, arg=on_timer) print(\"period:\",tim.period()) Demo 2 Print every 1s, and stop 5s then restart 5s then shutdown import time from machine import Timer def on_timer(timer,param): print(\"time up:\",timer) print(\"param:\",param) tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, period=1, unit=Timer.UNIT_S, callback=on_timer, arg=on_timer, start=False, priority=1, div=0) print(\"period:\",tim.period()) tim.start() time.sleep(5) tim.stop() time.sleep(5) tim.restart() time.sleep(5) tim.stop() del tim "},"libs/machine/uart.html":{"url":"libs/machine/uart.html","title":"UART","keywords":"","body":"machine.UART "},"libs/Maix/":{"url":"libs/Maix/","title":"Maix","keywords":"","body":"Maix Library FPIOA GPIO "},"libs/Maix/fpioa.html":{"url":"libs/Maix/fpioa.html","title":"FPIOA","keywords":"","body":"FPIOA (Field Programmable Input and Output Array) The K210 supports each peripheral to be randomly mapped to any pin, using the FPIOA function. Attention: Some GPIOHS used by default, don't use these GPIOHS if you don't have to, GPIOHS used as follows: GPIOHS Function GPIOHS31 LCD_DC GPIOHS30 LCD_RST GPIOHS29 SD_CS GPIOHS28 MIC_LED_CLK GPIOHS27 MIC_LED_DATA Class FPIOA Method help(func) Display peripherals and their brief description Parameters func: Peripheral name (function/number), you can not pass the parameter, then display all the peripheral names in a tabular form, which is also a brief description. This table can also be found at the end of this page (Appendix: Peripheral Table); If the parameter is passed, an integer value is passed. When the peripheral corresponding to the number is found, the peripheral name and description are printed, For example FPIOA.JTAG_TCLK or fm.fpioa.JTAG_TCLK (fm is described later in this page) or 0 such as: From Maix import FPIOA Fpioa = FPIOA() Fpioa.help() Fpioa.help(0) Fpioa.help(fpioa.JTAG_TCLK) Fm.fpioa.help() Fm.fpioa.help(fm.fpioa.JTAG_TCLK) Back Peripheral name and its brief description set_function(pin, func) Set the peripheral function corresponding to the pin, that is, pin mapping Parameters pin: pin number, value [0, 47], please refer to the circuit diagram for the specific pin connection. You can also use board_info. and then press the TAB button to get the common pins of the board. board_info.LED_G func: Peripheral function, passing an integer value, can be obtained by fm.fpioa.help() or by looking at the [Appendix: Peripheral Table] (#Appendix: Peripheral Table) table at the end of this page. For example, you need to map the pin connecting green LED to high speed GPIO0: Fpioa = FPIOA() Fpioa.set_function(board_info.LED_G, fm.fpioa.GPIOHS0) get_Pin_num(func) Get which pin the peripheral is mapped to Parameters func: Peripheral function, passing an integer value, can be obtained by fm.fpioa.help() or by looking at the Appendix: Peripheral Table table at the end of this page. such as: Fpioa = FPIOA() Fpioa.set_function(board_info.LED_G, fm.fpioa.GPIOHS0) Pin = fpioa.get_Pin_num(fm.fpioa.GPIOHS0) If pin == board_info.LED_G: Print(\"set function ok\") Appendix: Peripheral Table Peripheral Functions (func) Brief Description JTAG_TCLK JTAG Test Clock JTAG_TDI JTAG Test Data In JTAG_TMS JTAG Test Mode Select JTAG_TDO JTAG Test Data Out SPI0_D0 SPI0 Data 0 SPI0_D1 SPI0 Data 1 SPI0_D2 SPI0 Data 2 SPI0_D3 SPI0 Data 3 SPI0_D4 SPI0 Data 4 SPI0_D5 SPI0 Data 5 SPI0_D6 SPI0 Data 6 SPI0_D7 SPI0 Data 7 SPI0_SS0 SPI0 Chip Select 0 SPI0_SS1 SPI0 Chip Select 1 SPI0_SS2 SPI0 Chip Select 2 SPI0_SS3 SPI0 Chip Select 3 SPI0_ARB SPI0 Arbitration SPI0_SCLK SPI0 Serial Clock UARTHS_RX UART High speed Receiver UARTHS_TX UART High speed Transmitter RESV6 Reserved function RESV7 Reserved function CLK_SPI1 Clock SPI1 CLK_I2C1 Clock I2C1 GPIOHS0 GPIO High speed 0 GPIOHS1 GPIO High speed 1 GPIOHS2 GPIO High speed 2 GPIOHS3 GPIO High speed 3 GPIOHS4 GPIO High speed 4 GPIOHS5 GPIO High speed 5 GPIOHS6 GPIO High speed 6 GPIOHS7 GPIO High speed 7 GPIOHS8 GPIO High speed 8 GPIOHS9 GPIO High speed 9 GPIOHS10 GPIO High speed 10 GPIOHS11 GPIO High speed 11 GPIOHS12 GPIO High speed 12 GPIOHS13 GPIO High speed 13 GPIOHS14 GPIO High speed 14 GPIOHS15 GPIO High speed 15 GPIOHS16 GPIO High speed 16 GPIOHS17 GPIO High speed 17 GPIOHS18 GPIO High speed 18 GPIOHS19 GPIO High speed 19 GPIOHS20 GPIO High speed 20 GPIOHS21 GPIO High speed 21 GPIOHS22 GPIO High speed 22 GPIOHS23 GPIO High speed 23 GPIOHS24 GPIO High speed 24 GPIOHS25 GPIO High speed 25 GPIOHS26 GPIO High speed 26 GPIOHS27 GPIO High speed 27 GPIOHS28 GPIO High speed 28 GPIOHS29 GPIO High speed 29 GPIOHS30 GPIO High speed 30 GPIOHS31 GPIO High speed 31 GPIO0 GPIO pin 0 GPIO1 GPIO pin 1 GPIO2 GPIO pin 2 GPIO3 GPIO pin 3 GPIO4 GPIO pin 4 GPIO5 GPIO pin 5 GPIO6 GPIO pin 6 GPIO7 GPIO pin 7 UART1_RX UART1 Receiver UART1_TX UART1 Transmitter UART2_RX UART2 Receiver UART2_TX UART2 Transmitter UART3_RX UART3 Receiver UART3_TX UART3 Transmitter SPI1_D0 SPI1 Data 0 SPI1_D1 SPI1 Data 1 SPI1_D2 SPI1 Data 2 SPI1_D3 SPI1 Data 3 SPI1_D4 SPI1 Data 4 SPI1_D5 SPI1 Data 5 SPI1_D6 SPI1 Data 6 SPI1_D7 SPI1 Data 7 SPI1_SS0 SPI1 Chip Select 0 SPI1_SS1 SPI1 Chip Select 1 SPI1_SS2 SPI1 Chip Select 2 SPI1_SS3 SPI1 Chip Select 3 SPI1_ARB SPI1 Arbitration SPI1_SCLK SPI1 Serial Clock SPI_SLAVE_D0 SPI Slave Data 0 SPI_SLAVE_SS SPI Slave Select SPI_SLAVE_SCLK SPI Slave Serial Clock I2S0_MCLK I2S0 Master Clock I2S0_SCLK I2S0 Serial Clock(BCLK) I2S0_WS I2S0 Word Select(LRCLK) I2S0_IN_D0 I2S0 Serial Data Input 0 I2S0_IN_D1 I2S0 Serial Data Input 1 I2S0_IN_D2 I2S0 Serial Data Input 2 I2S0_IN_D3 I2S0 Serial Data Input 3 I2S0_OUT_D0 I2S0 Serial Data Output 0 I2S0_OUT_D1 I2S0 Serial Data Output 1 I2S0_OUT_D2 I2S0 Serial Data Output 2 I2S0_OUT_D3 I2S0 Serial Data Output 3 I2S1_MCLK I2S1 Master Clock I2S1_SCLK I2S1 Serial Clock(BCLK) I2S1_WS I2S1 Word Select(LRCLK) I2S1_IN_D0 I2S1 Serial Data Input 0 I2S1_IN_D1 I2S1 Serial Data Input 1 I2S1_IN_D2 I2S1 Serial Data Input 2 I2S1_IN_D3 I2S1 Serial Data Input 3 I2S1_OUT_D0 I2S1 Serial Data Output 0 I2S1_OUT_D1 I2S1 Serial Data Output 1 I2S1_OUT_D2 I2S1 Serial Data Output 2 I2S1_OUT_D3 I2S1 Serial Data Output 3 I2S2_MCLK I2S2 Master Clock I2S2_SCLK I2S2 Serial Clock(BCLK) I2S2_WS I2S2 Word Select(LRCLK) I2S2_IN_D0 I2S2 Serial Data Input 0 I2S2_IN_D1 I2S2 Serial Data Input 1 I2S2_IN_D2 I2S2 Serial Data Input 2 I2S2_IN_D3 I2S2 Serial Data Input 3 I2S2_OUT_D0 I2S2 Serial Data Output 0 I2S2_OUT_D1 I2S2 Serial Data Output 1 I2S2_OUT_D2 I2S2 Serial Data Output 2 I2S2_OUT_D3 I2S2 Serial Data Output 3 RESV0 Reserved function RESV1 Reserved function RESV2 Reserved function RESV3 Reserved function RESV4 Reserved function RESV5 Reserved function I2C0_SCLK I2C0 Serial Clock I2C0_SDA I2C0 Serial Data I2C1_SCLK I2C1 Serial Clock I2C1_SDA I2C1 Serial Data I2C2_SCLK I2C2 Serial Clock I2C2_SDA I2C2 Serial Data CMOS_XCLK DVP System Clock CMOS_RST DVP System Reset CMOS_PWDN DVP Power Down Mode CMOS_VSYNC DVP Vertical Sync CMOS_HREF DVP Horizontal Reference output CMOS_PCLK Pixel Clock CMOS_D0 Data Bit 0 CMOS_D1 Data Bit 1 CMOS_D2 Data Bit 2 CMOS_D3 Data Bit 3 CMOS_D4 Data Bit 4 CMOS_D5 Data Bit 5 CMOS_D6 Data Bit 6 CMOS_D7 Data Bit 7 SCCB_SCLK SCCB Serial Clock SCCB_SDA SCCB Serial Data UART1_CTS UART1 Clear To Send UART1_DSR UART1 Data Set Ready UART1_DCD UART1 Data Carrier Detect UART1_RI UART1 Ring Indicator UART1_SIR_IN UART1 Serial Infrared Input UART1_DTR UART1 Data Terminal Ready UART1_RTS UART1 Request To Send UART1_OUT2 UART1 User-designated Output 2 UART1_OUT1 UART1 User-designated Output 1 UART1_SIR_OUT UART1 Serial Infrared Output UART1_BAUD UART1 Transmit Clock Output UART1_RE UART1 Receiver Output Enable UART1_DE UART1 Driver Output Enable UART1_RS485_EN UART1 RS485 Enable UART2_CTS UART2 Clear To Send UART2_DSR UART2 Data Set Ready UART2_DCD UART2 Data Carrier Detect UART2_RI UART2 Ring Indicator UART2_SIR_IN UART2 Serial Infrared Input UART2_DTR UART2 Data Terminal Ready UART2_RTS UART2 Request To Send UART2_OUT2 UART2 User-designated Output 2 UART2_OUT1 UART2 User-designated Output 1 UART2_SIR_OUT UART2 Serial Infrared Output UART2_BAUD UART2 Transmit Clock Output UART2_RE UART2 Receiver Output Enable UART2_DE UART2 Driver Output Enable UART2_RS485_EN UART2 RS485 Enable UART3_CTS UART3 Clear To Send UART3_DSR UART3 Data Set Ready UART3_DCD UART3 Data Carrier Detect UART3_RI UART3 Ring Indicator UART3_SIR_IN UART3 Serial Infrared Input UART3_DTR UART3 Data Terminal Ready UART3_RTS UART3 Request To Send UART3_OUT2 UART3 User-designated Output 2 UART3_OUT1 UART3 User-designated Output 1 UART3_SIR_OUT UART3 Serial Infrared Output UART3_BAUD UART3 Transmit Clock Output UART3_RE UART3 Receiver Output Enable UART3_DE UART3 Driver Output Enable UART3_RS485_EN UART3 RS485 Enable TIMER0_TOGGLE1 TIMER0 Toggle Output 1 TIMER0_TOGGLE2 TIMER0 Toggle Output 2 TIMER0_TOGGLE3 TIMER0 Toggle Output 3 TIMER0_TOGGLE4 TIMER0 Toggle Output 4 TIMER1_TOGGLE1 TIMER1 Toggle Output 1 TIMER1_TOGGLE2 TIMER1 Toggle Output 2 TIMER1_TOGGLE3 TIMER1 Toggle Output 3 TIMER1_TOGGLE4 TIMER1 Toggle Output 4 TIMER2_TOGGLE1 TIMER2 Toggle Output 1 TIMER2_TOGGLE2 TIMER2 Toggle Output 2 TIMER2_TOGGLE3 TIMER2 Toggle Output 3 TIMER2_TOGGLE4 TIMER2 Toggle Output 4 CLK_SPI2 Clock SPI2 CLK_I2C2 Clock I2C2 "},"libs/Maix/gpio.html":{"url":"libs/Maix/gpio.html","title":"GPIO","keywords":"","body":"GPIO General Purpose Input Output is referred to as GPIO, or bus extender. High speed gpio and universal gpio on the K210 On the K210, GPIO has the following characteristics: High speed GPIO: The high-speed GPIO is GPIOHS, a total of 32. Has the following characteristics: • Configurable input and output signals • Each IO has an independent interrupt source • Interrupt support edge trigger and level trigger • Each IO can be assigned to one of the 48 pins on the FPIOA • Configurable up and down, or high resistance General GPIO: There are 8 general-purpose GPIOs with the following characteristics: • 8 IOs use one interrupt source • Configurable input and output signals • Configurable trigger IO total interrupt, edge trigger and level trigger • Each IO can be assigned to one of the 48 pins on the FPIOA Attention: Some GPIOHS used by default, don't use these GPIOHS if you don't have to, GPIOHS used as follows: GPIOHS Function GPIOHS31 LCD_DC GPIOHS30 LCD_RST GPIOHS29 SD_CS GPIOHS28 MIC_LED_CLK GPIOHS27 MIC_LED_DATA Constructor Class GPIO(ID, MODE, PULL, VALUE) Create a new SPI object with the specified parameters Parameters ID: The GPIO pin used (must be specified using the constants in GPIO) MODE: GPIO mode • GPIO.IN is the input mode • GPIO.OUT is the output mode PULL: GPIO pull-down mode * • GPIO.PULL_UP pull up • GPIO.PULL_DOWN dropdown • GPIO.PULL_NONE does not pull up or pull down method value Modify/read GPIO pin status GPIO.value([value]) Parameters [value]: optional parameter, if this parameter is not empty, return the current GPIO pin status return value Returns the current GPIO pin status if the [value] parameter is not empty irq Configure an interrupt handler to call when the pin's trigger source is active. If the pin mode is pin.in, the trigger source is an external value on the pin. GPIO.irq(CALLBACK_FUNC, TRIGGER_CONDITION, GPIO.WAKEUP_NOT_SUPPORT, PRORITY) Parameters CALLBACK_FUNC: callback function, called when the interrupt is triggered, it has two parameters, GPIO and PIN_NUM • GPIO returns a GPIO object • PIN_NUM returns the GPIO pin number that triggered the interrupt (only GPIOHS supports interrupts, so the pin number here is also the GPIOHS pin number) TRIGGER_CONDITION: Trigger interrupt when GPIO pin is in this state • GPIO.IRQ_RISING rising edge trigger • GPIO.IRQ_RISING falling edge trigger • GPIO.IRQ_BOTH is triggered on both rising and falling edges return value no disirq Close interrupt GPIO.disirq() Parameters no return value no mode GPIO mode GPIO.mode(MODE) Parameters MODE • GPIO.IN is the input mode • GPIO.OUT is the output mode return value no pull GPIO pull-down mode GPIO.pull(PULL) Parameters PULL • GPIO.IRQ_RISING rising edge trigger • GPIO.IRQ_RISING falling edge trigger • GPIO.IRQ_BOTH is triggered on both rising and falling edges return value no Constant GPIO0: GPIO0 GPIO1: GPIO1 GPIO2: GPIO2 GPIO3: GPIO3 GPIO4: GPIO4 GPIO5: GPIO5 GPIO6: GPIO6 GPIO7: GPIO7 GPIOHS0: GPIOHS0 GPIOHS1: GPIOHS1 GPIOHS2: GPIOHS2 GPIOHS3: GPIOHS3 GPIOHS4: GPIOHS4 GPIOHS5: GPIOHS5 GPIOHS6: GPIOHS6 GPIOHS7: GPIOHS7 GPIOHS8: GPIOHS8 GPIOHS9: GPIOHS9 GPIOHS10: GPIOHS10 GPIOHS11: GPIOHS11 GPIOHS12: GPIOHS12 GPIOHS13: GPIOHS13 GPIOHS14: GPIOHS14 GPIOHS15: GPIOHS15 GPIOHS16: GPIOHS16 GPIOHS17: GPIOHS17 GPIOHS18: GPIOHS18 GPIOHS19: GPIOHS19 GPIOHS20: GPIOHS20 GPIOHS21: GPIOHS21 GPIOHS22: GPIOHS22 GPIOHS23: GPIOHS23 GPIOHS24: GPIOHS24 GPIOHS25: GPIOHS25 GPIOHS26: GPIOHS26 GPIOHS27: GPIOHS27 GPIOHS28: GPIOHS28 GPIOHS29: GPIOHS29 GPIOHS30: GPIOHS30 GPIOHS31: GPIOHS31 GPIO.IN: input mode GPIO.OUT: output mode GPIO.PULL_UP: Pull up GPIO.PULL_DOWN: drop down GPIO.PULL_NONE: does not pull up or pull down GPIO.IRQ_RISING: rising edge trigger GPIO.IRQ_RISING: falling edge trigger GPIO.IRQ_BOTH: Both rising and falling edges are triggered DEMO1 import utime from Maix import GPIO fm.register(board_info.LED_R,fm.fpioa.GPIO0) led_r=GPIO(GPIO.GPIO0,GPIO.OUT) utime.sleep_ms(500) led_r.value() fm.unregister(board_info.LED_R,fm.fpioa.GPIO0) DEMO2 import utime from Maix import GPIO fm.register(board_info.LED_R,fm.fpioa.GPIO0) led_r=GPIO(GPIO.GPIO0,GPIO.IN) utime.sleep_ms(500) led_r.value() fm.unregister(board_info.LED_R,fm.fpioa.GPIO0) DEMO3 import utime from Maix import GPIO def test_irq(GPIO,pin_num): print(\"key\",pin_num,\"\\n\") fm.register(board_info.BOOT_KEY,fm.fpioa.GPIOHS0) key=GPIO(GPIO.GPIOHS0,GPIO.IN,GPIO.PULL_NONE) utime.sleep_ms(500) key.value() key.irq(test_irq,GPIO.IRQ_BOTH,GPIO.WAKEUP_NOT_SUPPORT,7) key.disirq() fm.unregister(board_info.BOOT_KEY,fm.fpioa.GPIOHS0) "},"libs/Maix/kpu.html":{"url":"libs/Maix/kpu.html","title":"KPU","keywords":"","body":"KPU KPU is a general-purpose neural network processor, which can do convolutional neural network calculation at low power consumption, for example obtain the size, coordinates and types of detected objects or detect and classify faces and objects. KPU has the following features: Supports fixed-point models trained by mainstream framework with some restrictions There is no direct limit on the number of network layers. It supports separate configuration of each layer of convolutional neural network parameters, including the number of input and output channels, input and output line width and column height. Supports two convolution kernels 1x1 and 3x3 Support any form of activation function The maximum supported neural network parameter size in real-time work is 5.5MiB to 5.9MiB Maximum supported network parameter size when working in non-real time (Flash capacity - software volume) Module Method Loading the model Load a model from flash or file system import KPU as kpu task = kpu.load(offset or file_path) Parameters offtset: The offset of the model in flash, such as 0xd00000 indicates that the model is flashed at the beginning of 13M file_path: The model is the file name in the file system, such as \"/sd/xxx.kmodel\" Back kpu_net: kpu network object Initializing the yolo2 network Passing initialization parameters for the yolo2 network model import KPU as kpu task = kpu.load(offset or file_path) anchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025) kpu.init_yolo2(task, 0.5, 0.3, 5, anchor) Parameters kpu_net: kpu network object threshold: probability threshold nms_value: box_iou threshold anchor_num: number of anchors anchor: anchor parameters are consistent with model parameters initialization import KPU as kpu task = kpu.load(offset or file_path) kpu.deinit(task) Parameters kpu_net: kpu_net object returned by kpu_load Running yolo2 network import KPU as kpu import image task = kpu.load(offset or file_path) anchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025) kpu.init_yolo2(task, 0.5, 0.3, 5, anchor) img = image.Image() kpu.run_yolo2(task, img) #This is not right, please refer to the routine Parameters kpu_net: kpu_net object returned by kpu_load image_t: image captured from sensor Back list: list of kpu_yolo2_find Network forward operation (forward) Calculate the loaded network model to the specified number of layers 3, and output the feature map of the target layer import KPU as kpu task = kpu.load(offset or file_path) …… fmap=kpu.forward(task,img,3) Parameters kpu_net: kpu_net object image_t: image captured from sensor int: specifies the number of layers to calculate to the network Back fmap: Feature map object, containing the feature map of all channels of the current layer fmap feature map Take the specified channel data of the feature map to the image object img=kpu.fmap(fmap,1) Parameters fmap: feature map object int: specify the channel number of the feature map Back img_t: The grayscale image generated by the corresponding map of the feature map fmap_free Release Feature Map Release feature map object kpu.fmap_free(fmap) Parameters fmap: feature map object Back none netinfo Get the network structure information of the model info=kpu.netinfo(task) layer0=info[0] Parameters kpu_net: kpu_net object Back netinfo list: a list of all layers of information, including information:Index: the number of layers of the current layer in the network Wi: input width Hi: input height Wo: output width Ho: output height Chi: number of input channels Cho: number of output channels Dw: whether it is a depth wise layer Kernel_type: convolution kernel type, 0 is 1x1, 1 is 3x3 Pool_type: pooling type, 0 is not pooled; 1:2x2 max pooling; 2:... Para_size: the number of bytes of the convolution parameter of the current layer Routine Running face recognition demo Model download address: http://dl.sipeed.com/MAIX/MaixPy/model/face_model_at_0x300000.kfpkg import sensor import image import lcd import KPU as kpu lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) task = kpu.load(0x300000) #使用kfpkg将 kmodel 与 maixpy 固件打包下载到 flash anchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025) a = kpu.init_yolo2(task, 0.5, 0.3, 5, anchor) while(True): img = sensor.snapshot() code = kpu.run_yolo2(task, img) if code: for i in code: print(i) a = img.draw_rectangle(i.rect()) a = lcd.display(img) a = kpu.deinit(task) Operational feature map Model download address: http://dl.sipeed.com/MAIX/MaixPy/model/face_model_at_0x300000.kfpkg The model is an 8-bit fixed-point model, about 380KB in size, and the layer information is: 1 2 : 160x120 3 4 5 6 : 80x60 7 8 9 10 :40x30 11~16 : 20x15 import sensor import image import lcd import KPU as kpu index=3 lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) task=kpu.load(0x300000) img=image.Image() info=kpu.netinfo(task) layer=info[index] w=layer.wo() h=layer.ho() num=int(320*240/w/h) list=[None]*num x_step=int(320/w) y_step=int(240/h) img_lcd=image.Image() while True: img=sensor.snapshot() fmap=kpu.forward(task,img,index) for i in range(0,num): list[i]=kpu.fmap(fmap,i) for i in range(0,num): list[i].stretch(64,255) for i in range(0,num): a=img_lcd.draw_image(list[i],((i%x_step)*w,(int(i/x_step))*h)) lcd.display(img_lcd) kpu.fmap_free(fmap) "},"libs/Maix/fft.html":{"url":"libs/Maix/fft.html","title":"FFT","keywords":"","body":"FFT operation The FFT fast Fourier transform module performs Fourier transform on the input data and returns the corresponding frequency amplitudes. The FFT fast Fourier operation can convert the time domain signal into the frequency domain signal. Module function arithmetic function Enter time domain data and perform Fourier transform import FFT res = FFT.run(data, points, shift) Parameters data: input time domain data, bytearray type points: FFT operation points, only supports 64, 128, 256 and 512 points shift: offset, default is 0 return value res: Returns the calculated frequency domain data, presented as list type. The list has points tuples, each tuple has 2 elements, the first element is the real part, and the second is Imaginary Frequency function FFT res = FFT.freq(points, sample_rate) Parameters points: Calculate points sample_rate: sample rate return value res : Returns a list of the frequency values ​​of all frequency points after the operation Amplitude function It is used to calculate the amplitude of each frequency point after the FFT operation. It is currently used as a test. Users can write their own amplitude processing functions in python. amp = FFT.amplitude(FFT_res) Parameters FFT_res: function run results after running return value res : Returns a list that stores the magnitude of each frequency point Routine Acquire sound and perform FFT operation, and display the calculated data on the screen as a histogram from Maix import GPIO from Maix import I2S from Maix import FFT import image import lcd lcd.init() fm.register(8, fm.fpioa.GPIO0) wifi_en=GPIO(GPIO.GPIO0,GPIO.OUT) wifi_en.value(0) fm.register(20,fm.fpioa.I2S0_IN_D0) fm.register(19,fm.fpioa.I2S0_WS) fm.register(18,fm.fpioa.I2S0_SCLK) rx = I2S(I2S.DEVICE_0) rx.channel_config(rx.CHANNEL_0, rx.RECEIVER, align_mode = I2S.STANDARD_MODE) sample_rate = 38640 rx.set_sample_rate(sample_rate) img = image.Image() sample_points = 1024 FFT_points = 512 lcd_width = 320 lcd_height = 240 hist_num = FFT_points #changeable if hist_num > 320: hist_num = 320 hist_width = int(320 / hist_num)#changeable x_shift = 0 while True: audio = rx.record(sample_points) FFT_res = FFT.run(audio.to_bytes(),FFT_points) FFT_amp = FFT.amplitude(FFT_res) img = img.clear() x_shift = 0 for i in range(hist_num): if FFT_amp[i] > 240: hist_height = 240 else: hist_height = FFT_amp[i] img = img.draw_rectangle((x_shift,240-hist_height,hist_width,hist_height),[255,255,255],2,True) x_shift = x_shift + hist_width lcd.display(img) "},"libs/builtin_py/":{"url":"libs/builtin_py/","title":"Built-in class","keywords":"","body":"Built-in class The library is a user-level interface that encapsulates the underlying classes of MaixPy, making it easy for users to use MaixPy, which includes the following: fpioa_manager board_info 需要注意的是， 这些类在开机启动的时候在 _boot.py 里面已经被导入了， 所以在串口终端可以直接使用， 但是， 如果是执行文件， 则需要手动写代码导入， 否则找不到类 Be attention, theses class imported at the start up by _boot.py, so we can directly use it in serial terminal without any import, but if we execute file, we need to import by ourselves~ from board import board_info from fpioa_manager import fm or from fpioa_manager import fm, board_info "},"libs/builtin_py/fm.html":{"url":"libs/builtin_py/fm.html","title":"fpioa_manager","keywords":"","body":"FPIOA Manager fpioa_manager: referred to as fm, this module is used to register internal functions and pins of the chip, to help users manage internal functions and pins. If the functions and pins are already registered, the internal functions and pins will not be available. Actually fm is global variable define with Fpioa_Manager class, written by Micropython and integrated to firmware, source code see board.py method Registration function Register pins and functions fm.register(pin,function) Parameters This method must pass in 2 parameters, otherwise it will return a null value. pin: function mapping pin function : chip function return value This method has 2 return values. Parameter error returns None,None Set the success to return pin, function Setting fails to return reg_pin, reg_func, indicating the pins and functions that have been registered Logout function Logout pin and function fm.unregister(pin,function) Parameters This method can pass 1 or 2 parameters. When passing in 1 parameter, you need to add a parameter keyword. If it is 1 parameter, its pins and functions will be logged out. pin: function mapping pin function : chip function return value Parameter error returns None,None Set successfully returns pin, function, indicating the pin and function being logged out Set failure to return 0,0 Routine from fpioa_manager import fm, board_info fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX)#Register again fm.register(board_info.WIFI_RX,fm.fpioa.SPI0_SS0)#Register the same pin fm.register(board_info.WIFI_RX,fm.fpioa.SPI0_SS0)#Register the same function fm.unregister(board_info.WIFI_RX, fm.fpioa.UART2_TX)#Logout function and pin fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) fm.unregister(function = fm.fpioa.UART2_TX)#Logout function fm.register(board_info.WIFI_RX,fm.fpioa.UART2_TX) fm.unregister(pin = board_info.WIFI_RX)#Logout pin Appendix The following pins have been registered when MaxiPy is powered on. Please pay attention to the user. SD card Function: SPI1_SCLK/SPI1_D0/SPI1_D1/GPIOHS7/SPI0_SS1 Pin: PIN25/PIN26/PIN27/PIN28/PIN29 LCD Function: SPI0_SS3/SPI0_SCLK/GPIOHS1/GPIOHS2 Pin: PIN36/PIN37/PIN38/PIN39 sensor Function: SCCB_SDA/SCCB_SCLK/CMOS_RST/CMOS_VSYNC/CMOS_PWDN/CMOS_HREF/CMOS_XCLK/CMOS_PCLK Pin: PIN40/PIN41/PIN42/PIN43/PIN44/PIN45/PIN46/PIN47 REPL Function: UARTHS_RX/UARTHS_TX Pin: PIN4/PIN5 "},"libs/builtin_py/board_info.html":{"url":"libs/builtin_py/board_info.html","title":"board_info","keywords":"","body":"board_info board_info: Mainly used for user-friendly development board pin configuration, built-in user-friendly naming and interface, which allows users to reduce the dependence on the electrical connection schematic. board_info is a global variable defined with Board_Info class, written by MicroPython and integrated to firmware, source code see fpioa_manager.py Members Board_info has many pin indexes and a list pin_namelist The list is mainly used internally by the class, and the user does not operate it. Pin Index The pin index is mainly to convert numbers into human-friendly strings, which is convenient for users to program. Enter the following, please be careful not to ignore the . number, then press the tab key to complete, you can see the board-related pin functions. Board_info. For example, enter the following code, it will return the number 8, which represents the 8th pin of the development board, and its electrical connection is the enable pin of the wifi module. board_info.WIFI_EN method Search method When the user does not know the pin electrical connection, you can use this method to find Board_info.pin_map(pin_num) Parameters This method does not pass in parameters or pass in a parameter pin_num: pin number, range [6,47] Board-level electrical connection information for all pins will be printed when no parameters are passed in When the parameters are passed in, only the board-level electrical connection information for the specified pin is printed. return value Parameter error returns False Unknown error return False Find successful return information Routine Routine 1 from board import board_info Wifi_en_pin = board_info.WIFI_EN Print(wifi_en_pin)# output is 8 Board_info.pin_map()# print all Board_info.pin_map(8)# prints only pin 8 information "},"libs/machine_vision/":{"url":"libs/machine_vision/","title":"Machine vision","keywords":"","body":"Machine vision It mainly contains classes related to images and displays, including: LCD Sensor Image "},"libs/machine_vision/lcd.html":{"url":"libs/machine_vision/lcd.html","title":"LCD","keywords":"","body":"Lcd screen display driver function lcd.init(type=1, freq=15000000, color=lcd.BLACK) Initialize the LCD screen to display Parameters type: type of LCD (reserved for future use): 0: None 1: lcd shield (default) type is a key-value parameter that must be explicitly called by writing type= in the function call freq: frequency of lcd ( actually maybe SPI ) color： LCD initialized color, 16 bits RGB565 color, e.g. 0xFFFF; or RGB888 tuple, e.g. (236, 36, 36), default lcd.BLACK lcd.deinit() Unregister the LCD driver to release the I/O pins lcd.width() Returns the width of the LCD (horizontal resolution) lcd.height() Returns the height of the LCD (vertical resolution). lcd.type() Returns the type of LCD (reserved for future use): 0: None 1: lcd Shield lcd.freq(freq) Set or get frequency of LCD (SPI) Paremeters freq: frequency of LCD (SPI) Return frequency of LCD lcd.set_backlight(state) Setting the backlight status of LCD, turning off the backlight will greatly reduce the energy consumption of the LCD expansion board. //TODO: Not implemented Parameters state: backlight brightness, value [0,100] lcd.get_backlight() Return to backlight status return value Backlight brightness, value [0,100] lcd.display(image, roi=Auto) Display a image (GRAYSCALE or RGB565) on the LCD. Roi is a rectangular tuple (x, y, w, h) of a region of interest. If not specified, it is an image rectangle If the roi width is less than the lcd width, the vertical black border is used to make roi at the center of the screen (that is, fill the unoccupied area with black). If the roi width is greater than the lcd width, roi is at the center of the screen, and the unmatched pixels are not displayed (ie, the LCD displays the center of roi in window form). If the roi height is less than the lcd height, use a vertical black border to center roi in the center of the screen (ie fill the unoccupied area with black). If the roi height is greater than the lcd height, roi is at the center of the screen, and the unmatched pixels are not displayed (ie, the LCD displays the center of roi in window form). roi is a key-value parameter that must be explicitly called by writing roi= in a function call. lcd.clear() Empty the LCD screen to black or other color. Parameters color： LCD initialized color, 16 bits RGB565 color, e.g. 0xFFFF; or RGB888 tuple, e.g. (236, 36, 36) lcd.direction(dir) Set LCD direction and mirror parameters maybe change in the future Parameters dir： nomally lcd.YX_LRUD or lcd.YX_RLDU， other values just exchange XY or LR or DU Routine Routine 1: Display English import lcd lcd.init() lcd.draw_string(100, 100, \"hello maixpy\", lcd.RED, lcd.BLACK) Routine 2: Displaying pictures import lcd import image img = image.Image(\"/sd/pic.bmp\") lcd.display(img) Routine 3: Display English in the form of displaying pictures import lcd import image img = image.Image() img.draw_string(60, 100, \"hello maixpy\", scale=2) lcd.display(img) Routine 4: Real-time display of images captured by the camera import sensor, lcd sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) sensor.skip_frames() lcd.init() while(True): lcd.display(sensor.snapshot()) "},"libs/machine_vision/sensor.html":{"url":"libs/machine_vision/sensor.html","title":"Sensor","keywords":"","body":"Sensor Sensor module for camera configuration and image capture, etc., used to control the development board camera to complete the camera task method Reset function Reset and initialize the camera. This will automatically scan and get the camera address import sensor sensor.reset() Parameters no return value no Start function Start the camera import sensor sensor.run(enbale) Parameters enbale: 1 means open, 0 means stop return value return: returns 1 Setting the frame size It is used to set the camera output frame size. The k210 supports VGA format at most. If it is larger than VGA, it will not be able to acquire images. The screen of the MaixPy development board is 320*240 resolution, and the recommended setting is QVGA format. sensor.set_framesize(framesize) Parameters framesize: frame size return value True : set successfully False: setting error Setting the frame format Used to set the camera output format, k210 supports rgb565 and yuv422 formats. The screen of the MaixPy development board configuration is set using rgb565, and the recommended setting is RGB565 format. sensor.set_pixformat(format) Parameters format: frame format return value True : set successfully False: setting error Starting image capture Turn on image capture sensor.run(enable) Parameters enable: 1 means start grabbing image 0 means stop grabbing image return value True : set successfully False: setting error Getting images Control camera capture image img = sensor.snapshot() Parameters no return value img: returned image object Close the camera Turn off the camera sensor.shutdown(enable) Parameters enable: 1 means to turn on the camera 0 means to turn off the camera return value no Frame skipping Skip the specified number of frames or skip the image for the specified time sensor.skip_frames([n,time]) Parameters n: skip n frame image time: Skip the specified time in ms return value no Resolution width Get camera resolution width sensor.width() Parameters no return value camera resolution width of int type Resolution Height sensor.height() Parameters no return value int type camera resolution height Get frame buffer Get the current frame buffer sensor.get_fb() Parameters no return value Object of type image Get ID Get the current camera ID sensor.get_id() Parameters no return value int type ID Setting color bar mode Set the camera to color bar mode sensor.set_colorbar(enable) Parameters enable: 1 means to turn on the color bar mode 0 means to turn off the color bar mode return value no Setting the contrast Set camera contrast sensor.set_contrast(contrast) Parameters constrast: camera contrast, range [-2, +2] return value True : set successfully False: setting error Setting brightness Set camera brightness sensor.set_brightness(brightness) Parameters constrast: camera brightness, range [-2, +2] return value True : set successfully False: setting error Setting the saturation Set camera saturation sensor.set_saturation(saturation) Parameters constrast: camera saturation, range [-2, +2] return value True : set successfully False: setting error Setting automatic gain Set the camera automatic gain mode sensor.set_auto_gain(enable,gain_db) Parameters enable: 1 means to turn on automatic gain 0 means to turn off automatic gain gain_db: Set the camera fixed gain value when the auto gain is turned off, the unit is db return value no Get the gain value Get camera gain value sensor.get_gain_db() Parameters no return value Gain value of float type Setting up horizontal mirroring Set the camera horizontal mirror sensor.set_hmirror(enable) Parameters enable: 1 means to turn on horizontal mirroring 0 to turn off horizontal mirroring return value no Write register Write the specified value to the camera register sensor.__write_reg(address, value) Parameters address: register address value : write value return value no Read register Read camera register value sensor.__read_reg(address) Parameters address: register address return value Register value of type int Routine Routine 1 import sensor import lcd lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) while 1: img = sensor.snapshot() lcd.display(img) "},"libs/machine_vision/image.html":{"url":"libs/machine_vision/image.html","title":"Image","keywords":"","body":"Image — machine vision Ported in openmv, same as openmv Routine Routine 1: Find green import sensor import image import lcd import time lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) green_threshold = (0, 80, -70, -10, -0, 30) while True: img=sensor.snapshot() blobs = img.find_blobs([green_threshold]) if blobs: for b in blobs: tmp=img.draw_rectangle(b[0:4]) tmp=img.draw_cross(b[5], b[6]) c=img.get_pixel(b[5], b[6]) lcd.display(img) Routine 2: Display fps import sensor import image import lcd import clock clock = clock.clock() lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) sensor.skip_frames(30) while True: clock.tick() img = sensor.snapshot() fps =clock.fps() img.draw_string(2,2, (\"%2.1ffps\" %(fps)), color=(0,128,0), scale=2) lcd.display(img) Routine 3: Scan QR code import sensor import image import lcd import clock clock = clock.clock() lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.set_vflip(1) sensor.run(1) sensor.skip_frames(30) while True: clock.tick() img = sensor.snapshot() res = img.find_qrcodes() fps =clock.fps() if len(res) > 0: img.draw_string(2,2, res[0].payload(), color=(0,128,0), scale=2) print(res[0].payload()) lcd.display(img) If the lens is used, the picture will be distorted and the picture needs to be corrected. Use the lens_corr function to correct, such as 2.8mm, img.lens_corr(1.8) function The function can also press Ctrl+F on the page to search for functions using the browser's search function search image. image.rgb_to_lab(rgb_tuple) Returns the tuple (l, a, b) of the LAB format corresponding to the tuple rgb_tuple (r, g, b) in RGB888 format. RGB888 refers to 8 bits (0-255) of red, green and blue. In LAB, L has a value range of 0-100, and a/b ranges from -128 to 127. image.lab_to_rgb(lab_tuple) Returns the tuple (r, g, b) of the RGB888 format corresponding to the tuple lab_tuple (l, a, b) in LAB format. RGB888 refers to 8 bits (0-255) of red, green and blue. In LAB, L has a value range of 0-100, and a/b ranges from -128 to 127. image.rgb_to_grayscale(rgb_tuple) Returns the gray value corresponding to the tuple rgb_tuple (r, g, b) in RGB888 format. RGB888 refers to 8 bits (0-255) of red, green and blue. The gray value is from 0 to 255. image.grayscale_to_rgb(g_value) Returns the tuple (r, g, b) of the RGB888 format corresponding to the gray value g_value. RGB888 refers to 8 bits (0-255) of red, green and blue. The gray value is from 0 to 255. image.load_decriptor(path) Load a descriptor object from the disk. Path is the path where the descriptor file is saved. image.save_descriptor(path, descriptor) Save the descriptor object descriptor to disk. Path is the path where the descriptor file is saved. image.match_descriptor(descritor0, descriptor1[, threshold=70[, filter_outliers=False]]) For the LBP descriptor, this function returns an integer that represents the difference between the two descriptors. This distance measurement is especially necessary. This distance is a measure of similarity. The closer this measure is to 0, the better the LBPF feature points will match. For the ORB descriptor, this function returns the kptmatch object. See above. Threshold is used to filter the ambiguous matching service for the ORB keypoint. A lower threshold value will be tied to the keypoint matching algorithm. The threshold value is at 0-100 (int). The default is 70. Filter_outliers is used to filter outliers for ORB keypoints. Feature points allow the user to increase the threshold value. The default setting is False. HaarCascade Class – Feature Descriptors The Haar Cascade feature descriptor is used for the image.find_features() method. It has no methods for the user to call. Constructor Class image.HaarCascade(path[, stages=Auto]) Load a Haar Cascade from a Haar Cascade binary (a format suitable for OpenMV Cam). If you pass a \"frontalface\" string instead of a path, this constructor will load a built-in positive face Haar Cascade into memory. In addition, you can also load Haar Cascade into memory via \"eye\". Finally, this method returns the loaded Haar Cascade object, which is used to use image.find_features() . The stage default is the number of stages in Haar Cascade. However, you can specify a lower value to speed up the running of the feature detector, which of course leads to a higher false positive rate. You can make your own Haar Cascades to work with your OpenMV Cam. First, use Google search \" Haar Cascade\" to check if someone has created OpenCV Haar Cascade for the object you want to detect. If not, you need to do it yourself (the amount of work is huge). For information on how to make your own Haar Cascade, see here on how to turn OpenCV Haar Cascades into a mode that your OpenMV Cam can read, see this script Q: What is Haar Cascade? A: Haar Cascade is a series of comparison checks used to determine if an object is present in an image. This series of comparison checks is divided into phases, and the operation of the latter phase is premised on the completion of the previous phase. Contrast checks are not complicated, but are like processes that check if the center of the image is slightly more vertical than the edges. A wide range of inspections are carried out first in the early stages, and more small area inspections are carried out later. Q: How was Haar Cascades made? A: Haar Cascades trains generator algorithms with positive and negative images. For example, use hundreds of pictures containing cats (marked as containing cats) and hundreds of pictures that do not contain cats (have been marked differently) to train this generation algorithm. This generation algorithm will eventually generate a Haar Cascades for detecting cats. Similarity Class – Similarity Object The similarity object is returned by image.get_similarity. Constructor Class image.similarity Call the image.get_similarity() function to create this object. 方法 similarity.mean() Returns the mean of the similarity difference in 8x8 pixel block structure. Range [-1/+1], where -1 is completely different and +1 is identical. You can also get this value via index [0]. similarity.stdev() Returns the standard deviation of the 8x8 pixel block structure similarity difference. You can also get this value via index [1]. similarity.min() Returns the minimum value of the 8x8 pixel block structure similarity difference. Where -1 is completely different and +1 is identical. You can also get this value via index [2]. By looking at this value, you can quickly determine if any 8x8 pixel blocks between the two images are very different, which is much lower than +1. similarity.max() Returns the minimum value of the 8x8 pixel block structure similarity difference. Where -1 is completely different and +1 is identical. You can also get this value via index [3]. By looking at this value, you can quickly determine if any 8x8 pixel blocks between the two images are the same. That is much larger than -1. Histogram Class – Histogram Object The histogram object is returned by image.get_histogram. A grayscale histogram has a channel that contains multiple binaryes. All binaries are normalized to a total of one. RGB565 has three channels with multiple binary. All binaries are normalized to a total of one. Constructor Class image.histogram Please call the image.get_histogram() function to create this object. 方法 histogram.bins() Returns a list of floating point numbers for the grayscale histogram. You can also get this value via index [0]. histogram.l_bins() Returns a list of floating point numbers for the L channel of the RGB565 histogram LAB. You can also get this value via index [0]. histogram.a_bins() Returns a list of floating point numbers for the A channel of the RGB565 histogram LAB. You can also get this value via index [1]. histogram.b_bins() Returns a list of floating point numbers for the B channel of the RGB565 histogram LAB. You can also get this value via index [2]. histogram.get_percentile(percentile) Calculates the CDF of the histogram channel, returning a value that passes the histogram in percentile (0.0 - 1.0) (floating point). Therefore, if you pass in 0.1, this method will tell you which binary will cause the accumulator to cross 0.1 when accumulating the accumulator. This is effective for determining the minimum (0.1) and max(0.9) of the color distribution when there is no anomalous utility to corrupt your adaptive color tracking results. histogram.get_threhsold() Use the Otsu’s method to calculate the optimal threshold, dividing each channel of the histogram into two halves. This method returns an image.threshold object. This method is especially useful for determining the best image.binary() threshold. histogram.get_statistics() Calculates the mean, median, value, standard deviation, minimum, maximum, lower quartile, and upper quartile for each color channel in the histogram and returns a statistics object. You can also use histogram.statistics() and histogram.get_stats() as aliases for this method. Percentile Class – Percentage Value Object The percentage value object is returned by histogram.get_percentile. The grayscale value has one channel. Do not use the l* , a , or b_ methods. The RGB565 percentage value has three channels. Use the l* , a , and b_ methods. Constructor Class image.percentile Call the histogram.get_percentile() function to create this object. 方法 percentile.value() Returns the grayscale percentage value (value range 0-255). You can also get this value via index [0]. percentile.l_value() Returns the percentage value of the L channel of the RGB565 LAB (value range is 0-100). You can also get this value via index [0]. percentile.a_value() Returns the percentage value of the A channel of the RGB565 LAB (value range -128-127). You can also get this value via index [1]. percentile.b_value() Returns the percentage value of the B channel of the RGB565 LAB (value range -128-127). You can also get this value via index [2]. Threhsold Class – Threshold Object The threshold object is returned by histogram.get_threshold. The grayscale image has a channel. There are no l*, a, and b_ methods. The RGB565 threshold has three channels. Use the l*, a, and b_ methods. Constructor Class image.threshold Call the histogram.get_threshold() function to create this object. 方法 threhsold.value() Returns the threshold of the grayscale image (between 0 and 255). You can also get this value via index [0]. threhsold.l_value() Returns the L threshold in RGB565 map LAB (between 0 and 100). You can also get this value via index [0]. threhsold.a_value() Returns the A threshold in the RGB565 graph LAB (between -128 and 127). You can also get this value via index [1]. threhsold.b_value() Returns the B threshold in RGB565 map LAB (between -128 and 127). You can also get this value via index [2]. class Statistics – Statistics Object The statistics object is returned by histogram.get_statistics or image.get_statistics. Grayscale statistics have one channel, using non-l*, a, or b_ methods. The RGB565 percentage value has three channels. Use the l* , a , and b_ methods. Constructor Class image.statistics Call the histogram.get_statistics() or image.get_statistics() function to create this object. 方法 statistics.mean() Returns the grayscale mean (0-255) (int). You can also get this value via index [0]. statistics.median() Returns the gray value median (0-255) (int). You can also get this value via index [1]. statistics.mode() Returns the gray level value (0-255) (int). You can also get this value via index [2]. statistics.stdev() Returns the gray standard deviation (0-255) (int). You can also get this value via index [3]. statistics.min() Returns the minimum gray level (0-255) (int). You can also get this value via index [4]. statistics.max() Returns the grayscale maximum (0-255) (int). You can also get this value via index [5]. statistics.lq() Returns the quarter value (0-255) (int) under gray. You can also get this value via index [6]. statistics.uq() Returns the grayscale upper quartile (0-255) (int). You can also get this value via index [7]. statistics.l_mean() Returns the mean (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [0]. statistics.l_median() Returns the median (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [1]. statistics.l_mode() Returns the value of L (0-255) (int) in RGB5656 LAB. You can also get this value via index [2]. statistics.l_stdev() Returns the standard deviation value (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [3]. statistics.l_min() Returns the minimum value (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [4]. statistics.l_max() Returns the maximum value (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [5]. statistics.l_lq() Returns the lower quartile (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [6]. statistics.l_uq() Returns the upper quartile (0-255) (int) of L in RGB5656 LAB. You can also get this value via index [7]. statistics.a_mean() Returns the mean (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [8]. statistics.a_median() Returns the median (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [9]. statistics.a_mode() Returns the value of A (0-255) (int) in RGB5656 LAB. You can also get this value via index [10]. statistics.a_stdev() Returns the standard deviation value (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [11]. statistics.a_min() Returns the minimum value (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [12]. statistics.a_max() Returns the maximum value (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [13]. statistics.a_lq() Returns the lower quartile (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [14]. statistics.a_uq() Returns the upper quartile (0-255) (int) of A in RGB5656 LAB. You can also get this value via index [15]. statistics.b_mean() Returns the mean (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [16]. statistics.b_median() Returns the median (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [17]. statistics.b_mode() Returns the value of B (0-255) (int) in RGB5656 LAB. You can also get this value via index [18]. statistics.b_stdev() Returns the standard deviation (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [19]. statistics.b_min() Returns the minimum value (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [20]. statistics.b_max() Returns the maximum value (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [21]. statistics.b_lq() Returns the lower quartile (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [22]. statistics.b_uq() Returns the upper quartile (0-255) (int) of B in RGB5656 LAB. You can also get this value via index [23]. Blob class – color block object The patch object is returned by image.find_blobs. Constructor Class image.blob Call the image.find_blobs() function to create this object. 方法 blob.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the color block bounding box. blob.x() Returns the x coordinate (int) of the bounding box of the patch. You can also get this value via index [0]. blob.y() Returns the y coordinate (int) of the bounding box of the patch. You can also get this value via index [1]. blob.w() Returns the w coordinate (int) of the bounding box of the patch. You can also get this value via index [2]. blob.h() Returns the h coordinate (int) of the bounding box of the patch. You can also get this value via index [3]. blob.pixels() Returns the number of pixels subordinate to a part of the int. You can also get this value via index [4]. blob.cx() Returns the center x position of the color block (int). You can also get this value via index [5]. blob.cy() Returns the center x position of the color block (int). You can also get this value via index [6]. blob.rotation() Returns the rotation of the patch (in radians). If the color block is similar to a pencil or pen, then this value is a unique value between 0-180. If the color block is round, then this value has no effect. If this color block is completely symmetrical, you can only get a 0-360 degree rotation. You can also get this value via index [7]. blob.code() Returns a 16-bit binary number with one bit set for each color threshold, which is part of the color block. For example, if you look for three color thresholds via image.find_blobs, this color block can be set to 0/1/2 digits. Note: You can only set one bit per color block unless you call image.find_blobs with merge=True . Then multiple color patches with different color thresholds can be merged together. You can also use this method and multiple thresholds to implement color code tracking. You can also get this value via index [8]. blob.count() Returns the number of multiple patches that are merged into this patch. This number is not 1 only if you call image.find_blobs with merge=True. You can also get this value via index [9]. blob.area() Returns the border area around the patch (w * h) blob.density() Returns the density ratio of this patch. This is the number of pixels in the bounding box area of ​​the patch. In general, a lower density ratio means that the object is not locked well. Line Class – Straight Line Object Line objects are returned by image.find_lines , image.find_line_segments or image.get_regression. Constructor Class image.line Call the image.find_lines(), image.find_line_segments(), or image.get_regression() function to create this object. 方法 line.line() Returns a line tuple (x1, y1, x2, y2) for use with other image methods such as image.draw_line . line.x1() Returns the p1 vertex x coordinate component of the line. You can also get this value via index [0]. line.y1() Returns the p1 y component of the line. You can also get this value via index [1]. line.x2() Returns the p2 x component of the line. You can also get this value via index [2]. line.y2() Returns the p2 y component of the line. You can also get this value via index [3]. line.length() Returns the length of the line ie sqrt(((x2-x1)^2) + ((y2-y1)^2). You can also get this value via index [4]. line.magnitude() Returns the length of the line after the Hough transform. You can also get this value via index [5]. line.theta() Returns the angle of the line after the Hough transform (0-179 degrees). You can also get this value via index [7]. line.rho() Returns the p value of the line after the Hough transform. You can also get this value via index [8]. CircleClass - Round Object The circular object is returned by image.find_circles. Constructor Class image.circle Call the image.find_circles() function to create this object. 方法 circle.x() Returns the x position of the circle. You can also get this value via index [0]. circle.y() Returns the y position of the circle. You can also get this value via index [1]. circle.r() Returns the radius of the circle. You can also get this value via index [2]. circle.magnitude() Returns the size of the circle. You can also get this value via index [3]. Rect class – rectangular object The rectangle object is returned by image.find_rects. Constructor Class image.rect Call the image.find_rects() function to create this object. 方法 rect.corners() Returns a list of four tuples (x, y) consisting of the four corners of a rectangular object. The four corners are usually returned in a clockwise order starting from the upper left corner. rect.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the bounding box of the rectangle. rect.x() Returns the x position of the top left corner of the rectangle. You can also get this value via index [0]. rect.y() Returns the y position of the top left corner of the rectangle. You can also get this value via index [1]. rect.w() Returns the width of the rectangle. You can also get this value via index [2]. rect.h() Returns the height of the rectangle. You can also get this value via index [3]. rect.magnitude() Returns the size of the rectangle. You can also get this value via index [4]. QRCode Class – QR Code Object The QR code object is returned by image.find_qrcodes. Constructor Class image.qrcode Call the image.find_qrcodes() function to create this object. 方法 qrcode.corners() Returns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in a clockwise order starting from the upper left corner. qrcode.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the bounding box of the QR code. qrcode.x() Returns the x coordinate (int) of the bounding box of the QR code. You can also get this value via index [0]. qrcode.y() Returns the y coordinate (int) of the bounding box of the QR code. You can also get this value via index [1]. qrcode.w() Returns the w coordinate (int) of the bounding box of the QR code. You can also get this value via index [2]. qrcode.h() Returns the h coordinate (int) of the bounding box of the QR code. You can also get this value via index [3]. qrcode.payload() Returns a string of the QR code payload, such as a URL. You can also get this value via index [4]. qrcode.version() Returns the version number (int) of the QR code. You can also get this value via index [5]. qrcode.ecc_level() Returns the ECC level (int) of the QR code. You can also get this value via index [6]. qrcode.mask() Returns the mask (int) of the QR code. You can also get this value via index [7]. qrcode.data_type() Returns the data type of the QR code. You can also get this value via index [8]. qrcode.eci() Returns the ECI of the QR code. The ECI stores the code for storing the data bytes in the QR code. If you want to process a QR code that contains more than standard ASCII text, you need to look at this value. You can also get this value via index [9]. qrcode.is_numeric() Returns True if the data type of the QR code is numeric. qrcode.is_alphanumeric() Returns True if the data type of the QR code is alphanumeric. qrcode.is_binary() Returns True if the data type of the QR code is binary. If you are dealing with all types of text carefully, you need to check if eci is True to determine the text encoding of the data. Usually it's just standard ASCII, but it could also be UTF8 with two byte characters. qrcode.is_kanji() Returns True if the data type of the QR code is Japanese Kanji. When set to True, you need to decode the string yourself, because the Japanese character is 10 digits per character, and MicroPython does not support parsing such text. AprilTag类 – AprilTag object The AprilTag object is returned by image.find_apriltags. Constructor Class image.apriltag Call the image.find_apriltags() function to create this object. 方法 apriltag.corners() Returns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in a clockwise order starting from the upper left corner. apriltag.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the AprilTag bounding box. apriltag.x() Returns the x coordinate (int) of the AprilTag bounding box. You can also get this value via index [0]. apriltag.y() Returns the y coordinate (int) of the AprilTag bounding box. You can also get this value via index [1]. apriltag.w() Returns the w coordinate (int) of the AprilTag bounding box. You can also get this value via index [2]. apriltag.h() Returns the h coordinate (int) of the AprilTag bounding box. You can also get this value via index [3]. apriltag.id() Returns the numeric ID of the AprilTag. TAG16H5 -> 0 to 29 TAG25H7 -> 0 to 241 TAG25H9 -> 0 to 34 TAG36H10 -> 0 to 2319 TAG36H11 -> 0 to 586 ARTOOLKIT -> 0 to 511 You can also get this value via index [4]. apriltag.family() Return to the digital family of AprilTag. image.TAG16H5 image.TAG25H7 image.TAG25H9 image.TAG36H10 image.TAG36H11 image.ARTOOLKIT You can also get this value via index [5]. apriltag.cx() Returns the center x position (int) of the AprilTag. You can also get this value via index [6]. apriltag.cy() Returns the center y position (int) of the AprilTag. You can also get this value via index [7]. apriltag.rotation() Returns the curl (int) of the AprilTag in radians. You can also get this value via index [8]. apriltag.decision_margin() Returns the color saturation of the AprilTag match (values ​​0.0 - 1.0), where 1.0 is optimal. You can also get this value via index [9]. apriltag.hamming() Returns the acceptable digit error value for the AprilTag. TAG16H5 -> accepts up to 0 bit errors TAG25H7 -> accepts up to 1 bit error TAG25H9 -> accepts up to 3 bit errors TAG36H10 -> accepts up to 3 bit errors TAG36H11 -> accepts up to 4 errors ARTOOLKIT -> accepts up to 0 bit errors You can also get this value via index [10]. apriltag.goodness() Returns the color saturation of the AprilTag image (value 0.0 - 1.0), where 1.0 is optimal. Currently this value is usually 0.0. In the future, we can enable a feature called \"tag refinement\" to achieve detection of smaller AprilTag. However, this feature now reduces the frame rate below 1 FPS. You can also get this value via index [11]. apriltag.x_translation() Returns the transformation from the x direction of the camera. The unit of distance is unknown. This method is useful for determining the position of the AprilTag away from the camera. However, the size of the AprilTag and the factors you use will affect the determination of the X unit ownership. For ease of use, we recommend that you use a lookup table to convert the output of this method into information that is useful to your application. Note: The direction here is from left to right. You can also get this value via index [12]. apriltag.y_translation() Returns the transformation from the y direction of the camera, the unit of distance is unknown. This method is useful for determining the position of the AprilTag away from the camera. However, the size of the AprilTag and the factors you use will affect the determination of the Y unit ownership. For ease of use, we recommend that you use a lookup table to convert the output of this method into information that is useful to your application. Note: The direction here is from top to bottom. You can also get this value via index [13]. apriltag.z_translation() Returns the transformation from the camera's z direction, the unit of distance is unknown. This method is useful for determining the position of the AprilTag away from the camera. However, factors such as the size of the AprilTag and the lens you are using will affect the determination of the Z-unit attribution. For ease of use, we recommend that you use a lookup table to convert the output of this method into information that is useful to your application. Note: The direction here is from front to back. You can also get this value via index [14]. apriltag.x_rotation() Returns the curl of the AprilTag in radians on the X plane. Example: Visually see the AprilTag and move the camera from left to right. You can also get this value via index [15]. apriltag.y_rotation() Returns the curl of the AprilTag in radians on the Y plane. Example: Visualize the AprilTag and move the camera from top to bottom. You can also get this value via index [16]. apriltag.z_rotation() Returns the curl of the AprilTag in radians on the Z plane. Example: Visualize the AprilTag and rotate the camera. Note: This is just a renamed version of apriltag.rotation(). You can also get this value via index [17]. DataMatrix Class – Data Matrix Object The data matrix object is returned by image.find_datamatrices. Constructor Class image.datamatrix Call the image.find_datamatrices() function to create this object. 方法 datamatrix.corners() Returns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in a clockwise order starting from the upper left corner. datamatrix.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the bounding box of the data matrix. datamatrix.x() Returns the x coordinate (int) of the bounding box of the data matrix. You can also get this value via index [0]. datamatrix.y() Returns the y coordinate (int) of the bounding box of the data matrix. You can also get this value via index [1]. datamatrix.w() Returns the w width of the bounding box of the data matrix. You can also get this value via index [2]. datamatrix.h() Returns the h height of the bounding box of the data matrix. You can also get this value via index [3]. datamatrix.payload() Returns a string of payloads for the data matrix. Example: String. You can also get this value via index [4]. datamatrix.rotation() Returns the curl (float) of the data matrix in radians. You can also get this value via index [5]. datamatrix.rows() Returns the number of rows (int) of the data matrix. You can also get this value via index [6]. datamatrix.columns() Returns the number of columns (int) of the data matrix. You can also get this value via index [7]. datamatrix.capacity() Returns the number of characters this data matrix can hold. You can also get this value via index [8]. datamatrix.padding() Returns the number of unused characters in this data matrix. You can also get this value via index [9]. BarCode Class – Barcode Object The barcode object is returned by image.find_barcodes. Constructor Class image.barcode Call the image.find_barcodes() function to create this object. 方法 barcode.corners() Returns a list of four tuples (x, y) consisting of the four corners of the object. The four corners are usually returned in a clockwise order starting from the upper left corner. barcode.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the bounding box of the data matrix. barcode.x() Returns the x coordinate (int) of the bounding box of the barcode. You can also get this value via index [0]. barcode.y() Returns the y coordinate (int) of the bounding box of the barcode. You can also get this value via index [1]. barcode.w() Returns the w width (int) of the bounding box of the barcode. You can also get this value via index [2]. barcode.h() Returns the h height (int) of the bounding box of the barcode. You can also get this value via index [3]. barcode.payload() Returns a string of the payload of the barcode. Example: Quantity. You can also get this value via index [4]. barcode.type() Returns the enumerated type (int) of the barcode. You can also get this value via index [5]. image.EAN2 image.EAN5 image.EAN8 image.UPCE image.ISBN10 image.UPCA image.EAN13 image.ISBN13 image.I25 image.DATABAR image.DATABAR_EXP image.CODABAR image.CODE39 image.PDF417 - Enable in the future (e.g. is not working properly now). image.CODE93 image.CODE128 barcode.rotation() Returns the curl (floating point) of the barcode in radians. You can also get this value via index [6]. barcode.quality() Returns the number of times the barcode was detected in the image (int). When scanning a barcode, each new scan line can decode the same barcode. Each time this process is performed, the value of the barcode will increase. You can also get this value via index [7]. Displacement class – displacement object The displacement object is returned by image.find_displacement. Constructor Class image.displacement Call the image.find_displacement() function to create this object. 方法 displacement.x_translation() Returns an x ​​translation pixel between two images. This is a precise subpixel, so it is a floating point number. You can also get this value via index [0]. displacement.y_translation() Returns the y translation pixel between the two images. This is a precise subpixel, so it is a floating point number. You can also get this value via index [1]. displacement.rotation() Returns the z translation pixel between the two images. This is a precise subpixel, so it is a floating point number. You can also get this value via index [2]. displacement.scale() Returns the arc of rotation between two images. You can also get this value via index [3]. displacement.response() Returns the quality of the displacement match between the two images. Range 0-1. A displacement object with a response of less than 0.1 may be noise. You can also get this value via index [4]. Kptmatch class – feature point object The feature point object is returned by image.match_descriptor. Constructor Class image.kptmatch Please call the image.match_descriptor() function to create this object. 方法 kptmatch.rect() Returns a rectangular tuple (x, y, w, h) for other image methods such as image.draw_rectangle of the bounding box of the feature point. kptmatch.cx() Returns the center x position (int) of the feature point. You can also get this value via index [0]. kptmatch.cy() Returns the center y position (int) of the feature point. You can also get this value via index [1]. kptmatch.x() Returns the x coordinate (int) of the bounding box of the feature point. You can also get this value via index [2]. kptmatch.y() Returns the y coordinate (int) of the bounding box of the feature point. You can also get this value via index [3]. kptmatch.w() Returns the w width (int) of the feature point bounding box. You can also get this value via index [4]. kptmatch.h() Returns the h height (int) of the feature point bounding box. You can also get this value via index [5]. kptmatch.count() Returns the number of matching feature points (int). You can also get this value via index [6]. kptmatch.theta() Returns the curl of the estimated feature point (int). You can also get this value via index [7]. kptmatch.match() Returns a list of (x,y) tuples that match the key. You can also get this value via index [8]. ImageWriterClass – ImageWriter Object The ImageWriter object allows you to quickly write uncompressed images to disk. Constructor Class image.ImageWriter(path) Create an ImageWriter object and you can write uncompressed images to disk in a simple file format for OpenMV Cams. The uncompressed image can then be re-read using ImageReader. method imagewriter.size() Returns the size of the file being written. imagewriter.add_frame(img) Write an image to disk. Because the image is not compressed, it performs quickly but takes up a lot of disk space. imagewriter.close() Close the image stream file. You must close the file or the file will be corrupted. ImageReader Class – ImageReader Object The ImageReader object allows you to quickly read uncompressed images from disk. Constructor Class image.ImageReader(path) Create an ImageReader object to play back the image data written by the ImageWriter object. Frames played back by the ImageWriter object are played back under the same FPS as when writing to disk. method imagereader.size() Returns the size of the file being read. Imagereader.next_frame([copy_to_fb=True, loop=True]) Returns an image object from a file written by ImageWriter. If copy_to_fb is True, the image object will be loaded directly into the frame buffer. Otherwise the image object will be placed in the heap. Note: Unless the image is small, the heap may not have enough space to store the image object. If loop is True, playback will resume after the last image of the stream has been read. Otherwise, this method will return None after all frames have been read. Note: imagereader.next_frame attempts to limit the playback speed by pausing playback after reading the frame to match the speed of the frame recording. Otherwise, this method will play all images at a speed of 200+FPS. imagereader.close() Close the file being read. You need to do this to prevent the imagereader object from being damaged. However, since it is a read-only file, the file will not be damaged when it is not closed. ImageClass - Image Object Image objects are the basic objects of machine vision operations. Constructor Class image.Image(path[, copy_to_fb=False]) Create a new image object from the file in path. Support image files in bmp/pgm/ppm/jpg/jpeg format. If copy_to_fb is True, the image will be loaded directly into the framebuffer and you can load large images. If False, the image will be loaded into the MicroPython heap, which is much smaller than the frame buffer. In OpenMV Cam M4, if copy_to_fb is False, you should try to keep the image size below 8KB. If True, the image can be up to 160KB. In OpenMV Cam M7, if copy_to_fb is False, you should try to keep the image size below 16KB. If True, the image can be up to 320KB. The image supports the \"[]\" notation. Let image[index] = 8/16-bit value to assign image pixels or image[index] and get an image pixel. If it is a grayscale image of 16-bit RGB565 value for RGB image, this pixel is 8 Bit. For JPEG images, \"[]\" gives you access to JPEG image patches in the form of compressed section arrays. Since JPEG images are in the form of compressed byte streams, reading and writing of data sets is opaque. The image also supports read buffer operations. You can use the image as a section array object and enter the image into all types of MicroPython functions. If you want to transfer an image, you can pass it to the UART / SPI / I2C write function for automatic transfer. method image.width() Returns the width of the image in pixels. image.height() Returns the height of the image in pixels. image.format() Returns sensor.GRAYSCALE for grayscale images, sensor.RGB565 for RGB images, and sensor.JPEG for JPEG images. image.size() Returns the image size in bytes. image.get_pixel(x, y[, rgbtuple]) Grayscale: Returns the grayscale pixel value at the (x, y) position. RGB565l: Returns the RGB888 pixel tuple (r, g, b) at the (x, y) position. Bayer image: Returns the pixel value at the (x, y) position. Compressed images are not supported. image.get_pixel() and image.set_pixel() are the only ways you can manipulate Bayer mode images. The Bayer pattern image is a text image. For even rows, where the pixels in the image are R/G/R/G/ and so on. For odd lines, where the pixels in the image are G/B/G/B/etc. Each pixel is 8 bits. image.set_pixel(x, y, pixel) Grayscale: Set the pixel at the (x, y) position to the grayscale value pixel . RGB image: Set the pixel at the (x, y) position to RGB888 tuple (r, g, b) pixel . Compressed images are not supported. image.get_pixel() and image.set_pixel() are the only ways you can manipulate Bayer mode images. The Bayer pattern image is a text image. For even rows, where the pixels in the image are R/G/R/G/ and so on. For odd lines, where the pixels in the image are G/B/G/B/etc. Each pixel is 8 bits. image.mean_pool(x_div, y_div) Find the average of the x_div * y_div squares in the image and return a modified image consisting of the average of each square. This method allows you to quickly reduce the image on the original image. Compressed images and bayer images are not supported. image.mean_pooled(x_div, y_div) Find the average of the x_div * y_div squares in the image and return a new image consisting of the average of each square. This method allows you to create a reduced copy of the image. Compressed images and bayer images are not supported. image.midpoint_pool(x_div, y_div[, bias=0.5]) Finds the midpoint value of the x_div * y_div square in the image and returns a modified image consisting of the midpoint values ​​of each square. Bias is 0.0 to return the minimum value for each region, and bias is 1.0 to return the maximum value for each region. This method allows you to quickly reduce the image on the original image. Compressed images and bayer images are not supported. image.midpoint_pooled(x_div, y_div[, bias=0.5]) Finds the midpoint value of the x_div * y_div square in the image and returns a new image consisting of the midpoint values ​​of each square. Bias is 0.0 to return the minimum value for each region, and bias is 1.0 to return the maximum value for each region. This method allows you to create a reduced copy of the image. Compressed images and bayer images are not supported. image.to_grayscale([copy=False]) Convert the image to a grayscale image. This method also modifies the base image pixels and changes the image size in bytes, so it can only be done on grayscale images or RGB565 images. Otherwise copy must be True to create a new modified image on the heap. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.to_rgb565([copy=False]) Convert an image to a color image. This method also modifies the base image pixels and changes the image size in bytes, so it can only be done on RGB565 images. Otherwise copy must be True to create a new modified image on the heap. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.to_rainbow([copy=False]) Convert an image to a rainbow image. This method also modifies the base image pixels and changes the image size in bytes, so it can only be done on RGB565 images. Otherwise copy must be True to create a new modified image on the heap. A rainbow image is a color image that has a unique color value for each 8-bit mask grayscale illumination value in the image. For example, it provides a heat map color for a thermal image. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.compress([quality=50]) JPEG properly compresses the image. Using this method to use a higher quality compression ratio is at the expense of destroying the original image compared to the compressed save heap space. Quality is the compression quality (0-100) (int). image.compress_for_ide([quality=50]) JPEG properly compresses the image. Using this method to use a higher quality compression ratio is at the expense of destroying the original image compared to the compressed save heap space. This method compresses the image and then formats the JPEG data by encoding each 6 bits into a byte between 128 and 191 and converts it to OpenMV IDE for display. This step is done to prevent JPEG data from being mistaken for other text data in the byte stream. You need to use this method to format the image data for display in the terminal window created by Open Terminal in OpenMV IDE. Quality is the compression quality (0-100) (int). image.compressed([quality=50]) Returns a JPEG compressed image - the original image is unprocessed. However, this method requires a large allocation of heap space, so image compression quality and image resolution must be low. Quality is the compression quality (0-100) (int). image.compressed_for_ide([quality=50]) Returns a JPEG compressed image - the original image is unprocessed. However, this method requires a large allocation of heap space, so image compression quality and image resolution must be low. This method compresses the image and then formats the JPEG data by encoding each 6 bits into a byte between 128 and 191 and converts it to OpenMV IDE for display. This step is done to prevent JPEG data from being mistaken for other text data in the byte stream. You need to use this method to format the image data for display in the terminal window created by Open Terminal in OpenMV IDE. Quality is the compression quality (0-100) (int). image.copy([roi[, copy_to_fb=False]]) Create a copy of the image object. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI copies the image rectangle of the entire image. But this does not apply to JPEG images. Remember that the image copy is stored in the MicroPython heap instead of the frame buffer. Again, you need to keep the image copy size below 8KB (OpenMV) or below 16KB (OpenMV Cam M7). If you want to use a copy operation to use all the heap space, this function will get an exception. An oversized image can easily trigger an exception. If copy_to_fb is True, this method replaces the framebuffer with an image. The frame buffer has much larger space than the heap and can accommodate large images. image.save(path[, roi[, quality=50]]) Save a copy of the image to the file system in path. Support image files in bmp/pgm/ppm/jpg/jpeg format. Note: You cannot save a compressed image in jpeg format to an uncompressed format. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI copies the image rectangle of the entire image. But this does not apply to JPEG images. Quality refers to the JPEG compression quality that saves the image to JPEG format when the image has not been compressed. image.clear() Set all pixels in the image to zero (very fast). Returns an image object so that you can use the . notation to call another method. Compressed images are not supported. image.draw_line(x0, y0, x1, y1[, color[, thickness=1]]) Draw a line from (x0, y0) to (x1, y1) on the image. You can pass x0, y0, x1, y1 individually or to a tuple (x0, y0, x1, y1). Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Thickness The thickness of the control line. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_rectangle(x, y, w, h[, color[, thickness=1[, fill=False]]]) Draw a rectangle on the image. You can pass x, y, w, h alone or as a tuple (x, y, w, h). Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Thickness The thickness of the control line. Set fill to True to fill the rectangle. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_circle(x, y, radius[, color[, thickness=1[, fill=False]]]) Draw a circle on the image. You can pass x, y, radius alone or as a tuple (x, y, radius). Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Thickness The thickness of the control line. Set fill to True to fill the circle. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_string(x, y, text[, color[, scale=1[, x_spacing=0[, y_spacing=0[, mono_space=True]]]]) Draw 8x10 text from the (x, y) position in the image. You can pass x, y alone or as a tuple (x, y). Text is a string that is written to the image. The \\n, \\r, and \\r\\n terminators move the cursor to the next line. Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. You can increase the scale to increase the size of the text on the image. Only integer values ​​(for example, 1/2/3 / etc). X_spacing allows you to add (if positive) or subtract (if negative) x pixels between characters to set the character spacing. Y_spacing allows you to add (if positive) or subtract (if negative) y pixels between characters to set the line spacing. Mono_space defaults to True, which forces the text spacing to be fixed. For big text, this looks bad. Setting False to get a non-fixed width of character spacing looks much better. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_cross(x, y[, color[, size=5[, thickness=1]]]) Draw a cross on the image. You can pass x, y alone or as a tuple (x, y). Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Size Controls the extension of the crosshair. Thickness Controls the pixel thickness of the edge. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_arrow(x0, y0, x1, y1[, color[, thickness=1]]) Draw an arrow from (x0, y0) to (x1, y1) on the image. You can pass x0, y0, x1, y1 individually or to a tuple (x0, y0, x1, y1). Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Thickness The thickness of the control line. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_image(image, x, y[, x_scale=1.0[, y_scale=1.0[, mask=None]]]) Draw an image whose top left corner starts at position x, y. You can pass x, y alone or pass it to a tuple (x, y). X_scale Controls the extent to which the image is scaled in the x direction (floating point). Y_scale Controls the extent to which the image is scaled in the y direction (floating point). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. You can use the mask mask to draw. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.draw_keypoints(keypoints[, color[, size=10[, thickness=1[, fill=False]]]]) Draw a point of a feature point object on the image. Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Size Controls the size of feature points. Thickness The thickness of the control line. Set fill to True to fill the feature points. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.flood_fill(x, y[, seed_threshold=0.05[, floating_threshold=0.05[, color[, invert=False[, clear_background=False[, mask=None]]]]]) The area where the image is filled starting from position x, y. You can pass x, y alone or pass it to a tuple (x, y). Seed_threshold Controls the difference between the pixels in the fill area and the original start pixel. Floating_threshold Controls the difference between pixels in the fill area and any adjacent pixels. Color is the RGB888 tuple for grayscale or RGB565 images. The default is white. However, you can also pass the base pixel value of the grayscale image (0-255) or the byte of the RGB565 image to invert the RGB565 value. Pass invert to True to repopulate everything outside the flood_fill connection area. Pass clear_background as True and zero the remaining flood_fill pixels that are not recolored. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask will be evaluated at flood_fill. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.binary(thresholds[, invert=False[, zero=False[, mask=None]]]) Sets all pixels in the image to black or white depending on whether the pixel is within the threshold in the threshold list thresholds. The thresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the range of colors you want to track. For grayscale images, each tuple needs to contain two values ​​- the minimum gray value and the maximum gray value. Only pixel regions that fall between these thresholds are considered. For RGB565 images, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi) - the minimum and maximum values ​​for the LAB L, A and B channels, respectively. For ease of use, this feature will automatically fix the minimum and maximum values ​​of the exchange. Also, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, the remaining thresholds are assumed to be in the maximum range. annotation To get the threshold of the tracked object, simply select (click and drag) the tracking object in the IDE framebuffer. The histogram will be updated accordingly to the area. Then just write down the color distribution in the starting and falling positions in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, the threshold is manually determined. You can also determine the color threshold by going to Tools -> Machine Vision -> Threshold Editor in the OpenMV IDE and dragging the slider from the GUI window. Invert Reverses the threshold operation, where pixels are matched outside of the known color range, not within the known color range. Set zero to True to make the threshold pixel zero and leave the pixels that are not in the threshold list unchanged. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.invert() Change binary image 0 (black) to 1 (white) and 1 (white) to 0 (black) to flip all pixel values ​​in the binary image very quickly. Returns an image object so that you can use the . notation to call another method. Compressed images and Bayer images are not supported. image.b_and(image[, mask=None]) Use another image to perform a logical AND operation with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.b_nand(image[, mask=None]) Use another image to perform a logical AND operation with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.b_or(image[, mask=None]) Use another image to perform a logical OR operation with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.b_nor(image[, mask=None]) Use another image to perform a logical OR operation with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.b_xor(image[, mask=None]) Use another image to perform an exclusive OR operation with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.b_xnor(image[, mask=None]) Use another image to logically AND the same image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.erode(size[, threshold[, mask=None]]) Remove pixels from the edges of the split area. This method is implemented by convolving the kernel of ((size2)+1)x((size2)+1) pixels on the convolution image. If the sum of the adjacent pixel sets is smaller than threshold, then the center pixel of the kernel is performed. Return to zero. If the threshold is not set, this method functions as the standard corrosion method. If the threshold is set, you can specify a specific pixel to be etched. For example, set a threshold of 2 around pixels that are less than 2 pixels. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.dilate(size[, threshold[, mask=None]]) Add pixels to the edges of the split area. This method is implemented by convolving the kernel of ((size2)+1)x((size2)+1) pixels on the convolution image. If the sum of the adjacent pixel sets is greater than threshold, the central pixel of the kernel is performed. Settings. If the threshold is not set, this method functions as the standard corrosion method. If the threshold is set, you can specify a specific pixel to be etched. For example, set a threshold of 2 around pixels that are less than 2 pixels. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.open(size[, threshold[, mask=None]]) The image is subjected to corrosion and expansion in sequence. See image.erode() and image.dilate() for more information. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.close(size[, threshold[, mask=None]]) The image is expanded and etched in sequence. See image.erode() and image.dilate() for more information. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.top_hat(size[, threshold[, mask=None]]) Returns the difference between the original image and the image after executing the image.open() function. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Compressed images and bayer images are not supported. image.black_hat(size[, threshold[, mask=None]]) Returns the difference between the original image and the image after executing the image.close() function. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Compressed images and bayer images are not supported. image.negate() Flip (number invert) all pixel values ​​in the image very quickly. The value of the pixel value of each color channel is converted. Example: (255 - pixel). Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.replace(image[, hmirror=False[, vflip=False[, mask=None]]]) Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Set hmirror to True to replace the image with a horizontal mirror. Set vflip to True to replace the image with a vertical flip. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.add(image[, mask=None]) Add two images to each other in pixels. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.sub(image[, reverse=False[, mask=None]]) The two images are subtracted from each other by pixel. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Set reverse to True to reverse the subtraction from this_image-image to image-this_image . Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.mul(image[, invert=False[, mask=None]]) Multiply two images by pixel by pixel. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Setting invert to True changes the multiplication operation from ab to 1/((1/a)(1/b)). In particular, this brightens the image rather than darkening the image (eg, multiply and burn operations). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.div(image[, invert=False[, mask=None]]) Divide this image by another image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Set invert to True to change the division direction from a/b to b/a. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.min(image[, mask=None]) At the pixel level, replace the pixels in this image with the smallest pixel value between this image and another image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV4. image.max(image[, mask=None]) Replace pixels in this image at the pixel level with the maximum pixel value between this image and another image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.difference(image[, mask=None]) The two images are taken to each other in absolute values. Example: For each color channel, replace each pixel with ABS (this.pixel-image.pixel). Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Mask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.blend(image[, alpha=128[, mask=None]]) Combine another image image with this image. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Alpha controls how much other images are to be blended into this image. alpha should be an integer value between 0 and 256. A value close to zero will mix more images into this image, and close to 256 is the opposite. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.histeq([adaptive=False[, clip_limit=-1[, mask=None]]]) Run a histogram equalization algorithm on the image. Histogram equalization normalizes contrast and brightness in the image. If adaptive passes to True, the adaptive histogram equalization method will be run on the image, which is usually better than the non-adaptive histogram qualification, but runs longer. Clip_limit provides a way to limit the contrast of adaptive histogram equalization. A good histogram equalization contrast limited image can be generated using a small value (eg 10). Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.mean(size, [threshold=False, [offset=0, [invert=False, [mask=None]]]]]) Standard mean blur filtering using a box filter. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. Median(size, percentile=0.5, threshold=False, offset=0, invert=False, mask]) Run median filtering on the image. Median filtering is the best filtering to smooth the surface, but at very slow speeds, while preserving the edges. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. Percentile Controls the percentile of the values ​​used in the kernel. By default, each pixel is replaced with an adjacent fiftyth percentile (center). You can set this value to 0 when using minimum filtering, to 0.25 for lower quartile filtering, to 0.75 for upper quartile filtering, and to 1 for maximum filtering. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.mode(size[, threshold=False, offset=0, invert=False, mask]) Run a majority filter on the image, replacing each pixel with the pattern of adjacent pixels. This method works well on grayscale images. However, due to the non-linear nature of this operation, many artifacts are produced on the edges of the RGB image. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core). If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.midpoint(size[, bias=0.5, threshold=False, offset=0, invert=False, mask]) Run midpoint filtering on the image. This filter finds the midpoint of the neighborhood of each pixel in the image ((max-min)/2). Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. Bias Controls the minimum/maximum degree of image blending. 0 is only for minimum filtering and 1 is for maximum filtering only. You can minimize/maximize filtering of images with bias. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.morph(size, kernel, mul=Auto, add=0) The image is convolved through the filter kernel. This allows you to perform a general convolution on the image. Size Controls the size of the kernel to ((size2)+1)x((size2)+1) pixels. Kernel The kernel used to convolve the image, either as a tuple or as a list of values ​​[-128:127]. Mul is the number used to multiply the result of the convolutional pixel. If not set, it defaults to a value that will prevent scaling in the convolution output. Add is the number used to add the convolution result to each pixel. Mul can be used for global contrast adjustment, and add can be used for global brightness adjustment. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. image.gaussian(size[, unsharp=False[, mul[, add=0[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]]) The image is convolved by a smooth Gaussian kernel. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. If unsharp is set to True, this method does not perform Gaussian filtering only, but performs an unsharp masking operation to improve the image sharpness of the edges. Mul is the number used to multiply the result of the convolutional pixel. If not set, it defaults to a value that will prevent scaling in the convolution output. Add is the number used to add the convolution result to each pixel. Mul can be used for global contrast adjustment, and add can be used for global brightness adjustment. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.laplacian(size[, sharpen=False[, mul[, add=0[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]]) The image is convolved by edge detection of the Laplacian kernel. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. If sharpen is set to True, this method will instead sharpen the image instead of just outputting edge-detected images that have not been thresholded. Increase the kernel size and increase the image clarity. Mul is the number used to multiply the result of the convolutional pixel. If not set, it defaults to a value that will prevent scaling in the convolution output. Add is the number used to add the convolution result to each pixel. Mul can be used for global contrast adjustment, and add can be used for global brightness adjustment. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.bilateral(size[, color_sigma=0.1[, space_sigma=1[, threshold=False[, offset=0[, invert=False[, mask=None]]]]]) The image is convolved by a bilateral filter. A bilateral filter smoothes the image while maintaining the edges in the image. Size is the size of the kernel. Take 1 (3x3 core), 2 (5x5 core) or higher. The color_sigma control uses a bilateral filter to match the proximity of the color. Increasing this value increases the color blur. Space_sigma controls the degree to which pixels are blurred in space. Increasing this value increases pixel blur. If you want to adaptively set the threshold on the output of the filter, you can pass the threshold=True parameter to initiate adaptive threshold processing of the image, which is based on the brightness of the ambient pixel (the brightness of the pixels around the kernel function). Set to 1 or 0. A negative offset value sets more pixels to 1, while a positive value only sets the strongest contrast to 1. Set invert to invert the result output of the binary image. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.cartoon(size[, seed_threshold=0.05[, floating_threshold=0.05[, mask=None]]]) Roam the image and fill all the pixel areas in the image using the flood-fills algorithm. This effectively removes texture from the image by flattening the colors in all areas of the image. For best results, the image should have a lot of contrast so that the areas don't penetrate too easily. Seed_threshold Controls the difference between the pixels in the fill area and the original start pixel. Floating_threshold Controls the difference between pixels in the fill area and any adjacent pixels. Mask is another image that is used as a pixel-level mask for drawing operations. The mask should be an image with only black or white pixels and should be the same size as the image you are drawing. Only the pixels set in the mask are modified. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.remove_shadows([image]) Remove the shadow from the image. If the current image does not have a \"shadowless\" version, this method will attempt to remove the shadow from the image, but there is no true unshaded image basis. This algorithm is suitable for removing shadows in a flat, uniform background. Note that this method takes many seconds to run and is only suitable for removing shadows in real time, dynamically generating an unshadowed version of the image. Future versions of the algorithm will work for more environments, but equally slow. If the current image has a \"shadowless\" version, this method will remove all shadows in the image using the \"true source\" background unshadowed image to filter out the shadows. Non-shaded pixels are not filtered out, so you can add new objects that didn't exist before to the scene, and any non-shaded pixels in those objects will be displayed. Returns an image object so that you can use the . notation to call another method. Only RGB565 images are supported. This method is not available on OpenMV Cam M4. image.chrominvar() Remove the lighting effect from the image, leaving only the color gradient. Faster than image.illuminvar() but affected by shadows. Returns an image object so that you can use the . notation to call another method. Only RGB565 images are supported. This method is not available on OpenMV Cam M4. image.illuminvar() Remove the lighting effect from the image, leaving only the color gradient. Slower than image.chrominvar() but not affected by shadows. Returns an image object so that you can use the . notation to call another method. Only RGB565 images are supported. This method is not available on OpenMV Cam M4. image.linpolar([reverse=False]) The image is re-projected from Cartesian coordinates to linear polar coordinates. Set reverse = True to re-project in the opposite direction. Linear polar re-projection converts image rotation to x translation. Compressed images are not supported. This method is not available on OpenMV Cam M4. image.logpolar([reverse=False]) The image is re-projected from Cartesian coordinates to log polar coordinates. Set reverse = True to re-project in the opposite direction. Log-polar polar re-projection converts the rotation of the image to x translation and zoom to y translation. Compressed images are not supported. This method is not available on OpenMV Cam M4. image.lens_corr([strength=1.8[, zoom=1.0]]) Perform lens distortion correction to remove the fisheye effect caused by the lens. Strength is a floating point number that determines how much the fisheye effect is applied to the image. By default, try the value of 1.8 first, then adjust this value to make the image show the best results. Zoom is the value at which the image is scaled. The default is 1.0. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. img.rotation_corr([x_rotation=0.0[, y_rotation=0.0[, z_rotation=0.0[, x_translation=0.0[, y_translation=0.0[, zoom=1.0]]]]]) The perspective problem in the image is corrected by performing a 3D rotation of the frame buffer. X_rotation is the degree to which the image is rotated in the frame buffer around the x-axis (this causes the image to rotate up and down). Y_rotation is the degree of rotation of the image around the y-axis in the frame buffer (ie, the image is rotated left and right). Z_rotation is the degree by which the image is rotated in the frame buffer around the z-axis (ie, the image is rotated to the appropriate position). X_translation is the number of units that move the image to the left or right after rotation. Because this transformation is applied in 3D space, the unit is not a pixel... Y_translation is the number of units that move the image up or down after rotation. Because this transformation is applied in 3D space, the unit is not a pixel... Zoom is the amount that is scaled by the image. By default 1.0. Returns an image object so that you can use the . notation to call another method. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.get_similarity(image) Returns a \"similarity\" object describing the two images using the SSIM algorithm to compare the similarities of 8x8 pixel patches between the two images. Image can be an image object, the path to an uncompressed image file (bmp/pgm/ppm), or a scalar value. If a scalar value, the value can be an RGB888 tuple or a base pixel value (eg, an 8-bit grayscale of a grayscale image or a byte-inverted RGB565 value of an RGB image). Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.get_histogram([thresholds[, invert=False[, roi[, bins[, l_bins[, a_bins[, b_bins]]]]]]) Normalize histogram operations on all color channels of roi and return histogram objects. Please refer to the histogram object for more information. You can also call this method using image.get_hist or image.histogram . If you pass the thresholds list, the histogram information will only be calculated from the pixels in the threshold list. The thresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the range of colors you want to track. For grayscale images, each tuple needs to contain two values ​​- the minimum gray value and the maximum gray value. Only pixel regions that fall between these thresholds are considered. For RGB565 images, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi) - the minimum and maximum values ​​for the LAB L, A and B channels, respectively. For ease of use, this feature will automatically fix the minimum and maximum values ​​of the exchange. Also, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, the remaining thresholds are assumed to be in the maximum range. annotation To get the threshold of the tracked object, simply select (click and drag) the tracking object in the IDE framebuffer. The histogram will be updated accordingly to the area. Then just write down the color distribution in the starting and falling positions in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, the threshold is manually determined. You can also determine the color threshold by going to Tools -> Machine Vision -> Threshold Editor in the OpenMV IDE and dragging the slider from the GUI window. Invert Reverses the threshold operation, where pixels are matched outside of the known color range, not within the known color range. Unless you need to use color statistics for advanced operations, simply use the image.get_statistics() method instead of this method to see the pixel areas in the image. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Bins and other bins are the number of bins used for the histogram channel. For grayscale images, use bins, for RGB565 images, use each of the other channels. The bin count for each channel must be greater than 2. In addition, it makes no sense to set the bin count to a number greater than the unique pixel value of each channel. By default, the histogram will have the maximum number of bins per channel. Compressed images and bayer images are not supported. image.get_statistics([thresholds[, invert=False[, roi[, bins[, l_bins[, a_bins[, b_bins]]]]]]) Calculates the average, median, value, standard deviation, minimum, maximum, lower quartile, and upper quartile for each color channel in roi and returns a data object. See the statistics object for more information. You can also call this method using image.get_stats or image.statistics . If you pass the thresholds list, the histogram information will only be calculated from the pixels in the threshold list. The thresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the range of colors you want to track. For grayscale images, each tuple needs to contain two values ​​- the minimum gray value and the maximum gray value. Only pixel regions that fall between these thresholds are considered. For RGB565 images, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi) - the minimum and maximum values ​​for the LAB L, A and B channels, respectively. For ease of use, this feature will automatically fix the minimum and maximum values ​​of the exchange. Also, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, the remaining thresholds are assumed to be in the maximum range. annotation To get the threshold of the tracked object, simply select (click and drag) the tracking object in the IDE framebuffer. The histogram will be updated accordingly to the area. Then just write down the color distribution in the starting and falling positions in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, the threshold is manually determined. You can also determine the color threshold by going to Tools -> Machine Vision -> Threshold Editor in the OpenMV IDE and dragging the slider from the GUI window. Invert Reverses the threshold operation, where pixels are matched outside of the known color range, not within the known color range. You can use this method when you need to get a pixel area information in an image. For example, if you want to use the frame difference method to detect motion, you need to use this method to determine the change in the color channel of the image, which triggers the motion detection threshold. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Bins and other bins are the number of bins used for the histogram channel. For grayscale images, use bins, for RGB565 images, use each of the other channels. The bin count for each channel must be greater than 2. In addition, it makes no sense to set the bin count to a number greater than the unique pixel value of each channel. By default, the histogram will have the maximum number of bins per channel. Compressed images and bayer images are not supported. image.get_regression(thresholds[, invert=False[, roi[, x_stride=2[, y_stride=1[, area_threshold=10[, pixels_threshold=10[, robust=False]]]]]]) Perform linear regression calculations on all threshold pixels of the image. This calculation is done by least squares, which is usually faster, but does not handle any outliers. If robust is True, the Theil index will be used. The Theil index calculates the median of all slopes between all threshold pixels in the image. If you set too many pixels after the threshold transition, even on an 80x60 image, this N^2 operation may lower your FPS below 5. However, as long as the number of pixels to be set after the threshold conversion is small, linear regression is effective even when the threshold pixel exceeding 30% is an abnormal value. This method returns an image.line object. How to easily use straight line objects, see the following blog post: https://openmv.io/blogs/news/linear-regression-line-following The thresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the range of colors you want to track. For grayscale images, each tuple needs to contain two values ​​- the minimum gray value and the maximum gray value. Only pixel regions that fall between these thresholds are considered. For RGB565 images, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi) - the minimum and maximum values ​​for the LAB L, A and B channels, respectively. For ease of use, this feature will automatically fix the minimum and maximum values ​​of the exchange. Also, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, the remaining thresholds are assumed to be in the maximum range. To get the threshold of the tracked object, simply select (click and drag) the tracked object in the IDE framebuffer. The histogram will be updated accordingly to the area. Then just write down the color distribution in the starting and falling positions in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, the threshold is manually determined. You can also determine the color threshold by going to Tools -> Machine Vision -> Threshold Editor in the OpenMV IDE and dragging the slider from the GUI window. Invert Reverses the threshold operation, where pixels are matched outside of the known color range, not within the known color range. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. X_stride is the number of x pixels to skip when calling a function. Y_stride is the number of y pixels to skip when calling a function. Returns None if the bounding box area after the regression is smaller than area_threshold . Returns None if the number of pixels after regression is less than pixel_threshold . Compressed images and bayer images are not supported. image.find_blobs(thresholds[, invert=False[, roi[, x_stride=2[, y_stride=1[, area_threshold=10[, pixels_threshold=10[, merge=False[, margin=0[, threshold_cb =None[, merge_cb=None]]]]]]]]]]]) Finds all the patches in the image and returns a list of patch objects that include each patch. Please observe the image.blob object for more information. The thresholds must be a list of tuples. [(lo, hi), (lo, hi), ..., (lo, hi)] Define the range of colors you want to track. For grayscale images, each tuple needs to contain two values ​​- the minimum gray value and the maximum gray value. Only pixel regions that fall between these thresholds are considered. For RGB565 images, each tuple needs to have six values ​​(l_lo, l_hi, a_lo, a_hi, b_lo, b_hi) - the minimum and maximum values ​​for the LAB L, A and B channels, respectively. For ease of use, this feature will automatically fix the minimum and maximum values ​​of the exchange. Also, if the tuple is greater than six values, the remaining values ​​are ignored. Conversely, if the tuple is too short, the remaining thresholds are assumed to be in the maximum range. annotation To get the threshold of the tracked object, simply select (click and drag) the tracking object in the IDE framebuffer. The histogram will be updated accordingly to the area. Then just write down the color distribution in the starting and falling positions in each histogram channel. These will be the low and high values ​​of thresholds. Since the difference between the upper and lower quartiles is small, the threshold is manually determined. You can also determine the color threshold by going to Tools -> Machine Vision -> Threshold Editor in the OpenMV IDE and dragging the slider from the GUI window. Invert Reverses the threshold operation, where pixels are matched outside of the known color range, not within the known color range. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. X_stride is the number of x pixels that need to be skipped when looking for a patch. Once the color block is found, the line fill algorithm will be precise pixels. If the color block is known to be large, increase x_stride to increase the speed at which the color block is found. Y_stride is the number of y pixels that need to be skipped when looking for a patch. Once the color block is found, the line fill algorithm will be precise pixels. If the color block is known to be large, increase y_stride to increase the speed at which the patch is found. If the bounding box area of ​​a patch is smaller than area_threshold, it will be filtered out. If the number of pixels in a patch is smaller than pixel_threshold, it will be filtered out. Merge If True, merges all the patches that have not been filtered. The border rectangles of these patches overlap each other. Margin can be used in the intersection test to increase or decrease the size of the patch boundary rectangle. For example, patches with edges of 1 and border rectangles of 1 will be merged. Merging patches allows color code tracking to be achieved. Each patch object has a code value code , which is a bit vector. For example, if you enter two color thresholds in image.find_blobs, the first threshold code is 1 and the second code is 2 (the third code is 4, the fourth code is 8, and so on). Merged patches use logical OR operations on all code so you know the color that produced them. This allows you to track two colors, and if you get a patch object in two colors, it might be a color code. If you use a strict color range and cannot fully track all the pixels of the target object, you may need to merge the patches. Finally, if you want to merge the patches, but don't want the two different threshold colors to be merged, just call image.find_blobs twice, and the different threshold patches will not be merged. The threshold_cb can be set to a function that calls each color block after threshold filtering to filter it out of the list of patches to be merged. The callback function will receive a parameter: the patch object to be filtered. The callback function then returns True to preserve the color block or return False to filter the color block. Merge_cb can be set to function to call two patches to be merged to disable or permit the merge. The callback function will receive two arguments - two patch objects that will be merged. The callback function must return True to merge the color blocks, or return False to prevent color block merging. Compressed images and bayer images are not supported. image.find_lines([roi[, x_stride=2[, y_stride=1[, threshold=1000[, theta_margin=25[, rho_margin=25]]]]]) Use the Hough transform to find all the lines in the image. Returns a list of image.line objects. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. X_stride is the number of x pixels that need to be skipped during the Hough transform. If the line is known to be large, increase x_stride. Y_stride is the number of y pixels that need to be skipped during the Hough transform. If the line is known to be large, increase y_stride. Threshold Controls the line that is detected from the Hough transform. Only return lines that are greater than or equal to threshold. The correct threshold value for the application depends on the image. Note: The magnitude of a line is the sum of the size of all Sobel filter pixels that make up the line. Theta_margin controls the merging of the lines being monitored. The part of the line angle of theta_margin is merged with the part of the line p value of rho_margin. Rho_margin controls the merging of the lines being monitored. The part of the line angle of theta_margin is merged with the part of the line p value of rho_margin. The method performs a Hough transform by running a Sobel filter on the image and using the amplitude and gradient response of the filter. No pre-processing of the image is required. However, cleaning up the image filter results in more stable results. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.find_line_segments([roi[, merge_distance=0[, max_theta_difference=15]]]) Use Hough transform to find line segments in the image. Returns a list of image.line objects. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle. The operating range is limited to pixels in the roi area. Merge_distance specifies the maximum number of pixels between two segments that can be separated from each other without being merged. Max_theta_difference is the maximum angle difference between the two line segments that merge_distancede will merge above. This method uses the LSD library (also used by OpenCV) to find line segments in the image. This is a bit slow, but very accurate, the line segments won't jump. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.find_circles([roi[, x_stride=2[, y_stride=1[, threshold=2000[, x_margin=10[, y_margin=10[, r_margin=10]]]]]]) Use the Hough transform to find a circle in the image. Returns a list of image.circle objects (see above). Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle. The operating range is limited to pixels in the roi area. X_stride is the number of x pixels that need to be skipped during the Hough transform. If the circle is known to be large, increase x_stride. Y_stride is the number of y pixels that need to be skipped during the Hough transform. If the circle is known to be large, increase y_stride. Threshold Controls the circle detected from the Hough transform. Only returns a circle greater than or equal to threshold. The correct threshold value for the application depends on the image. Note: The magnitude of a circle is the sum of the size of all Sobel filter pixels that make up the circle. X_margin controls the merge of the detected circles. The round pixels are partially merged for x_margin , y_margin , and r_margin . Y_margin controls the merge of the detected circles. The round pixels are partially merged for x_margin , y_margin , and r_margin . R_margin Controls the merge of the detected circles. The round pixels are partially merged for x_margin , y_margin , and r_margin . Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.find_rects([roi=Auto, threshold=10000]) Use the same quad detection algorithm used to find AprilTAg to find rectangles in the image. Ideal for rectangles that contrast sharply with the background. AprilTag's quad detection can handle arbitrary scaling/rotating/cutting rectangles. Returns a list of image.rect objects. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle. The operating range is limited to pixels in the roi area. The border size (by sliding the Sobel operator over all pixels on the edge of the rectangle and adding the value) is smaller than the rectangle of the threshold and is filtered from the return list. The correct value for threshold depends on your application/scenario. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.find_qrcodes([roi]) Find all the QR codes in roi and return a list of image.qrcode objects. Please refer to the image.qrcode object for more information. In order for this method to work successfully, the QR code on the image needs to be flat. By using the sensor.set_windowing function to zoom in at the center of the lens, the image.lens_corr function to dissipate the barrel distortion of the lens, or by replacing a lens with a narrow field of view, you get a flatter QR code that is unaffected by lens distortion. Some machine vision lenses do not cause barrel distortion, but they are much more expensive than the standard lenses offered by OpenMV, which is an undistorted lens. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. Image.find_apriltags([roi[, families=image.TAG36H11[, fx[, fy[, cx[, cy]]]]]) Find all AprilTags in roi and return a list of image.apriltag objects. Please refer to the image.apriltag object for more information. Compared to QR codes, AprilTags can be detected in longer distances, poorer light, and more distorted image environments. AprilTags can handle all kinds of image distortion problems, and the QR code does not. That is, AprilTags can only encode the digital ID as its payload. AprilTags can also be used for localization. Each image.apriltag object returns its three-dimensional position information and rotation angle from the camera. The position information is determined by fx, fy, cx, and cy, which are the focal length and center point of the image in the X and Y directions, respectively. Create AprilTags using the Tag Generator tool built into OpenMV IDE. The tag generator creates a printable 8.5\"x11\" AprilTags. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. The family is the bit mask of the tag family to be decoded. Is a logical or: image.TAG16H5 image.TAG25H7 image.TAG25H9 image.TAG36H10 image.TAG36H11 image.ARTOOLKIT The default setting is the best image.TAG36H11 tag family. Note: every time a tag family is enabled, the speed of find_apriltags will be slightly slower. Fx is the focal length of the camera's x-direction in pixels. The value of the standard OpenMV Cam is (2.8 / 3.984) * 656, which is obtained by dividing the focal length value of the millimeter by the length of the photosensitive element in the X direction and multiplying by the number of pixels of the photosensitive element in the X direction (for the OV7725 photosensitive element) In terms of). Fy is the focal length of the camera in the y direction in pixels. The value of the standard OpenMV Cam is (2.8 / 2.952) * 488, which is obtained by dividing the focal length value of the millimeter meter by the length of the photosensitive element in the Y direction, and multiplying by the number of pixels of the photosensitive element in the Y direction (for the OV7725 photosensitive element) In terms of). Cx is the center of the image, image.width()/2 , not roi.w()/2 . Cy is the center of the image, image.height()/2, not roi.h()/2 . Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. Image.find_datamatrices([roi[, effort=200]]) Finds all the data matrices in roi and returns a list of image.datamatrix objects. Please refer to the image.datamatrix object for more information. In order for this method to work successfully, the rectangular code on the image needs to be flat. By using the sensor.set_windowing function to zoom in on the center of the lens, the image.lens_corr function to dissipate the barrel distortion of the lens, or by replacing a lens with a narrow field of view, you get a flatter rectangular code that is unaffected by lens distortion. Some machine vision lenses do not cause barrel distortion, but they are much more expensive than the standard lenses offered by OpenMV, which is an undistorted lens. Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. The effort controls the time used to find the rectangular code match. The default value of 200 should apply to all use cases. However, you may also increase the detection at the expense of the frame rate or increase the frame rate at the expense of detection. Note: If the effort is set below about 160, you will not be able to perform any tests; instead, you can set it to any high value you want, but if the setting is higher than 240, the detection rate will not continue to increase. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. image.find_barcodes([roi]) Find all the 1D barcodes in roi and return a list of image.barcode objects. Please refer to the image.barcode object for more information. For best results, use a long 640, wide 40/80/160 window. The lower the degree of verticality, the faster the speed. Since the barcode is a linear one-dimensional image, it is only necessary to have a higher resolution in one direction and a lower resolution in the other direction. Note: This function performs horizontal and vertical scanning, so you can use a window with a width of 40/80/160 and a length of 480. Finally, be sure to adjust the lens so that the bar code is positioned where the focal length produces the sharpest image. Fuzzy barcodes cannot be decoded. This function supports all 1D barcodes: image.EAN2 image.EAN5 image.EAN8 image.UPCE image.ISBN10 image.UPCA image.EAN13 image.ISBN13 image.I25 image.DATABAR (RSS-14) image.DATABAR_EXP (RSS-Expanded) image.CODABAR image.CODE39 image.PDF417 image.CODE93 image.CODE128 Roi is a region of interest (x, y, w, h) of a rectangle to be copied. If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Compressed images and bayer images are not supported. This method is not available on OpenMV Cam M4. Image.find_displacement(template[, roi[, template_roi[, logpolar=False]]]) Find the transform offset for this image from the template. This method can be used to make light flow. This method returns an image.displacement object containing the results of the displacement calculation using phase correlation. Roi is a rectangular area (x, y, w, h) that needs to be processed. If not specified, it is equal to the image rectangle. Template_roi is the rectangular area (x, y, w, h) that needs to be processed. If not specified, it is equal to the image rectangle. Roi and template roi must have the same w/h, but x/y can be anywhere in the image. You can slide a smaller rois on a larger image to get a smoother image of the light flow. Image.find_displacement usually calculates the x/y translation between two images. However, if you set logpolar = True , it will find a change in rotation and scaling between the two images. The same image.displacement object results in two possible feedbacks. Compressed images and bayer images are not supported. annotation Use this method on images with a uniform length and width (for example, sensor.B64X64). This method is not available on OpenMV Cam M4. image.find_number(roi) A LENET-6 CNN (Convolutional Neural Network) trained on the MINST data set is run to detect numbers in the 28x28 ROI located anywhere on the image. Returns a tuple containing integers and floating point numbers representing the detected number (0-9) and the confidence of the detection (0-1). Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only grayscale images are supported. annotation This method is experimental. This method may be removed if you run any CNN that Caffe trains on your PC in the future. This function has been removed by the latest 3.0.0 firmware. This method is not available on OpenMV Cam M4. image.classify_object(roi) Run CIFAR-10 CNN on the ROI of the image to detect aircraft, cars, birds, cats, deer, dogs, frogs, horses, boats and trucks. This method automatically scales the image internally to 32x32 to feed to the CNN. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only RGB565 images are supported. annotation This method is experimental. This method may be removed if you run any CNN that Caffe trains on your PC in the future. This method is not available on OpenMV Cam M4. Image.find_template(template, threshold[, roi[, step=2[, search=image.SEARCH_EX]]]) Try to find the location of the first template match in the image using the Normalized Cross Correlation (NCC) algorithm. Returns the bounding box tuple (x, y, w, h) of the matching position, otherwise returns None. Template is a small image object that matches this image object. Note: Both images must be grayscale. Threshold is a floating point number (0.0-1.0), where a smaller value increases the detection rate while increasing the false positive rate. Conversely, a higher value reduces the detection rate while reducing the false positive rate. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Step is the number of pixels that need to be skipped when looking up the template. Skip pixels can greatly increase the speed at which the algorithm runs. This method is only applicable to the algorithm in SERACH_EX mode. Search can be used for image.SEARCH_DS or image.SEARCH_EX. image.SEARCH_DS The algorithm used for searching templates is faster than image.SEARCH_EX, but if the template is around the edges of the image, it may not be searched successfully. image.SEARCH_EX performs a more detailed search of the image, but it runs much faster than image.SEARCH_DS . Only grayscale images are supported. image.find_features(cascade[, threshold=0.5[, scale=1.5[, roi]]]) This method searches for images of all regions that match Haar Cascade and returns a list of bounding box rectangle tuples (x, y, w, h) for these features. If no features are found, a blank list is returned. Cascade is a Haar Cascade object. See image.HaarCascade() for more information. Threshold is a floating point number (0.0-1.0), where a smaller value increases the detection rate while increasing the false positive rate. Conversely, a higher value reduces the detection rate while reducing the false positive rate. Scale is a floating point number that must be greater than 1.0. A higher scale factor runs faster, but its image matching is poorer. The ideal value is between 1.35 and 1.5. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only grayscale images are supported. image.find_eye(roi) Find the pupil in the region of interest (x, y, w, h) around the eye. Returns a tuple containing the position of the pupil (x, y) in the image. If no pupil is found, it returns (0,0). Before using this function, you first need to search for someone's face using image.find_features() and Haar operator frontalface. Then use image.find_features and Haar operator find_eye to search for the eye on the face. Finally, this method is called on each eye ROI returned after calling the image.find_features function to get the coordinates of the pupil. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only grayscale images are supported. image.find_lbp(roi) The LBP (local binary mode) key points are extracted from the ROI tuple (x, y, w, h). You can use the image.match_descriptor function to compare two sets of key points to get the matching distance. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only grayscale images are supported. image.find_keypoints([roi[, threshold=20[, normalized=False[, scale_factor=1.5[, max_keypoints=100[, corner_detector=image.CORNER_AGAST]]]]]) The ORB key points are extracted from the ROI tuple (x, y, w, h). You can use the image.match_descriptor function to compare two sets of key points to get the matching area. If no key is found, return None. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Threshold is a number that controls the number of extractions (values ​​0-255). For the default AGAST corner detector, this value should be around 20. For the FAST corner detector, this value is approximately 60-80. The lower the threshold, the more corner points you extract. Normalized is a boolean value. If True, close the extraction keypoint at multiple resolutions. If you don't care about handling extensions and want the algorithm to run faster, set it to True. Scale_factor is a floating point number that must be greater than 1.0. A higher scale factor runs faster, but its image matching is poorer. The ideal value is between 1.35 and 1.5. Max_keypoints is the maximum number of key points a keypoint object can hold. If the key point object is too large and causes memory problems, lower the value. Corner_detector is the corner detector algorithm used to extract key points from an image. Can be image.CORNER_FAST or image.CORNER_AGAST . The FAST corner detector runs faster, but with less accuracy. Only grayscale images are supported. image.find_edges(edge_type[, threshold]) Turn the image into black and white and leave only the edges as white pixels. image.EDGE_SIMPLE - Simple threshold high-pass filtering algorithm image.EDGE_CANNY - Canny edge detection algorithm Threshold is a binary tuple containing a low threshold and a high threshold. You can control the edge quality by adjusting this value. The default is (100, 200). Only grayscale images are supported. Find_hog([roi[, size=8]]) The pixels in the ROI are replaced with HOG (Directed Gradient Histogram) lines. Roi is a rectangular tuple of interest regions (x, y, w, h). If not specified, the ROI is the image rectangle of the entire image. The operating range is limited to pixels in the roi area. Only grayscale images are supported. This method is not available on OpenMV Cam M4. Constant image.SEARCH_EX Detailed template matching search. image.SEARCH_DS Faster template matching search. image.EDGE_CANNY Edge detection is performed on the image using the Canny edge detection algorithm. image.EDGE_SIMPLE Edge detection is performed on the image using a threshold high-pass filtering algorithm. image.CORNER_FAST High-speed low-accuracy corner detection algorithm for ORB key points image.CORNER_AGAST Low speed high accuracy algorithm for ORB key points. image.TAG16H5 Bitmask enumeration for the TAG1H5 tag group. Used in AprilTags. image.TAG25H7 Bitmask enumeration for the TAG25H7 tag group. Used in AprilTags. image.TAG25H9 Bitmask enumeration for the TAG25H9 tag group. Used in AprilTags. image.TAG36H10 Bitmask enumeration for the TAG36H10 tag group. Used in AprilTags. image.TAG36H11 Bitmask enumeration for the TAG36H11 tag group. Used in AprilTags. image.ARTOOLKIT The bit mask enumeration of the ARTOOLKIT tag group. Used in AprilTags. image.EAN2 EAN2 barcode type enumeration. image.EAN5 EAN5 barcode type enumeration. image.EAN8 EAN8 barcode type enumeration. image.UPCE UPCE barcode type enumeration. image.ISBN10 ISBN10 barcode type enumeration. image.UPCA UPCA barcode type enumeration. image.EAN13 EAN13 barcode type enumeration. image.ISBN13 ISBN13 barcode type enumeration. image.I25 I25 barcode type enumeration. image.DATABAR DATABAR barcode type enumeration. image.DATABAR_EXP DATABAR_EXP barcode type enumeration. image.CODABAR CODABAR barcode type enumeration. image.CODE39 CODE39 barcode type enumeration. image.PDF417 PDF417 barcode type enumeration (currently not working). image.CODE93 CODE93 barcode type enumeration. image.CODE128 CODE128 barcode type enumeration. "},"libs/machine_vision/cpufreq.html":{"url":"libs/machine_vision/cpufreq.html","title":"CPUfreq","keywords":"","body":"Cpufreq Cpu frequency module, support program to modify cpu and kpu frequency method Get the current frequency Get the current cpu and kpu frequency, this method has 2 return values import cpufreq cpu_freq,kpu_freq = cpufreq.get_current_frequencies() Parameters no return value cpu_freq: the current cpu frequency, the unit is M kpu_freq: the current kpu frequency, the unit is M Get the frequency of kpu support Since kpu is the rate obtained by dividing by pll1 and the current pll1 frequency is fixed at 400M, it is currently unable to support any frequency. Cpu theoretically supports arbitrary frequencies, but it will be biased according to the actual hardware. import cpufreq kpu_freqlist = cpufreq.get_kpu_supported_frequencies() Parameters no return value kpu_freqlist: kpu support frequency list Setting frequency Set the cpu or kpu frequency, please note that some peripherals may change performance after the frequency setting is completed. import cpufreq kpu_freqlist = cpufreq.set_frequency(cpu = cpu_freq, kpu = kpu_freq) Parameters Parameters can be entered in 1 or 2 of cpu or kpu cpu_freq: cpu frequency to be set, range [26,400] kpu_freq: The kpu frequency you want to set, please see the `kpu support frequency list. return value After using this interface, if the frequency does not change, it returns null. If the frequency changes, the machine will be restarted. Please confirm whether the current situation can be restarted before using this interface. "},"libs/machine_vision/video.html":{"url":"libs/machine_vision/video.html","title":"Video","keywords":"","body":"video Support play and record video with avi format Global Function open(path, record=False, interval=100000, quality=50, width=320, height=240, audio=False, sample_rate=44100, channels=1) Open a avi file to play or record Parameters path： file path, e.g. /sd/badapple.avi record： record video or not, if False just to play video interval： Record interval, unit: micro second, fps = 1000000/interval, default to 100000, that is 10 frames per second quality： jpeg compress quality(%), default to 50 width： record screen width, default to 320 height： record screen height, default to 240 audio： record audio or not, default to False sample_rate： sample rate of recorded audio, default to 44100 (44.1k) channels： channels of recorded audio, default to 1 Return Value Return a object, just support avi format yet, so just return a instance of avi class Class avi Get from video.open() play() Play video, decode one frame data(video or audio) every once called Return value 0: play end 1: playing 2: pause(reverve) 3: current frame is video 4: current frame is audio volume(volume) Set play volume Parameters volume: value:[0,100] Return value Set value, ranges: [0,100] record() Record video frame, it will block until the interval time up Return Value The length of current frame( video ) Examples Example 1: Play avi video Encode a video with format: screen size 320x240， MJEPG compress format, PCM format audio You can download avi video here: badapple.avi import video,time from Maix import GPIO fm.register(34, fm.fpioa.I2S0_OUT_D1) fm.register(35, fm.fpioa.I2S0_SCLK) fm.register(33, fm.fpioa.I2S0_WS) fm.register(8, fm.fpioa.GPIO0) wifi_en=GPIO(GPIO.GPIO0,GPIO.OUT) wifi_en.value(0) v = video.open(\"/sd/badapple.avi\") print(v) v.volume(50) while True: if v.play() == 0: print(\"play end\") break v.__del__() By default, it will use I2S0 to display audio, so we need to set their corresponding pins; Turn off WiFi because of the interference of Dock board WiFi on sound quality Example 2: Record Video import video, sensor, image, lcd, time lcd.init() sensor.reset() sensor.set_pixformat(sensor.RGB565) sensor.set_framesize(sensor.QVGA) sensor.run(1) sensor.skip_frames(30) v = video.open(\"/sd/capture.avi\", record=1, interval=200000, quality=50) i = 0 tim = time.ticks_ms() while True: tim = time.ticks_ms() img = sensor.snapshot() lcd.display(img) img_len = v.record(img) # print(\"record\",time.ticks_ms() - tim) i += 1 if i > 100: break print(\"finish\") v.record_finish() lcd.clear() You can cancel the print comment to see if the actual recording interval has reached the set frame interval (such as 200000us set here). The actual print should be 200ms, If the actual frame interval is greater than the set value, the actual performance does not meet the set requirements. You need to increase the set frame interval to decrease the frame rate. In addition, removing the display and printing can also increase the frame rate to some extent. "},"libs/peripheral_modules/":{"url":"libs/peripheral_modules/","title":"Peripheral Modules","keywords":"","body":"Peripheral Modules Here peripheral means offchip modules, for example: LCD、 Camera、 touchscreen etc. The peripheral related to vision are put into machine vision), modules as follows: lcd: Display image on LCD sensor: Get camera data, we name it as sensor just like openmv do, but not totally the same as openmv's, see the doc Other Modules: touchscreen: Touchscreen related operation, like get click status or get click coordinate "},"libs/peripheral_modules/touchscreen.html":{"url":"libs/peripheral_modules/touchscreen.html","title":"Touchscreen","keywords":"","body":"touchscreen Touchscreen related operation, like get click status or get click coordinate the drivers supported currently: ns2009 ( default ) To change driver, we need to rebuild the Maixpy firmware Global Function init(i2c=None, cal=None) Initialize touchscreen This API may be changed later, considering the different type of touchscreen Parameters i2c: Currently just support I2C touchscreen, so should give I2C object, we may rename this paramter or remove it later cal: Calibration data, a touple consist of 7 integer, get by touchscreen.calibrate() function calibrate() Calibrate touchscreen with LCD screen pixels Return Return a tuple consist of 7 integer, you can save it to file system or flash, use it in init function, so we no need to calibrate every power on read() Read the click status of touchscreen, and return coordinate of click( press ) Return 一个由 3 个整型值组成的元组 (status, x, y)， 注意这个值会一直保持上一个状态 A touple consist of 3 integet (status, x, y), be attention, the value always keep the last value if status did'nt change status： click status, values: touchscreen.STATUS_PRESS， touchscreen.STATUS_MOVE， touchscreen.STATUS_RELEASE x： x coordinate y： y coordinate Constant touchscreen.STATUS_PRESS The touchscreen is pressed, the firt value of tuple returned by read() touchscreen.STATUS_MOVE The touchscreen is pressed and pen is moving, the firt value of tuple returned by read() touchscreen.STATUS_RELEASE The touchscreen is released, the firt value of tuple returned by read() Examples Demo 1: Drawing Board Drawing board, you can clear content with boot key uncomment ts.calibrate() to execute calibration program import touchscreen as ts from machine import I2C import lcd, image from board import board_info from fpioa_manager import * board_info=board_info() fm.register(board_info.BOOT_KEY, fm.fpioa.GPIO1) btn_clear = GPIO(GPIO.GPIO1, GPIO.IN) lcd.init() i2c = I2C(I2C.I2C0, freq=400000, scl=30, sda=31) ts.init(i2c) #ts.calibrate() lcd.clear() img = image.Image() status_last = ts.STATUS_IDLE x_last = 0 y_last = 0 draw = False while True: (status,x,y) = ts.read() print(status, x, y) if draw: img.draw_line((x_last, y_last, x, y)) if status_last!=status: if (status==ts.STATUS_PRESS or status == ts.STATUS_MOVE): draw = True else: draw = False status_last = status lcd.display(img) x_last = x y_last = y if btn_clear.value() == 0: img.clear() ts.__del__() "},"application/":{"url":"application/","title":"Integrated Apps","keywords":"","body":"Integrated Application pye: Integrated MaixPy file editor. Directly edit files on the board using the serial port. nes: NES game emulator lvgl: LittlvGL GUI lib "},"application/pye.html":{"url":"application/pye.html","title":"MicroPython Editor","keywords":"","body":"pye Micropython Editor A file editor written by py, integrated into the MaixPy firmware. With it, you can directly edit files via the serial port terminal. Usage: from pye_mp import pye pye(\"/sd/boot.py\") "},"application/nes.html":{"url":"application/nes.html","title":"NES Simulator","keywords":"","body":"NES game emulator Classic NES game emulator, take us back to childhood! Or... Let us find a way to let it play itself! Function init(rc_type=nes.KEYBOARD, cs, mosi, miso, clk, repeat=16, vol=5) Initializes the NES emulator Parameters tc_type： Remote control type, keyboard（nes.KEYBOARD） （The serial port communicates with the computer's keyboard, it's not directly connected to the board's USB port...） or PS2 joystick（nes.JOYSTICK）。 A PS2 joystick is recommended for a better experience. Serial communication can't send more than one key at a time. If you want, you can try to write your own scripts here cs： If using a PS2 joystick with SPI interface, enter the cs pin number mosi： If using a PS2 joystick with SPI interface, enter the mosi pin number miso： If using a PS2 joystick with SPI interface, enter the miso pin number clk： If using a PS2 joystick with SPI interface, enter the clk pin number repeat： (Only for keyboard mode!) key repetition rate vol： Initial volume, can be adjusted later run(nes) Run a NES game (ROM) Parameters nes： File path of the game's ROM ， /sd/mario.nes for example Shortcuts Keyboard (serial port) move ： W A S D A ： J B ： K start ： M or Enter option： N or \\ exit ： ESC volume - ： - volume + ： = run speed - ： R run speed + ： F Joystick move ： ^ V -> A ： □ B ： × start ： START select： SELECT exit ： no volume - ： R2 volume + ： R1 run speed - ： L1 run speed + ： L2 Examples Demo 1： Keyboard (Serial port) import nes, lcd lcd.init(freq=15000000) nes.init(nes.KEYBOARD) nes.run(\"/sd/mario.nes\") Demo 2： PS2 joystick import nes, lcd lcd.init(freq=15000000) nes.init(nes.JOYSTICK, cs=19, clk=18, mosi=23, miso=21) nes.run(\"/sd/mario.nes\") "},"application/lvgl.html":{"url":"application/lvgl.html","title":"lvgl","keywords":"","body":"lvgl LittlevGL Refer to the official documentation: lvgl blog page Demo Demo 1: Buttion Display a button and tap it using the touchscreen import lvgl as lv import lvgl_helper as lv_h import lcd import time from machine import Timer from machine import I2C import touchscreen as ts i2c = I2C(I2C.I2C0, freq=400000, scl=30, sda=31) ts.init(i2c) lcd.init() lv.init() disp_drv = lv.disp_drv_t() lv.disp_drv_init(disp_drv) disp_drv.disp_flush = lv_h.flush disp_drv.disp_fill = lv_h.fill lv.disp_drv_register(disp_drv) indev_drv = lv.indev_drv_t() lv.indev_drv_init(indev_drv) indev_drv.type = lv.INDEV_TYPE.POINTER indev_drv.read = lv_h.read lv.indev_drv_register(indev_drv) scr = lv.obj() btn = lv.btn(scr) btn.align(lv.scr_act(), lv.ALIGN.CENTER, 0, 0) label = lv.label(btn) label.set_text(\"Button\") lv.scr_load(scr) while True: tim = time.ticks_ms() lv.tick_inc(5) lv.task_handler() while time.ticks_ms()-tim "},"advanced/compile.html":{"url":"advanced/compile.html","title":"Code compilation","keywords":"","body":"Source code compilation Compiled please refer to the source ports/k210-freertos directory README "},"advanced/code_struct.html":{"url":"advanced/code_struct.html","title":"Code structure","keywords":"","body":"Code structure This article mainly introduces the k210-freertos folder in the port directory of Micropython code, which is the code structure of the kendryte210 platform. Introduction to the directory Briefly introduce files and directories in k210-freertos file Code File main.c is outside the code of the program entry. If the contributing developer needs to modify the main function, we can edit it in this file. Script file Under normal circumstances, please do not modify the script file to avoid accidents. config.sh is a configuration script that needs to be used at compile time. It mainly uses export to configure variables in the shell environment to make the compilation work normally. build.sh is used to compile the code, please see the code compilation section for code compilation. clean_inc.sh for all mk files generated during compilation flash.sh is used to program in linux environment mk file The mk file is an intermediate file generated during the compilation process and is generally used for the path containing the code file. folder Code Folder The following directory is all the code for storing MaixPy mpy_support stores MicroPython code related to Openmv platform stores platform-related code such as sdk, drivers, etc. third_party stores portable third-party code, such as spiffs Other folders output stores the compiled output file tools to store the tool scripts needed for the development process, such as the package file system build stores the .o file during compilation. All the code folders have a build folder, which is used to store .o files. inc stores the mk file in the middle of each subdirectory. Generally, the files in this directory are not modified. docs for storing documents and routine demos Directory details Below we will detail the directories we use frequently during the development process to facilitate developers to develop faster. mpy_support The mpy_support folder is used to store all the code related to micropython, including micropython all platform porting code, such as mpconfigport.h, mpconfigboard.h, and so on. Also stores all micropython standard modules such as os, time, etc., as well as common hardware modules such as SPI, IIC, etc. standard_lib standard_lib is used to store the standard library code of micropython, such as machine, socket, os, etc. Each module has its own separate folder, and the include folder stores all the header files. You can refer to this when developing standard modules. omv omv stores the code related to the openmv port. If you need to develop modules such as lcd, sensor, and image, you can modify the files in the directory. Maix Maix stores the code of the platform feature function, such as FPIOA function, which is rare in other platforms, so we store the relevant code of FPIOA in the Maix directory. Functions that may be developed later, such as I2S and KPU, are stored here. builtin-py builtin-py stores the Python files built into MaixPy. Micropython supports compiling Python files into firmware. We store all the Python files we want to build in here so that they can be compiled into the firmware. Functions such as fm and board_info are implemented using the Python files here. platform Platform stores all platform related code, such as sdk, driver, etc. sdk sdk stores the software development kit for kendryte210. In general, we don't need to modify the code here. drivers drivers store code for common peripherals on the development board, such as lcd, flash, sd card, etc. third_party third_party stores all third-party porting code. If you need to use other third-party libraries or functions during development, you need to store the code in this directory. spiffs spiffs stores the porting code of the spiffs file system. During the open process, if you need to modify the configuration of the spiffs file system, you can find the configuration file and modify it in this directory. tools tool is a self-written function script used in the development process, such as packaging the file system, removing redundant arrays in the firmware, etc. If you write your own script during development, you need to put the script in this directory. output The output directory stores all the final results of the compilation, including the static library generated by each code folder and third-party code, the output binary file and the elf file, where we burn the binary .bin file. "},"contribute/":{"url":"contribute/","title":"Contribute","keywords":"","body":"Contribute to the project Since this is an open source project, everyone is welcome to join in and improve MaixPy. Due to the large number of people, we need a code convention (including format, style, etc.) The following documents describe the coding convention for both the documentation and code: Documentation convention Code convention "},"contribute/doc_convention.html":{"url":"contribute/doc_convention.html","title":"Documentation convention","keywords":"","body":"Documentation Convention Documents are built using gitbook and written in simple and efficient Markdown The documentation source code is hosted on GitHub Markdown syntax If you've never used the basic syntax of Markdown, please take half an hour to learn. We recommend the GitHub tutorial: GitHub Markdown Tutorial In this article, we need to pay attention to the following points: The syntax tags of the title class must be separated by spaces. A blank line is required between the headline and the body, such as: ## This is a secondary title * This is list item 1 * This is list item 2 The following example is not correct, it may cause the parser to parse the file with errors. ##This is a secondary title *This is list item 1 *This is list item 2 All pages have only one top level title Because the need to automatically generate a directory, mainly to ensure that the automatically generated directory is correct. Write each page like this Page title/top level title ======= (There is at least three equals here) (At least one more blank line is required, 2 lines are recommended) ## Secondary title 1 (You cannot use a first-level title here, and you cannot use a ##. You don't need to write a serial number, it will automatically generate a serial number.) ( Skip a line ) text (at least one line) ### Three-level title (similar to the second-level title, it does not need to be written, it will be generated automatically) text ## Secondary title 2 text Link Due to the large number of pages and the need to link resources such as images, relative paths are used when writing links. The directory structure is as follows: Assets/ (put public resource files) | ----pic000.png En/ | ----- get_started/ | ---- assets/ (put the resource file common to the md file in the get_started directory) | ------ pic.png | ---- get_hardware.md | ---- how_to_read.md Zh/ If you want to show the images in get_hardware.md, put the image in the assets folder, then use the following code to reference the image: ![pic](assets/pic.png) ![pic](../../assets/pic000.png) Chinese and English mixed When writing Chinese documents, the Chinese characters should be separated by spaces as much as possible. Punctuation should use full-width symbols as much as possible. Mainly to make it stand out and make the document more elegant. For example, the following comparison: In Micropython, we often use `deinit` to represent the destructor instead of setting the default value like STM32. In Micropython, we often use deinit to represent the destructor instead of setting the default value like STM32. In Micropython, we often use deinit to represent the destructor, instead of setting the default value like STM32. In Micropython, we often use deinit to represent the destructor, instead of setting the default value like STM32. Directory and file name The generated document directory is edited in the corresponding language folder SUMMARY.md The source document folder should be a function module corresponding to a folder, and the resource file (picture) is placed in the assets folder directory of the current path of the corresponding md document, which is more convenient when adding, deleting, and modifying. Assets/ (put public resource files) En/ | ----- get_started/ | ---- assets/ (put the resource file common to the md file in the get_started directory) | ---- get_hardware.md | ---- how_to_read.md Zh/ The file name is not limited to README.md, other file names are named with lowercase + underscore, such as get_hardware.md Catalog and links Try to guide readers to use the directory, and use the jump link in the text with caution. If the link jumps in a mess, it will cause the document to look messy and it will be difficult to read. Chinese and English (multi-language) page file directory structure and file name are the same Since there are multiple language switching options in the last generated page, clicking the switch will directly access the same path of the corresponding language, so the Chinese and English directory structure and file name must be the same. For example, English is accessing en/get_started/how_to_read.md. After clicking the button for language switching, it will automatically access zh/get_started/how_to_read.md. If this file does not exist, it will report a 404 error! Module Document Content Need to include a module introduction in the file header Need to explain the constructor, function, constant, etc. Explain that you can't be lazy. Simply translate the function name again. You need to explain the function of the function, the range of parameters, and the point of attention Multi-version management In addition to the Chinese and English (multi-language) support (not automatic translation, manual modification), the document also has multi-version management. Each version is a branch with requirements for the branch name, which are: master branch is the main branch dev branch for development branch Other published historical versions start with a lowercase v, such as creating a branch called v1.2 After creating a new branch, you need to modify the version link in book.json in the directory of each language version, otherwise the reader can't find the entry. You can preview it locally under the newly created branch (see the root directory README.md for the preview method). Note that the previewed page is the current branch. If you want to preview other branches locally, you need to switch to other points before previewing. Just fine. After confirming that the error is modified, push the branch to the remote (github), the automatic build system will be automatically built and published to the pages branch, and the effect will be seen when the access URL is built. "},"contribute/code_convention.html":{"url":"contribute/code_convention.html","title":"Code convention","keywords":"","body":"Code Convention "},"others/open_projects.html":{"url":"others/open_projects.html","title":"Open Source Projects","keywords":"","body":"Open source projects related to MaixPy If you have any open source projects related to MaixPy, feel free to open a new pull request or let us know by opening an issue or sending an email (support@sipeed.com)! We are happy to receive your feedback and contributions! "}}